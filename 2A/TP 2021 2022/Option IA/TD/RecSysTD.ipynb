{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RecSysTD.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN7qdi1TWKNZN7pooHkTi8h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thad75/TP-ENSEA-ELEVE/blob/main/2A/TP%202021%202022/Option%20IA/TD/RecSysTD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puWxHBgcYLyM",
        "outputId": "eca9f464-dcbb-4d00-af44-c5e622d494c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-04 10:44:58--  https://files.grouplens.org/datasets/movielens/ml-20m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 198702078 (189M) [application/zip]\n",
            "Saving to: ‘ml-20m.zip’\n",
            "\n",
            "ml-20m.zip          100%[===================>] 189.50M  75.5MB/s    in 2.5s    \n",
            "\n",
            "2023-03-04 10:45:01 (75.5 MB/s) - ‘ml-20m.zip’ saved [198702078/198702078]\n",
            "\n",
            "Archive:  /content/ml-20m.zip\n",
            "   creating: ml-20m/\n",
            "  inflating: ml-20m/genome-scores.csv  \n",
            "  inflating: ml-20m/genome-tags.csv  \n",
            "  inflating: ml-20m/links.csv        \n",
            "  inflating: ml-20m/movies.csv       \n",
            "  inflating: ml-20m/ratings.csv      \n",
            "  inflating: ml-20m/README.txt       \n",
            "  inflating: ml-20m/tags.csv         \n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-1.9.4-py3-none-any.whl (827 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m827.8/827.8 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (4.5.0)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (4.64.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (2023.1.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (6.0)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.11.3-py3-none-any.whl (518 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.6/518.6 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (1.13.1+cu116)\n",
            "Collecting lightning-utilities>=0.6.0.post0\n",
            "  Downloading lightning_utilities-0.7.1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.25.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.12.7)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, pytorch-lightning\n",
            "Successfully installed lightning-utilities-0.7.1 pytorch-lightning-1.9.4 torchmetrics-0.11.3\n"
          ]
        }
      ],
      "source": [
        "!wget https://files.grouplens.org/datasets/movielens/ml-20m.zip\n",
        "!unzip \"/content/ml-20m.zip\"\n",
        "!pip install pytorch-lightning\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import pandas as pd\n",
        "import pycocotools\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from IPython.display import clear_output, display\n",
        "from pytorch_lightning import loggers as pl_loggers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "pd.set_option(\"expand_frame_repr\", False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hands-On : Recommending an artist\n",
        "\n",
        "Given the following data, we want to recommend a list of artists from our existing database to the listener. Using similarity computation, recommend in the decreasing order the artists that suits listerners' taste"
      ],
      "metadata": {
        "id": "z5mobf2WMiey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'Artist': ['Celine Dion', 'Fred Again', 'Elton John', 'Black Eyed Peas', 'BTS', 'Anirudh', 'A.R Rahman', 'User'],\n",
        "    'International': [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    'Sings in French': [1, 0, 0, 0, 0, 0, 0, 0],\n",
        "    'Versatility': [0, 0, 0, 0, 0, 1, 1, 1],\n",
        "    'Danceability': [0, 1, 0, 1, 1, 1, 1, 0],\n",
        "    'Makes Film Music (BGM)': [0, 0, 1, 0, 0, 1, 1, 1],\n",
        "    'Won Awards': [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    'Recent Hit': [0, 1, 0, 0, 1, 1, 1, 0]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df = df.set_index('Artist')\n",
        "\n",
        "# TODO : Print the datafmale\n",
        "print(df)"
      ],
      "metadata": {
        "id": "Is2l__NFM6bb",
        "outputId": "2ef1a35a-921b-4530-9b17-c50095f16418",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 International  Sings in French  Versatility  Danceability  Makes Film Music (BGM)  Won Awards  Recent Hit\n",
            "Artist                                                                                                                    \n",
            "Celine Dion                  1                1            0             0                       0           1           0\n",
            "Fred Again                   1                0            0             1                       0           1           1\n",
            "Elton John                   1                0            0             0                       1           1           0\n",
            "Black Eyed Peas              1                0            0             1                       0           1           0\n",
            "BTS                          1                0            0             1                       0           1           1\n",
            "Anirudh                      1                0            1             1                       1           1           1\n",
            "A.R Rahman                   1                0            1             1                       1           1           1\n",
            "User                         1                0            1             0                       1           1           0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import manhattan_distances\n",
        "\n",
        "\n",
        "# TODO : Extract users' likings (check loc method from df)\n",
        "user= df.loc[['User']]\n",
        "other_line = df.loc[['Celine Dion']]\n",
        "keys = [key for key in df.index if 'User' not in key]\n",
        "\n",
        "# TODO : Define a Similarity Function (Cosine or Distance will be enough)\n",
        "def similarity_function(l1, l2):\n",
        "  return manhattan_distances(l1,l2)\n",
        "# TODO : Compare each artists to the user's taste and print the list of recommendable artist.\n",
        "values = []\n",
        "\n",
        "for key in keys: \n",
        "\n",
        "  value = similarity_function(user, df.loc[[key]])\n",
        "  values.append((key, value))\n",
        "distance_df = pd.DataFrame(values, columns=[\"key\", \"similarity\"])\n",
        "distance_df.set_index('key')\n",
        "print(distance_df)"
      ],
      "metadata": {
        "id": "s8WfvAvmNLp7",
        "outputId": "619ec02e-51b9-4d26-b3c2-c1a8ad759273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               key similarity\n",
            "0      Celine Dion    [[3.0]]\n",
            "1       Fred Again    [[4.0]]\n",
            "2       Elton John    [[1.0]]\n",
            "3  Black Eyed Peas    [[3.0]]\n",
            "4              BTS    [[4.0]]\n",
            "5          Anirudh    [[2.0]]\n",
            "6       A.R Rahman    [[2.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hands-on: Feature Extraction and Hashing Tricks"
      ],
      "metadata": {
        "id": "FFnCrRfoarHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction import FeatureHasher\n",
        "\n",
        "# Creating array of dicts\n",
        "data = [\n",
        "    {'dog': -1, 'cat': 2, 'elephant': 4},\n",
        "    {'dog': 2, 'run': 5, 'cat':-7}\n",
        "]\n",
        "\n",
        "h = FeatureHasher(n_features=150)\n",
        "h.transform(data).toarray()"
      ],
      "metadata": {
        "id": "7BbJFP_hbeqO",
        "outputId": "7830f1d5-8c35-4b21-b362-f284bb1c68ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0., -4.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
              "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -5.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0., -7.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommendation Systems\n",
        "\n",
        "Using MovieLens Dataset, build a recommendation system. Feel free for your model. We suggest you to inspire yourself from the NCF Model. This mini lab is **voluntarily sparse**. As future engineers,you'll need to go fetch informations everywhere in order to create and train your model. Don't hesitate to ask questions ! A live correction will be given.\n",
        "\n",
        "Goal of this mini Lab :   \n",
        "*  **Be lost**\n",
        "* Discover new frameworks and read documentation\n",
        "* Explore Datas and think\n",
        "* Create and Train a model using Pytorch Lightning"
      ],
      "metadata": {
        "id": "cSsUwP-oYO6g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MovieLens Dataset\n",
        "\n",
        "As a Data Scientist, your work is to understand the data your working with. Using Panda Dataframe have a look at the ratings.csv and movies.csv files and answer the following questions.\n",
        "\n",
        "* What are the features of both csv files ?\n",
        "* To you, what could be the most important csv file ?\n",
        "* How many movies are there ?\n",
        "* How many users rated movies ? \n",
        "* How users did rate the movies ? \n",
        "* What's the span of the ratings ? Using matplotlib or seaborn, plot the ratings for a given movie.\n",
        "* Can we merge both tables ? if yes what key should be used to merge them ?\n",
        "* What are the differents genres of the movies ?\n",
        "* Are there outliers ?\n",
        "\n",
        "Documentation available on : https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html"
      ],
      "metadata": {
        "id": "k-HveM9ZYieW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZVIq4szvaj76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some Changes\n",
        "\n",
        "For the rest of the lab, we will only use .05% of the dataset as it it too much for this notebook ( RIP Google ). Run the following cell for the rating dataframe. It will replace the existing rating dataset by a splitted dataset corresponding to 0.05% of the dataset"
      ],
      "metadata": {
        "id": "8Hg8zt9ea1_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings, _ = train_test_split(ratings, test_size = 0.95)"
      ],
      "metadata": {
        "id": "sVkJ5S1LbMLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create your Dataset\n",
        "\n",
        "At this point, you should have a good understanding of the given model. \n",
        "The given Dataset is a csv file. As we work with Tensors and Pytorch, we need to convert the Dataset to something readable by a Pytorch Model. Define a Dataset class that inherits from Dataset that returns a dictionnary {user, item, ratings}. The skeleton is given.\n",
        "Don't forget to create your train, test, validation datasets.\n",
        "\n",
        "Documentation available on : https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
      ],
      "metadata": {
        "id": "nlIXMBoRbc1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MovieLensDataset(Dataset):\n",
        "\n",
        "  def __init__(self,dataframe):\n",
        "      self.dataframe = \n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "\n",
        "      return {'user': torch.tensor(, dtype=torch.long),\n",
        "              'movie':  torch.tensor(, dtype=torch.long),\n",
        "              'rating':  torch.tensor(, dtype=torch.float)}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len()\n"
      ],
      "metadata": {
        "id": "3YW4LI87cAdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create your DataLoaders\n",
        "\n",
        "Now as in the labs, we want to fetch lot of data at the same time to send it to the model. We use DataLoaders. Define Dataloaders for each of your DataSets"
      ],
      "metadata": {
        "id": "4gi20sLNbfbt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rYvkMJCwcsot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Model\n",
        "\n",
        "Create a model that inherits from nn.Module. A skeleton is given. If you don't have any ideas, try to reimplement NCF model.\n",
        "\n",
        "Documenation available on : https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html"
      ],
      "metadata": {
        "id": "7P3EpMnMbiwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RecModel(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self,..):\n",
        "\n",
        "\n",
        "    def forward(self, ..):"
      ],
      "metadata": {
        "id": "XkCM-u6KcrQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train\n",
        "\n",
        "Form your training Loop and train your model. Don't forget your optimizer, batch size , number of epochs...\n",
        "\n",
        "Documentation with example on : https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
      ],
      "metadata": {
        "id": "UlOXFaW5bnyx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OH61ZalJcuXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test\n",
        "\n",
        "Test your model on the test set. \n",
        "Do we need a metric ? If yes use the RSME as a metric"
      ],
      "metadata": {
        "id": "X2ID6GmcbpR2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QZgUaa7Ycu0A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}