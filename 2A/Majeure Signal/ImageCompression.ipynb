{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thad75/TP_ENSEA_ELEVE/blob/main/2A/Majeure%20Signal/ImageCompression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUZCOMw1Gem5"
      },
      "source": [
        "# Image Compression using AutoEncoders: A Deep Learning Task\n",
        "\n",
        "Time : 8h"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Goal of this lab\n",
        "\n",
        "* Get to know Deep Learning and PyTorch Framework\n",
        "* Learn how to compress images using AutoEncoders\n",
        "* Understand the differences between JPEG compression and Deep Learning for compression\n",
        "* Know how to read and use code given by someone else\n"
      ],
      "metadata": {
        "id": "mL9lLUJmpab6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parts of this lab\n",
        "\n",
        "The lab is constructed as follows\n",
        "\n",
        "* 0 - Introduction and Documents Reading\n",
        "* 1 - Discovering a Dataset\n",
        "* 2 - Creating a Model\n",
        "* 3 - Training the Model\n",
        "* 4 - Testing the Model\n",
        "* 5 - Reporting the findings"
      ],
      "metadata": {
        "id": "NN6NsODyqGEw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc8OA-MQ6n09"
      },
      "source": [
        "# Disclaimer\n",
        "\n",
        "We will refer to :\n",
        "- AutoEncoder as AE\n",
        "- Multi Layer Perceptron as MLP\n",
        "\n",
        "Before beginning this lab, please make sure that your environment has a GPU. For that, go to : \n",
        "* Execution\n",
        "* Modifier le type d'execution\n",
        "* Accelerateur matÃ©riel : GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fup2OihC7Kkv"
      },
      "source": [
        "# 0 - Introduction\n",
        "\n",
        "So basically during the part 1 of this lab, we have seen JPEG Compression. JPEG compression is a general algorithm that can compress any image. Let's first see your understanding of the JPEG algorithm :\n",
        "* What are the component in the Encoding part of the algorithm ?\n",
        "* What are the component in the Decoding part of the algorithm ?\n",
        "* Is the down-sampling phase of JPEG linear ? (i.e : in a y = ax+b form)\n",
        "* Is it a lossless compression algorithm ?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "knsHAKnypFdk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmPz4EM86n09"
      },
      "source": [
        "## a- Your Mission : AI for the Win\n",
        "\n",
        "\n",
        "Hi there, we are a Big Company and we need your help. We have some images that we want to compress. We tried the JPEG algorithm but we want to try some new state of the art methods. Your mission is to help us as a Data Scientist in this task by creating a DL model that compresses image with as less loss as possible. \n",
        "\n",
        "\n",
        "Alright, let's get started.\n",
        "\n",
        "<img src=\"https://i.pinimg.com/originals/16/b2/96/16b296afb78ec57d12c931bc72b42eec.gif\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "315B4XDj9ln-"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import MNIST, CIFAR10\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import skimage\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import torchvision.transforms as transform"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b - Reading the Docs \n",
        "\n",
        "Welcome to Big Company, as usual when beginning a new project you have some reading to do. Take 5-10 minutes to read the following documentation to understand something.\n",
        "\n",
        "In this lab you will see messages from :\n",
        "* The Data Engineering Team\n",
        "* The Senior Data Scientist\n",
        "\n",
        "Read them"
      ],
      "metadata": {
        "id": "2AKbYlYjUiw8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1iy5iLS6n0_"
      },
      "source": [
        "### i - What is Deep Learning ?\n",
        "\n",
        "Deep Learning is a branch of AI where you **teach a Model** a certain **task** using a **Dataset**. The model or a neural network is built by multiple consecutive **layers** of neuron-like units, remotely based on neurons in the human brain. Typically, many consecutive layers are used, that is why it is referred to as deep learning. In those layers, each neuron has several **parameters** (**weights**) that are updated during **training** by minimizing a **loss** (error) function, using **Stochastic Gradient Descent**. Besides the model parameters, to be found using a dataset, there are also **hyperparameters** that you have to tune by yourself, for example, how many layers used in your model, how many neurons per layer,.... The Model infers a prediction from an **input**. In fact, a Deep Neural Network can be seen as a complex function ${f}$ that maps the input data to a learned space from the Dataset. \n",
        "\n",
        "Note the bold words. These are the important things you need to understand about Deep Learning. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awLz7ozJ6n1A"
      },
      "source": [
        "### ii- Generalities on AutoEncoder\n",
        "\n",
        "<img src = \"https://blog.keras.io/img/ae/autoencoder_schema.jpg\">\n",
        "\n",
        "\"Autoencoding\" is a data compression algorithm where the compression and decompression functions are 1) data-specific, 2) lossy, and 3) learned automatically from examples rather than engineered by a human. In almost all contexts where the term \"autoencoder\" is used, the compression and decompression functions are implemented with neural networks.\n",
        "\n",
        "1) Autoencoders are data-specific, which means that they will only be able to compress data similar to what they have been trained on. \n",
        "\n",
        "2) Autoencoders are lossy.\n",
        "\n",
        "3) Autoencoders are learned automatically from data examples.\n",
        "\n",
        "To build an autoencoder, you need three things: an encoding function, a decoding function, and a distance function between the amount of information loss between the compressed representation of your data and the decompressed representation. In fact, we can look at the model as a big function :\n",
        "\n",
        "* The Encoder : This part of the model compresses the input image to a compressed version of it, where $f(x)= z$, where $x$ is the input image, and $z$ the compressed representation of it.\n",
        "* The Decoder : This part of the model decompresses the compressed representation $z$ to the decompressed image $\\tilde{x}$, in other terms we have a function $g$ where, $\\tilde{x} = g(z)$\n",
        "* The AutoEncoder : by stacking the Encoder and the Decoder, and as we want $\\tilde{x} = x$ (a.k.a the reconstructed image as similar as the input image), we can rewrite the AE as $\\tilde{x} = g(z) = g\\circ f(x)=  x$ where $g= f^{-1}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### iii - Layers\n",
        "\n",
        "A Layer is an important part of a Model. In fact, it is the key element of a DL Model. A Layer is a structure that takes information from a layer to pass them to the next layer. In a DL Network, each layer extracts features. "
      ],
      "metadata": {
        "id": "qhcd3QvKhXdj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### iv -  Activation Functions\n",
        "\n",
        "An Activation Function is a function that is applied to the output of a Neural Layer. It is the equivalent of the excitation threshold for which a neuron reacts or not.\n",
        "\n",
        "<img src = \"https://miro.medium.com/max/1200/1*ZafDv3VUm60Eh10OeJu1vw.png\" height = 200>"
      ],
      "metadata": {
        "id": "Z7pUFCRvhYuE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DLNHchj6n1B"
      },
      "source": [
        "# 1- Data : Exploring the Unknown\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        " ðŸ”Š ðŸ”Š ðŸ”Š **Message from the Data Engineer** ðŸ”Š ðŸ”Š ðŸ”Š\n",
        "\n",
        "Hi,\n",
        "\n",
        "This is K. from the Data Engineering Team, we sent you some API and some code for you to begin your research.\n",
        "\n",
        "Good Luck\n",
        "\n",
        "K.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqws4UbZ6n1B"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "<img src=\"https://labelyourdata.com/img/article-illustrations/splitting_data.png\" height=200>\n",
        "\n",
        "\n",
        "When training  a DL model, we use a Dataset. The model uses the data to learn something for a task. We usually divide the data into Training, Validation, Test sets.\n",
        "- Training set is used to train the Model (i.e., to find the parameters of Model).\n",
        "- Validation set is used to watch the Model's training (to verify whether the training procedure goes well).\n",
        "- Test set is used to evaluate the performance of the Model (in our case, to measure if the model compresses and decompresses well new images).\n",
        "\n",
        "\n",
        "<img src=\"https://i.imgflip.com/653bu2.jpg\" height=400>\n",
        "\n",
        "**In our case of AE, we do not need the label of image. Our method is an unsupervised algorithm.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a - The first one : the Training set\n",
        "\n",
        "Understanding the Data : Data Exploration\n",
        "\n",
        "Ok let's have a look at what the Data Engineering Team sent us. Let's understand the Dataset. Let's use their API.\n",
        "\n",
        "\n",
        "- What is the size of the train dataset ?\n",
        "- What are the elements available in one piece of data ? (image,label)\n",
        "- What is the shape of one piece of data ?\n",
        "- What is the type of one piece of data ?\n",
        "- Plot few elements of the dataset using Matplotlib."
      ],
      "metadata": {
        "id": "TRKH2GO8PPKS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOdefqiw6n1B"
      },
      "outputs": [],
      "source": [
        "# TODO: Load MNIST Train Dataset from TorchVision\n",
        "\n",
        "dataset = MNIST('', train=..., download=True, transform=transforms.ToTensor())\n",
        "\n",
        "# TODO: What's the size of the Dataset ?\n",
        "# TODO: Retrieve one element of the Dataset ? What is the shape of one piece of Data ? \n",
        "\n",
        "size_of_dataset =  \n",
        "data = \n",
        "print(data[0].shape) # Question : Why is there [0] ?\n",
        "\n",
        "# TODO: Plot the retrieved Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b - The second one : the Test Dataset"
      ],
      "metadata": {
        "id": "IU_I7BipPEto"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsqbBFiz6n1C"
      },
      "source": [
        "As you can see, there's a train attribute to the MNIST Class. When it's set to True, you're loading the train Dataset. Hence, change it to false to load the test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVnRxxaa6n1C"
      },
      "outputs": [],
      "source": [
        "# TODO : Load the test dataset. Inspire yourself from the minst_train dataset loading\n",
        "\n",
        "mnist_test = "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's verify that the Data in the Test dataset are in the same style of the Train Dataset :    \n",
        "- Plot few Data from the Test Dataset with its label.\n",
        "- Are the data similar ? Are the labels similar ?"
      ],
      "metadata": {
        "id": "y77InD1eSuQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: What's the size of the Dataset ?\n",
        "# TODO: Retrieve one element of the Dataset ? What is the shape of one piece of Data ? \n",
        "# TODO: Plot the retrieved Data\n",
        "\n",
        "size_of_dataset = \n",
        "data = \n",
        "\n",
        "plt.imshow"
      ],
      "metadata": {
        "id": "ZGl0JVb9S75z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c - The third one : Creating the Validation Dataset"
      ],
      "metadata": {
        "id": "6x4LBC7HUk8S"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSbPGhqP6n1D"
      },
      "source": [
        "At this moment, we have a Train and a Test Dataset. We also like having a Validation Dataset. The validation dataset is often a smaller part of the training dataset.The Validation Dataset allows us to follow the models training. In fact, the data of the Validation Dataset is sent to the model while training.  However, no gradients are computed for the Validation Dataset Data resulting in no update on the weights.\n",
        "\n",
        "- What does 55000 and 5000 mean ?\n",
        "- Determine the split value of the training set to create the validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiGz4sBr6n1D"
      },
      "outputs": [],
      "source": [
        "# Questions : what does 55000 and 5000 mean ? Hint: look at the Dataset length and determine the split value\n",
        "mnist_train, mnist_val = random_split(dataset, [55000, 5000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blh2vwZu6n1D"
      },
      "source": [
        "### d - Creating the Dataloader\n",
        "\n",
        "So the Dataset returns one element at a time. In DL, we like sending many items at the same time to the model. We form BATCH of Data using a DataLoader. Dataloader are an iterable over the dataset. It means that the Dataloader will form BATCH of Data for you and fetch them \n",
        "- Create a DataLoader for your Training, Valid and Testing Dataset\n",
        "- What is the drop_last attribute ?\n",
        "\n",
        "More information on dataloader : https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EM2xVJQ6n1D"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(mnist_train, batch_size=128,drop_last =True)\n",
        "val_loader = \n",
        "test_loader ="
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Did the Data Engineer do a good work ?\n",
        "- Is there enough data ?\n",
        "- Are they easily accessible ?\n",
        "- Are they correctly labeled ?\n",
        "\n"
      ],
      "metadata": {
        "id": "eHI5FPtkbiY_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utu6siUB6n1D"
      },
      "source": [
        "# 2 - Creating and Training the Model : The AutoEncoder\n",
        "\n",
        "Now that we saw what the data was and created our datasets, we need to fullfil our mission. We need a model.\n",
        "\n",
        "<img src=\"https://i.imgflip.com/640uob.jpg\" height=300>\n",
        "\n",
        "We are going to explore the path of AutoEncoders ! Alright let's write some readable codes. Our code must be modulable and easy to read. We should try two types of AutoEncoders :    \n",
        "- MLP Style\n",
        "- Conv Style\n",
        "\n",
        "\n",
        "Use PyTorch and Create Modulable and Stackable Models that inherits from nn.Module."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjUHGbOi6n1E"
      },
      "source": [
        "## a - MLP Style : Exploring the Neurons\n",
        "\n",
        "<img src='https://www.researchgate.net/publication/344394387/figure/fig1/AS:974657746399232@1609387923440/Figure-Computational-Schematics-of-the-MLP-and-the-autoencoder.png'>\n",
        "\n",
        "We will first try a MLP AE.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating a Model in PyTorch\n",
        "\n",
        "Creating a model in PyTorch is simple. A PyTorch is an object that inherits from nn.Module. The pseudo-code is the following :     \n",
        "\n",
        "```\n",
        "class Model(nn.Module):\n",
        "  def __init__(self,...):\n",
        "    \"\"\"\"\n",
        "    Defines the model. You can put the input size as a parameter if needed..\n",
        "    \"\"\"\"\n",
        "    super().__init__() # to init the main class\n",
        "    self.layers = ... # defining the model : could be Conv2d, Linear, RNN, LSTM\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    \"\"\"\n",
        "    The input x is forwarded through the neural net. \n",
        "    \"\"\"\n",
        "    output = self.layers(x)\n",
        "    return output\n",
        "\n",
        "  # Other methods go down\n",
        "```\n",
        "\n",
        "More informations : https://pytorch.org/docs/stable/nn.html\n"
      ],
      "metadata": {
        "id": "UvnEBg0ahMa1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### i - Correcting the Mistakes\n",
        "\n",
        "First, we will try a really simple model :\n",
        "* an Input Dense Layer\n",
        "* a Latent Space\n",
        "* an Output Dense Layer\n",
        "\n",
        "\n",
        "We have received some codes from the other members of the Deep Learning Engineering Team. Looks like there are lots of mistakes.. Let's correct them."
      ],
      "metadata": {
        "id": "T730pWdwLRXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Correct the Following Class. \n",
        "# Hint : Look at the input, output size, the activations, how the data is forwarded ...\n",
        "\n",
        "class AutoEncoder_MLP(nn.Module):\n",
        "  def __init__(self, input_size, compressed_space_size):\n",
        "    \"\"\"\n",
        "    The model is an Input Layer, a Hidden Layer and an Output layer \n",
        "    \"\"\"\n",
        "    super().__init__() \n",
        "    # TODO : Init the class attributes thanks to the arguments of the init methods\n",
        "    self.input_size = 42\n",
        "    self.output_size = 'ouioui le sens de la vie'\n",
        "    self.compressed_space_size = -1\n",
        "    # TODO : Correct the mistakes from the model\n",
        "    self.input = nn.Sequential(nn.Linear(self.input_size, self.compressed_space_size),\n",
        "                               nn.Sigmoid())\n",
        "    self.output = nn.Sequential(nn.Linear(self.output_size,self.compressed_space_size ),\n",
        "                               nn.ReLU())\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    \"\"\"\n",
        "    The input x is forwarded through the neural net. \n",
        "    \"\"\"\n",
        "    # TODO : Correct the mistakes\n",
        "    compressed_image = self.input(x)\n",
        "    decompressed_image = \n",
        "    return decompressed_image"
      ],
      "metadata": {
        "id": "bxvGXm9rLx2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Create an Instance of the Model by calling the Class with the correct values\n",
        "\n",
        "model = AutoEncoder_MLP(input_size = ...,\n",
        "                        compressed_space_size= ...)\n",
        "\n",
        "# TODO : Print the model.\n"
      ],
      "metadata": {
        "id": "YSb86xStr3gK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N8KQNJy6n1F"
      },
      "source": [
        "## b - Training\n",
        "\n",
        "We can train the model. We have a Model and a Dataset. We need few more things..\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### i - A Loss\n",
        "\n",
        "We need a Loss Function. The Loss function must tell us how far our predictions are from the labels (or not ?). It could be by comparing the distribution of two input datas, or by directly comparing the datas using distances .\n",
        "\n",
        "Let's reason. We are recreating an Image from its compressed version and we want that the recreated image must be as similar as the original image. i.e $\\tilde{x} = x$\n",
        "\n",
        "<img src=\"https://i.imgflip.com/653jbl.jpg\" height=400>\n"
      ],
      "metadata": {
        "id": "5MqMXbQw_1Kr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- How can you calculate the similarity between two vectors ?\n",
        "- What type of loss do you know that calculates the **distance** between two inputs ?\n",
        "\n",
        "More informations : https://pytorch.org/docs/stable/nn.html#loss-functions"
      ],
      "metadata": {
        "id": "cjJwaIhlVrWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Delete the uncorrect loss \n",
        "criterion = nn.MSELoss() or nn.BCELoss() \n",
        "\n",
        "\"\"\" \n",
        "RÃ©ponse : \n",
        "criterion = nn.MSELoss()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Am2fuauUBoUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ii - An Optimizer\n",
        "\n",
        "<img src=\"https://i.imgflip.com/640sfs.jpg\" height= 400>\n",
        "\n",
        "We need something to update the weights of the model. In fact, we need to perform Gradient Descent to recalculate the weights of each layers regarding the model's predictions. The optimizer will search for an Optimum. However, it needs a step to perform this research. This step is called the Learning Rate. The learning rate has a huge effect on the learning. \n",
        "\n",
        "<img src=https://miro.medium.com/max/918/0*uIa_Dz3czXO5iWyI. height =300>\n",
        "\n",
        "In this case, we will use Adam Optimizer as it is a really efficient Optimizer. Don't hesitate to have a look at the other optimizers. \n",
        "\n",
        "More informations : https://pytorch.org/docs/stable/optim.html"
      ],
      "metadata": {
        "id": "vdJa2rgV___i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : define a small learning rate\n",
        "learning_rate =  \n",
        "# TODO : load the Adam optimizer in the optimizer variable\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=....)\n"
      ],
      "metadata": {
        "id": "7lykHsQ-HrMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### iii - Training\n",
        "\n",
        "Now that we have everything that is needed for training, we have to create the training loop. We need hyperparameters, parameters that controls the learning. We also need to send the model and the data to the gpu for accelerated computation.\n",
        "\n",
        "\n",
        "The loop consists of :\n",
        "* Sending Data through the model to obtain Predictions\n",
        "* Computing the Loss \n",
        "* Backwarding the Loss using Gradients \n",
        "* Logging the losses and accuracies (if exists)\n",
        "\n",
        "\n",
        "The number of epochs is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset.\n",
        "\n",
        "Think of it as you trying to answer an exercise : the first time you won't understand, the second time you'll suceed more, and so on.."
      ],
      "metadata": {
        "id": "9sVerRhLIdpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre Defined and Useful variables\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' # To send to the gpu\n",
        "mini_batches_print = 10 # To print every 10 mini batches\n",
        "\n",
        "# TODO : Send the model to the device using .to\n",
        "net = \n",
        "\n",
        "# TODO : Define your number of epochs\n",
        "\n",
        "num_epochs = \n",
        "\n",
        "loss_train , loss_val = [], []\n",
        "for epoch in range(num_epochs) : \n",
        "    running_loss_t,running_loss_v = 0.0, 0.0\n",
        "    # TODO : Create your Training Loop\n",
        "    for i, data in enumerate(train_loader, 0): \n",
        "        # TODO : load the data into two variables\n",
        "        image, label = ...\n",
        "        # TODO : reshape the input image using .view() so that it fits the input layers neuron numbers.\n",
        "        # Don't forget the Batch Size, the 1rst dimension must always be the Batch Size\n",
        "        image_reshaped, label = \n",
        "        optimizer.zero_grad()\n",
        "        # TODO : send the image to the model\n",
        "        outputs = net()\n",
        "\n",
        "        # TODO/Questions : Do we need to reshape the input image ? If yes, reshape the image\n",
        "        outputs = \n",
        "\n",
        "        # TODO : Compute the loss. Don't forget to send the image to the device\n",
        "        loss = criterion( , )\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss_t += loss.item()\n",
        "        if i == mini_batches_print :\n",
        "          running_loss_t= running_loss_t/mini_batches_print  \n",
        "          print('training loss is :',running_loss_t)\n",
        "          loss_train.append(running_loss_t)  \n",
        "\n",
        "    # TODO : Create your Validation Loop\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(val_loader, 0):    \n",
        "        # TODO : Do the same as the Train loop but delete everything related to weight update (optimizer, loss backwards ...)\n",
        "        image, label = # Keep or not ?\n",
        "        outputs =\n",
        "        outputs =\n",
        "        loss =  \n",
        "        optimizer.zero_grad() # Keep or not ?\n",
        "        loss.backward() # Keep or not ?\n",
        "\n",
        "        running_loss_v += loss.item()\n",
        "        if i == mini_batches_print :\n",
        "            running_loss_v= running_loss_v/mini_batches_print \n",
        "            print('validation loss is :',running_loss_v)\n",
        "            loss_val.append(running_loss_v)\n",
        "      "
      ],
      "metadata": {
        "id": "v_9nrxJj7Bj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### iv - Did it learn somethin' ?\n",
        "\n",
        "As you might see we've logged into two lists (train_loss, val_loss) the losses computed while training. Let's plot them (Don't forget to put Titles and Axis)\n",
        "- How can you tell that the training is over ?"
      ],
      "metadata": {
        "id": "KP7wfVDTVNn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : plot the train and val loss on the same graph using matplotlib.pyplot.\n",
        "# Always put legend on your graphs\n",
        "\n",
        "plt.plot(...)\n",
        "plt.plot(...)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "myd0mSIkVc7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c - Testing the Compression\n",
        "\n",
        "Now that we trained our model, let's test it on the test dataset. What does testing mean ? Wait there's an email from the senior Data Scientist :\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        " ðŸ”Š ðŸ”Š ðŸ”Š **Message from the Senior Data Scientist** ðŸ”Š ðŸ”Š ðŸ”Š\n",
        "\n",
        "Hi, this is C. the Senior Data Scientist\n",
        "\n",
        "I heard that you've trained your model. Ok so let's test it, shall we ?\n",
        "Take the test dataloader, iterate through it and send the test data to the model. We need to check how similar to input image the decompressed image is..\n",
        "Don't forget to delete all gradients calculations, it takes time and space for nothing. \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6rFLeJkes8Ll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interesting, the Senior talked about deleting all gradient calculations \n",
        "* Why must we not compute the gradients for the testing step ?"
      ],
      "metadata": {
        "id": "FISqPpOGuGHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(img,name= 'GT'):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.title(name)\n",
        "    plt.show()\n",
        "\n",
        "# TODO : form your testing loop. Is it different than the validation loop ?\n",
        "with torch.no_grad():\n",
        "  losses = 0\n",
        "  for i, data in enumerate(test_loader, 0):\n",
        "    image, label = .....\n",
        "    .... \n",
        "    .... \n",
        "    ....\n",
        "\n",
        "# Plot the last batch\n",
        "imshow(torchvision.utils.make_grid(outputs.detach().cpu()),'Pred')\n",
        "imshow(torchvision.utils.make_grid(data[0]),'GT')\n",
        "\n",
        "# TODO : Print the difference in decompression and write it somewhere\n",
        "print('The difference between the Real Images and the Decompressed Images is: ',...)"
      ],
      "metadata": {
        "id": "1AB-kxbEtIbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jak6Xd8h6n1F"
      },
      "source": [
        "Ok now to see the effect of the compression, change the latent_size to different values. For example try : 512, 128, 16, 1.\n",
        "\n",
        "\n",
        "<img src=\"https://i.imgflip.com/64elyi.jpg\" height=200>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Change your model, Test for differents size of Compressed Space Size. We advice you to try 1, 128, 512\n",
        "model = AutoEncoder_MLP(28*28,...)\n",
        "\n",
        "# TODO : Train it. Can we copy paste previous things ?\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "net = model.to(device)\n",
        "criterion = ...\n",
        "learning_rate = ...\n",
        "optimizer = ...\n",
        "num_epochs = ...\n",
        "\n",
        "# TODO : Train it. Can we copy paste previous things ?\n",
        "for epoch in range(num_epochs) : \n",
        "    running_loss_t,running_loss_v = 0.0, 0.0\n",
        "    # Train Loop\n",
        "    for i, data in enumerate(train_loader, 0): \n",
        "      ....\n",
        "\n",
        "\n",
        "    # Validation Loop\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(val_loader, 0):  \n",
        "        ...\n",
        "\n",
        "# TODO : Test the Trained Model. Can we copy paste previous stuff ?\n",
        "\n",
        "with torch.no_grad():\n",
        "  running_loss = []\n",
        "  for i, data in enumerate(test_loader, 0):  \n",
        "    ...  \n",
        "\n",
        "# Plot the last batch\n",
        "imshow(torchvision.utils.make_grid(outputs.detach().cpu()),'Pred')\n",
        "imshow(torchvision.utils.make_grid(data[0]),'GT')\n",
        "\n",
        "# TODO : Print the reconstruction error over the test dataset\n",
        "\n",
        "print( 'The decompression of the Encoded Test Dataset has an reconstruction error of: ', ....)\n"
      ],
      "metadata": {
        "id": "wRMKAqZdzrVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## d - Testing on unseen Data\n",
        "\n",
        "Alright, we can obsviously say that it works pretty fairly on the Test Data. We should be ok nah ?\n",
        "\n",
        "Let's test it on other Data.\n",
        "\n",
        "* Write the code to test the inference on Images taken from the internet."
      ],
      "metadata": {
        "id": "d4dirY6mE_Sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Test some images from the internet to see the compression effect \n",
        "image_filename = # TODO: give a URL's image \n",
        "image_numpy = cv2.cvtColor(skimage.io.imread(image_filename ),cv2.COLOR_BGR2GRAY)\n",
        "transform=transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Resize((28,28))])\n",
        "\n",
        "# TODO : Transform the images and add a dimension for the batch size using unsqueeze\n",
        "image = transform(...).unsqueeze(0)\n",
        "\n",
        "# TODO : Send the model to the model and process the prediction. Don't forget \n",
        "# the resizes\n",
        "pred = model(...)\n",
        "pred =\n",
        "\n",
        "# TODO : Plot dem results'. Don't forget to detach and send to the gpu the data\n",
        "# using .detach().cpu()\n",
        "\n",
        "fig,axarr = plt.subplots(1, 2)\n",
        "axarr[0].imshow(...)\n",
        "...\n"
      ],
      "metadata": {
        "id": "z8GcBFKAFCqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* What can you say ?"
      ],
      "metadata": {
        "id": "0UhnIMewpF5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3- Write your Research\n",
        "\n",
        "Now we need to present our results to the Senior Data Scientist. \n",
        "* Sum up all your research on this subject in 2 pages.\n",
        "\n",
        "You must explain :\n",
        "* The dataset you used \n",
        "* The tests you did\n",
        "* The models you tested\n",
        "* The results you had\n",
        "* The explanation of the results (why it works, why it doesn't)\n",
        "* How can we compute the compression rate of the model ? \n",
        "* Do we need to consider the model's size ?"
      ],
      "metadata": {
        "id": "J8Ma8YUNE3So"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 - Convolutional Layer Style : Seeing a Region\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1838/1*LSYNW5m3TN7xRX61BZhoZA.png\" height = 300>\n",
        "\n",
        "The first sprint is over. The Senior Data Scientist sent a new message !\n",
        "\n",
        "\n",
        "---\n",
        " ðŸ”Š ðŸ”Š ðŸ”Š **Message from the Senior Data Scientist** ðŸ”Š ðŸ”Š ðŸ”Š\n",
        "\n",
        "\n",
        "Hello\n",
        "\n",
        "Good work for your first results. However, we need to try another type of model.\n",
        "Test the same using Conv2d layers. I know that it is new for you but here are some explanations:  Convolutional Layers are filters that \"scans\" the input image in order to extract features. These filters extract features by looking at the region they're on\n",
        "\n",
        "I sent you some classes that you must reuse in your code. Tell me if it has better results\n",
        "\n",
        "C.\n",
        "\n",
        "P.S here's a funny image for you \n",
        "\n",
        "<img src=\"https://i.imgflip.com/65b89l.jpg\" height=300>\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "i1kpRMLuU9_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO : Need more explanation on conv layers\n",
        "\n",
        "BLABLABLBLALABLBALBLABLABLABLABLBALBALBALBLBLABLABLABLABLABLABLABLABLABLABLABLABLABLABLABLABLABLABLABLABLABLABLABALBLAA\n",
        "\n",
        "* MUST CONTAIN EXPLANATION ON CONV LAYER ?"
      ],
      "metadata": {
        "id": "B5crmvSMbkMN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take 5 minutes and play with the following link :   \n",
        "\n",
        "* https://ezyang.github.io/convolution-visualizer/\n",
        "\n",
        "Questions :    \n",
        "* What is the stride parameter ?\n",
        "* What is the padding parameter ?\n",
        "* What does it change on the output to increase the Kernel Size ?\n"
      ],
      "metadata": {
        "id": "ibihGUzZ-C00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## o - Some Definition\n",
        "\n",
        "Receptive Field : The receptive field are the pixels seen by the kernel layer"
      ],
      "metadata": {
        "id": "CC7RbnN1dKiW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a - Model Definition : The code they sent us\n",
        "\n",
        "Hmmm let's have a look at the model sent by the senior Data Scientist. Looks like there are bunch of submodules   "
      ],
      "metadata": {
        "id": "6v_cYtuufVur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### i - SubModules : The stem"
      ],
      "metadata": {
        "id": "FiDIW6xzfURZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conv Down\n",
        "\n",
        "ConvDown is used to compress the input image. It applies a convolution between the input image and the kernel. In fact, it is used to extract features. Our ConvDown Model will be composed of two layers :     \n",
        "* Conv2d layer\n",
        "* Non Linearity (ReLU)\n",
        "\n",
        "<img src=\"https://www.jeremyjordan.me/content/images/2017/07/no_padding_no_strides.gif\">"
      ],
      "metadata": {
        "id": "6aR_6-5AfURZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30AE171_fURZ"
      },
      "outputs": [],
      "source": [
        "class ConvDown(nn.Module):\n",
        "    \"\"\"\n",
        "    This class takes as input the channels and returns a feature map \n",
        "    for the given output channel. \n",
        "    It indeed applies ReLU to it\n",
        "    ConvDown stacks a Conv2d layer with an ReLU Activation \n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, input_channel, output_channel, kernel_size = 3):\n",
        "        super().__init__()\n",
        "        self.input_channel = input_channel\n",
        "        self.output_channel = output_channel\n",
        "        self.kernel_size = kernel_size\n",
        "        self.model = nn.Sequential(nn.Conv2d(self.input_channel, self. output_channel, kernel_size =self.kernel_size ),\n",
        "                                    nn.ReLU())\n",
        "                                    \n",
        "    def forward(self,x):\n",
        "        # TODO :  Send the data through the model and return the output\n",
        "        output = \n",
        "        return"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conv Up\n",
        "\n",
        "ConvUp is used to decompress the input image. In fact, it uses extracted features to propose a reconstructed output feature map.\n",
        "\n",
        "* From what you've seen on the website, is it possible to increase output size map using Conv2d layers ?\n",
        "\n",
        "We introduce ConvTranpose2D layers, that applies Transpose Convolution over an input image. It also means that these layers upsamples the input image. In fact the ConvTranspose layers learns to upsample the images.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1400/1*HnxnJDq-IgsSS0q3Lut4xA.gif\" height=200>"
      ],
      "metadata": {
        "id": "RTj9S6BdfURZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iup_9vP8fURZ"
      },
      "outputs": [],
      "source": [
        "class ConvUp(nn.Module):\n",
        "    \"\"\"\n",
        "    ConvUp stacks a Conv2d layer with an Activation \n",
        "    If output is True : the Activation is Sigmoid\n",
        "    If output is False : the Activation is ReLU\n",
        "    \"\"\"\n",
        "    def __init__(self, input_channel, output_channel, kernel_size = 3 , output = True):\n",
        "        super().__init__()\n",
        "        self.input_channel = input_channel\n",
        "        self.output_channel = output_channel\n",
        "        self.kernel_size = kernel_size\n",
        "        self.output = output\n",
        "        self.model = nn.Sequential(nn.ConvTranspose2d(self.input_channel, self. output_channel, kernel_size =self.kernel_size ),\n",
        "                                    nn.ReLU()) if output is False else nn.Sequential(nn.ConvTranspose2d(self.input_channel, self. output_channel, kernel_size =self.kernel_size ),\n",
        "                                    nn.Sigmoid())\n",
        "        \n",
        "    def forward(self,x):        \n",
        "      # TODO :  Send the data through the model and return the output\n",
        "      output = \n",
        "      return"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ii - Modules : The Wrappers"
      ],
      "metadata": {
        "id": "xKSienu_fURZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoder\n",
        "\n",
        "The encoder stacks multiple ConvDown to compress and extract features.\n",
        "\n",
        "<img src=\"https://i.imgflip.com/65bqe0.jpg\" height=300>"
      ],
      "metadata": {
        "id": "add5ul-BfURZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJg8gNNPfURZ"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    The encoder stacks multiple ConvDown to compress and extract features\n",
        "    For the moment, we just keep one ConvDown layer\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self,input_channel, output_channel, kernel_size = 3):\n",
        "        super().__init__()\n",
        "        self.input_channel = input_channel\n",
        "        self.output_channel = output_channel\n",
        "        self.kernel_size = kernel_size\n",
        "        self.model = nn.Sequential( ConvDown(self.input_channel, self.output_channel,self.kernel_size))\n",
        "                    \n",
        "    def forward(self,x):\n",
        "      # TODO :  Send the data through the model and return the output\n",
        "      output = "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decoder\n",
        "\n",
        "The decoder stacks multiple ConvUp to decompress and upsamples the input.\n",
        "\n",
        "<img src=\"https://i.imgflip.com/65br5o.jpg\" height=300>"
      ],
      "metadata": {
        "id": "-Ty_eE8ufURa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOIjpP5JfURa"
      },
      "outputs": [],
      "source": [
        "# TODO : Find the error in the initialization and correct it\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    The Decoder stacks multiple ConvUp to upsample and reconstruct from the input\n",
        "    another feature map\n",
        "    For the moment, we just keep one ConvDown layer\n",
        "    NEEDS TO BE CORRECTED\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self,input_channel, output_channel, kernel_size = 3, output = True):\n",
        "        super().__init__()\n",
        "        self.input_channel = input_channel\n",
        "        self.output_channel = output_channel\n",
        "        self.kernel_size = kernel_size\n",
        "        self.output = output\n",
        "        self.model = nn.Sequential( ConvUp(self.input_channel,self.input_channel,self.kernel_size, output))\n",
        "        \n",
        "    def forward(self,x):\n",
        "        # TODO :  Send the data through the model and return the output\n",
        "        output = \n",
        "        return"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### iii - The Conv AutoEncoder : Final Model \n",
        "\n",
        "Stack the Encoder and Decoder, we just have to stack them in order to form the AutoEncoder. The stacking is different here as we refer to the input and output channels of each layers.\n"
      ],
      "metadata": {
        "id": "IuUrSK7QfURa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGslcjwafURa"
      },
      "outputs": [],
      "source": [
        "# TODO : Stack the Encoder and the Decoder to Create the AE\n",
        "# Be careful to respect the init attributes of the called class\n",
        "\n",
        "class AutoEncoder_Conv(nn.Module):\n",
        "\n",
        "    def __init__(self,input_size,latent_size, output= True):\n",
        "        super().__init__()\n",
        "        self.input_size =\n",
        "        self.latent_size = \n",
        "        self.output = \n",
        "        self.model = \n",
        "\n",
        "    def forward(self,x):\n",
        "        return \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxIt_IxgfURa"
      },
      "source": [
        "## b - Training and Testing\n",
        "\n",
        "We can reuse the previously written code. However, we need to make some changes...\n",
        "\n",
        "* What changes must we do ?\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Change your model \n",
        "model = AutoEncoder_Conv(1,128)\n",
        "\n",
        "# TODO : Reload your HyperParameters\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "net = model.to(device)\n",
        "criterion = ...\n",
        "learning_rate = ...\n",
        "optimizer = ...\n",
        "num_epochs = ...\n",
        "\n",
        "# TODO : Rewrite your Training  and Validation Loop\n",
        "for epoch in range(num_epochs) : \n",
        "    running_loss_t,running_loss_v = 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(val_loader, 0):\n",
        "\n",
        "\n",
        "# TODO : Rewrite your Testing Loop\n",
        "with torch.no_grad():\n",
        "  running_loss = []\n",
        "  for i, data in enumerate(test_loader, 0):  \n",
        "\n",
        "\n",
        "# TODO :  Plot the last batch and the Reconstruction Errors"
      ],
      "metadata": {
        "id": "wUO71k8zBwCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFdBGGd3fURa"
      },
      "source": [
        "Hmm interesting.\n",
        "Let's compare the results :  For the same compressed space size (512, 128, 16, 1) :\n",
        "* What are the reconstruction values on the test set ? \n",
        "* What are the training time ?\n",
        "* Which model would you advice ? "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c - Deepening The Models\n",
        "\n",
        "All the models we've created are only composed of 3 layers : \n",
        "\n",
        "      input layer => hidden layer => output layer\n",
        "\n",
        "We can obviously stack more layers :    \n",
        "* Modify the Convolutional Encoder and the Decoder so that the AE becomes :     \n",
        "      input layer => hidden layer => hidden layer => hidden layer => output layer\n",
        "\n",
        "\n",
        "We want the first and last hidden layer to have the same size"
      ],
      "metadata": {
        "id": "QODNCGtvbvGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Modify the Encoder and the Decoder by adding one additional hidden layer. The size of the additionnal hidden layer can be greater than the previous one\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Conv Encoder Class\n",
        "    \"\"\"\n",
        "    def __init__(self,input_channel, output_channel, kernel_size = 3):\n",
        "        super().__init__()\n",
        "        self.input_channel = input_channel\n",
        "        self.output_channel = output_channel\n",
        "        self.kernel_size = kernel_size\n",
        "        self.model = ...\n",
        "\n",
        "    def forward(self,x):\n",
        "        # TODO :  Send the data through the model and return the output\n",
        "        output = \n",
        "        return\n",
        " \n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Conv Decoder Class\n",
        "    be careful with the output attribute \n",
        "    \"\"\"\n",
        "    def __init__(self,input_channel, output_channel, kernel_size = 3, output = True):\n",
        "        super().__init__()\n",
        "        self.input_channel = input_channel\n",
        "        self.output_channel = output_channel\n",
        "        self.kernel_size = kernel_size\n",
        "        self.output = output\n",
        "        self.model= \n",
        "\n",
        "                    \n",
        "    def forward(self,x):\n",
        "        # TODO :  Send the data through the model and return the output\n",
        "        output = \n",
        "        return\n",
        "\n",
        "\n",
        "\n",
        "# TODO : Recreate the AutoEncoder using the Encoder and Decoder \n",
        "class AutoEncoder_Conv(nn.Module):\n",
        "\n",
        "    def __init__(self,input_size,latent_size, output= True):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.latent_size = latent_size\n",
        "        self.output = output\n",
        "        self.model = \n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        # TODO :  Send the data through the model and return the output\n",
        "        output = \n",
        "        return\n",
        "\n",
        "\n",
        "\n",
        "# TODO : Print the new model\n",
        "print(AutoEncoder_Conv(1,128))\n"
      ],
      "metadata": {
        "id": "e_qBhpBxcjsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrain your Model for a Compressed Space of :       \n",
        "* 128 \n",
        "* 64 \n",
        "\n",
        "Compare the results"
      ],
      "metadata": {
        "id": "_fgaTc96eSA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Change your model \n",
        "model = \n",
        "\n",
        "# TODO : Reload your HyperParameters\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "net = model.to(device)\n",
        "criterion = ...\n",
        "learning_rate = ....\n",
        "optimizer = ....\n",
        "num_epochs =...\n",
        "# TODO : Rewrite your Training  and Validation Loop\n",
        "for epoch in range(num_epochs) : \n",
        "    running_loss_t,running_loss_v = 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(val_loader, 0):\n",
        "\n",
        "# TODO : Rewrite your Testing Loop\n",
        "with torch.no_grad():\n",
        "  running_loss = []\n",
        "  for i, data in enumerate(test_loader, 0):  \n",
        "\n",
        "# TODO :  Plot the last batch and the Reconstruction Errors\n"
      ],
      "metadata": {
        "id": "kr48TkqhArJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 - Where's that noise ?\n",
        "\n",
        "The second sprint is over, but we received a mail for the third sprint\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        " ðŸ”Š ðŸ”Š ðŸ”Š **Message from the Senior Data Scientist** ðŸ”Š ðŸ”Š ðŸ”Š\n",
        "\n",
        "Hi\n",
        "I read somewhere that AE can denoise image. That means that if you add some noise to the input image, the AE will be able to reconsctruct the image without noise. Can you verify that ?\n",
        "\n",
        "C.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1400/1*z7SUcHkWp7jT1D_SqvTvgA.png\" height=300>\n",
        "\n",
        "Ok let's verify that, we received a function that add Gaussian Noise to an input image."
      ],
      "metadata": {
        "id": "HHkG7AzeIUNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Using torch.randn_like, create some noise and return a noisy input\n",
        "def add_noise(inputs, noise_factor):\n",
        "     noise = \n",
        "     return  noise + ....\n",
        "\n",
        "\n",
        "# TODO : Pick an image from the test set and add noise to it \n",
        "test_image = ... # Pick an image from test dataset\n",
        "test_image = ... # Add noise\n",
        "\n",
        "# TODO : Send the Image through your model and plot the original image and the infered image\n",
        "denoised_image = model(...)\n",
        "fig,axarr = plt.subplots(1, 2)\n",
        "axarr[0].imshow(test_image.squeeze(0).squeeze(0).squeeze(0))\n",
        "axarr[1].imshow(denoised_image.detach().cpu().squeeze(0).squeeze(0).squeeze(0))\n"
      ],
      "metadata": {
        "id": "0FTrNKuaI8s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* What can you tell ?\n",
        "* Does it work with lots of noise ?"
      ],
      "metadata": {
        "id": "wKdCjPuwMhxA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 - Getting Some Colors (Optional)\n",
        "\n",
        "In this part, you will try all the things you've seen previously on a new Dataset. Instead of black and white images, here we have RGB colored images.\n",
        "\n",
        "You must :    \n",
        "* Check your Data\n",
        "* Create the Dataloaders\n",
        "* Create your Models\n",
        "* Train your model for different parameters\n",
        "* Test the model\n",
        "* Provide some quantitative results on the behavior of your models.\n"
      ],
      "metadata": {
        "id": "sbc21j0pezi4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwsvWzvg2kTe"
      },
      "source": [
        "This is the fourth and final sprint. After that we can send the model to production. Let's read Senior Data Scientist email \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        " ðŸ”Š ðŸ”Š ðŸ”Š **Message from the Senior Data Scientist** ðŸ”Š ðŸ”Š ðŸ”Š\n",
        "\n",
        "Hi,\n",
        "\n",
        "You are doing some good work! I like colors. We like colors. But do your model work on colors ? I'm asking the Data Engineer Team to send you the API for CIFAR10 so that you can test. Just reapply the same methodology and send me the results asap\n",
        "\n",
        "C.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a - CIFAR10 : Colors and Classes\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        " ðŸ”Š ðŸ”Š ðŸ”Š **Message from the Data Engineering Team** ðŸ”Š ðŸ”Š ðŸ”Š\n",
        "\n",
        "Hi,\n",
        "\n",
        "Here the API for the new dataset\n",
        "\n",
        "K.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Understanding the Data : Data Exploration\n",
        "\n",
        "Ok so let's do the same thing as befor Let's use their API.\n",
        "\n",
        "\n",
        "- What is the size of the train dataset ?\n",
        "- What are the elements available in one piece of data ? (image,label)\n",
        "- What is the shape of one piece of data ?\n",
        "- What is the type of one piece of data ?\n",
        "- Plot few elements of the dataset using Matplotlib.\n",
        "\n"
      ],
      "metadata": {
        "id": "mbY6LTflOZgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "dataset_train = CIFAR10(root='./data', train=True,download=True, transform=transform)\n",
        "dataset_test =  CIFAR10(root='./data', train=False,download=True, transform=transform)\n",
        "# TODO : Do all the things related to DATA here"
      ],
      "metadata": {
        "id": "fBRmB5DUD3wB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Do all the things related to MLP MODELs here"
      ],
      "metadata": {
        "id": "jYBJkBudD9S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Do all the things related to TRAINING here"
      ],
      "metadata": {
        "id": "x68ewYEUEBBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Don't forget to write your results and explanation in your report"
      ],
      "metadata": {
        "id": "RXFXKZZQEJSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Do all the things related to Conv MODELs here"
      ],
      "metadata": {
        "id": "iLeYUiRsEGCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Do all the things related to TRAINING here"
      ],
      "metadata": {
        "id": "7zbLOzXCEGCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Don't forget to write your results and explanation in your report"
      ],
      "metadata": {
        "id": "_274sHzHETsk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 - Results\n",
        "\n",
        "Now analyze your results and write your report.\n",
        "\n"
      ],
      "metadata": {
        "id": "aYj-oU52PGK8"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "AutoEncoder.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}