{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thad75/TP_ENSEA_ELEVE/blob/main/2A/Majeure%20Signal/AutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUZCOMw1Gem5"
      },
      "source": [
        "# Image Compression using AutoEncoders: A Deep Learning Task\n",
        "\n",
        "Time : 8h"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Goal of this lab\n",
        "\n",
        "* Get to know Deep Learning and PyTorch Framework\n",
        "* Learn how to compress images using AutoEncoders\n",
        "* Understand the differences between JPEG compression and Deep Learning for compression\n",
        "* Know how to read and use code given by someone else\n"
      ],
      "metadata": {
        "id": "mL9lLUJmpab6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parts of this lab\n",
        "\n",
        "The lab is constructed as a basic Data Science Pipeline as follows\n",
        "\n",
        "* 0 - Introduction and Documents Reading\n",
        "* 1 - Discovering a Dataset\n",
        "* 2 - Creating a Model\n",
        "* 3 - Training the Model\n",
        "* 4 - Testing the Model\n",
        "* 5 - Reporting the findings"
      ],
      "metadata": {
        "id": "NN6NsODyqGEw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc8OA-MQ6n09"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Disclaimer\n",
        "\n",
        "We will refer to :\n",
        "- AutoEncoder as AE\n",
        "- Multi Layer Perceptron as MLP\n",
        "\n",
        "Before beginning this lab, please make sure that your environment has a GPU. For that, go to : \n",
        "* Execution\n",
        "* Modifier le type d'execution\n",
        "* Accelerateur mat√©riel : GPU\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fup2OihC7Kkv"
      },
      "source": [
        "# 0 - Introduction\n",
        "\n",
        "So basically during the part 1 of this lab, we have seen JPEG Compression. JPEG compression is a general algorithm that can compress any image. Let's first see your understanding of the JPEG algorithm :\n",
        "* What are the component in the Encoding part of the algorithm ?\n",
        "* What are the component in the Decoding part of the algorithm ?\n",
        "* Is the down-sampling phase of JPEG linear ? (i.e : in a y = ax+b form)\n",
        "* Is it a lossless compression algorithm ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmPz4EM86n09"
      },
      "source": [
        "# Your Mission : AI for the Win\n",
        "\n",
        "\n",
        "Hi there, we are a Big Company and we need your help. We have some images that we want to compress. We tried the JPEG algorithm but we want to try some new state of the art methods. Your mission is to help us as a Data Scientist in this task by creating a DL model that compresses image with as less loss as possible. \n",
        "\n",
        "\n",
        "Alright, let's get started.\n",
        "\n",
        "<img src=\"https://i.pinimg.com/originals/16/b2/96/16b296afb78ec57d12c931bc72b42eec.gif\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "315B4XDj9ln-"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import MNIST, CIFAR10\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import skimage\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transform\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transform\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading the Docs \n",
        "\n",
        "Welcome to Big Company, as usual when beginning a new project you have some reading to do. Take 5-10 minutes to read the following documentation to understand something"
      ],
      "metadata": {
        "id": "2AKbYlYjUiw8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1iy5iLS6n0_"
      },
      "source": [
        "## What is Deep Learning ?\n",
        "\n",
        "Deep Learning is a branch of AI where you **teach a Model** a certain **task** using a **Dataset**. The model or a neural network is built by multiple consecutive **layers** of neuron-like units, remotely based on neurons in the human brain. Typically, many consecutive layers are used, that is why it is referred to as deep learning. In those layers, each neuron has several **parameters** (**weights**) that are updated during **training** by minimizing a **loss** (error) function, using **Stochastic Gradient Descent**. Besides the model parameters, to be found using a dataset, there are also **hyperparameters** that you have to tune by yourself, for example, how many layers used in your model, how many neurons per layer,.... The Model infers a prediction from an **input**. In fact, a Deep Neural Network can be seen as a complex function ${f}$ that maps the input data to a learned space from the Dataset. \n",
        "\n",
        "Note the bold words. These are the important things you need to understand about Deep Learning. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awLz7ozJ6n1A"
      },
      "source": [
        "## Generalities on AutoEncoder\n",
        "\n",
        "\n",
        "\"Autoencoding\" is a data compression algorithm where the compression and decompression functions are 1) data-specific, 2) lossy, and 3) learned automatically from examples rather than engineered by a human. In almost all contexts where the term \"autoencoder\" is used, the compression and decompression functions are implemented with neural networks.\n",
        "\n",
        "1) Autoencoders are data-specific, which means that they will only be able to compress data similar to what they have been trained on. \n",
        "\n",
        "2) Autoencoders are lossy.\n",
        "\n",
        "3) Autoencoders are learned automatically from data examples.\n",
        "\n",
        "To build an autoencoder, you need three things: an encoding function, a decoding function, and a distance function between the amount of information loss between the compressed representation of your data and the decompressed representation. In fact, we can look at the model as a big function :\n",
        "\n",
        "* The Encoder : This part of the model compresses the input image to a compressed version of it, where $f(x)= z$, where $x$ is the input image, and $z$ the compressed representation of it.\n",
        "* The Decoder : This part of the model decompresses the compressed representation $z$ to the decompressed image $\\tilde{x}$, in other terms we have a function $g$ where, $\\tilde{x} = g(z)$\n",
        "* The AutoEncoder : by stacking the Encoder and the Decoder, and as we want $\\tilde{x} = x$ (a.k.a the reconstructed image as similar as the input image), we can rewrite the AE as $\\tilde{x} = g(z) = g\\circ f(x)=  x$ where $g= f^{-1}$\n",
        "\n",
        "\n",
        "You will code two types of AE models :\n",
        "* MLP style\n",
        "* Conv style\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generalities on Deep Learning\n",
        "\n",
        "In this part, we are going to talk about important stuff in Deep Learning."
      ],
      "metadata": {
        "id": "jXLjegt6hTGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Layers\n",
        "\n",
        "A Layer is an important part of a Model. In fact, it is the key element of a DL Model. A Layer is a structure that takes information from a layer to pass them to the next layer. In a DL Network, each layer extracts features. "
      ],
      "metadata": {
        "id": "qhcd3QvKhXdj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Activation Functions\n",
        "\n",
        "An Activation Function is a function that is applied to the output of a Neural Layer. It is the equivalent of the excitation threshold for which a neuron reacts or not.\n"
      ],
      "metadata": {
        "id": "Z7pUFCRvhYuE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DLNHchj6n1B"
      },
      "source": [
        "# 1- Data : Exploring the Unknown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqws4UbZ6n1B"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "<img src=\"https://labelyourdata.com/img/article-illustrations/splitting_data.png\" height=200>\n",
        "\n",
        "\n",
        "When training  a DL model, we use a Dataset. The model uses the data to learn something for a task. We usually divide the data into Training, Validation, Test sets.\n",
        "- Training set is used to train the Model (i.e., to find the parameters of Model).\n",
        "- Validation set is used to watch the Model's training (to verify whether the training procedure goes well).\n",
        "- Test set is used to evaluate the performance of the Model (in our case, to measure if the model compresses and decompresses well new images).\n",
        "\n",
        "\n",
        "<img src=\"https://i.imgflip.com/653bu2.jpg\" height=400>\n",
        "\n",
        "**In our case of AE, we do not need the label of image. Our method is an unsupervised algorithm.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 - a - The first one : the Training set"
      ],
      "metadata": {
        "id": "TRKH2GO8PPKS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Understanding the Data : Data Exploration\n",
        "\n",
        "Ok let's have a look at what the Data Engineering Team sent us. Let's understand the Dataset. Let's use their API.\n",
        "\n",
        "\n",
        "- What is the size of the train dataset ?\n",
        "- What are the elements available in one piece of data ? (image,label)\n",
        "- What is the shape of one piece of data ?\n",
        "- What is the type of one piece of data ?\n",
        "- Plot few elements of the dataset using Matplotlib."
      ],
      "metadata": {
        "id": "2tqEC77hQ4ob"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOdefqiw6n1B"
      },
      "outputs": [],
      "source": [
        "# TODO: Load MNIST Train Dataset from TorchVision\n",
        "\n",
        "dataset = MNIST('', train=True, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "# TODO: What's the size of the Dataset ?\n",
        "# TODO: Retrieve one element of the Dataset ? What is the shape of one piece of Data ? \n",
        "\n",
        "size_of_dataset =  len(dataset)\n",
        "data = dataset[0]\n",
        "print(data[0].shape)\n",
        "\n",
        "# TODO: Plot the retrieved Data\n",
        "\n",
        "plt.imshow(data[0].permute(1, 2, 0)[...,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - b - The second one : the Test Dataset"
      ],
      "metadata": {
        "id": "IU_I7BipPEto"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsqbBFiz6n1C"
      },
      "source": [
        "As you can see, there's a train attribute to the MNIST Class. When it's set to True, you're loading the train Dataset. Hence, change it to false to load the test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVnRxxaa6n1C"
      },
      "outputs": [],
      "source": [
        "# TODO : Load the test dataset\n",
        "mnist_test =  MNIST('', train=False, download=True, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's verify that the Data in the Test dataset are in the same style of the Train Dataset :    \n",
        "- Plot few Data from the Test Dataset with its label.\n",
        "- Are the data similar ? Are the labels similar ?"
      ],
      "metadata": {
        "id": "y77InD1eSuQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: What's the size of the Dataset ?\n",
        "# TODO: Retrieve one element of the Dataset ? What is the shape of one piece of Data ? \n",
        "# TODO: Plot the retrieved Data\n",
        "size_of_dataset =  len(dataset)\n",
        "data = dataset[0]\n",
        "print(data[0].shape)\n",
        "\n",
        "\n",
        "plt.imshow(data[0].permute(1, 2, 0)[...,0])"
      ],
      "metadata": {
        "id": "ZGl0JVb9S75z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 - c - The third one : Creating the Validation Dataset"
      ],
      "metadata": {
        "id": "6x4LBC7HUk8S"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSbPGhqP6n1D"
      },
      "source": [
        "At this moment, we have a Train and a Test Dataset. We also like having a Validation Dataset. The validation dataset is often a smaller part of the training dataset.The Validation Dataset allows us to follow the models training. In fact, the data of the Validation Dataset is sent to the model while training.  However, no gradients are computed for the Validation Dataset Data resulting in no update on the weights.\n",
        "\n",
        "- What does 55000 and 5000 mean ?\n",
        "- Determine the split value of the training set to create the validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiGz4sBr6n1D"
      },
      "outputs": [],
      "source": [
        "# Questions : what does 55000 and 5000 mean ? Hint: look at the Dataset length and determine the split value\n",
        "mnist_train, mnist_val = random_split(dataset, [55000, 5000])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blh2vwZu6n1D"
      },
      "source": [
        "### 1 - d - Creating the Dataloader\n",
        "\n",
        "So the Dataset returns one element at a time. In DL, we like sending many items at the same time to the model. We form BATCH of Data using a DataLoader. Dataloader are an iterable over the dataset. It means that the Dataloader will form BATCH of Data for you and fetch them \n",
        "- Create a DataLoader for your Training, Valid and Testing Dataset\n",
        "- What is the drop_last attribute ?\n",
        "\n",
        "More information on dataloader : https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EM2xVJQ6n1D"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(mnist_train, batch_size=128,drop_last =True)\n",
        "val_loader = DataLoader(mnist_val, batch_size=128,drop_last =True)\n",
        "test_loader = DataLoader(mnist_test, batch_size= 32,drop_last = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Did the Data Engineer do a good work ?\n",
        "- Is there enough data ?\n",
        "- Are they easily accessible ?\n",
        "- Are they correctly labeled ?\n",
        "\n"
      ],
      "metadata": {
        "id": "eHI5FPtkbiY_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utu6siUB6n1D"
      },
      "source": [
        "# 2 - Creating the Model : The AutoEncoder\n",
        "\n",
        "Now that we saw what the data was and created our datasets, we need to fullfil our mission. We need a model.\n",
        "\n",
        "<img src=\"https://i.imgflip.com/640uob.jpg\" height=300>\n",
        "\n",
        "We are going to explore the path of AutoEncoders ! Alright let's write some readable codes. Our code must be modulable and easy to read. We should try two types of AutoEncoders :    \n",
        "- MLP Style\n",
        "- Conv Style\n",
        "\n",
        "- Use PyTorch and Create Modulable and Stackable Models that inherits from nn.Module\n",
        "- Choose wisely our Optimizer and Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjUHGbOi6n1E"
      },
      "source": [
        "## I - MLP Style : Exploring the Neurons\n",
        "\n",
        "<img src='https://www.researchgate.net/publication/344394387/figure/fig1/AS:974657746399232@1609387923440/Figure-Computational-Schematics-of-the-MLP-and-the-autoencoder.png'>\n",
        "\n",
        "We will first try a MLP AE.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating a Model in PyTorch\n",
        "\n",
        "Creating a model in PyTorch is simple. A PyTorch is an object that inherits from nn.Module. The pseudo-code is the following :     \n",
        "\n",
        "```\n",
        "class Model(nn.Module):\n",
        "  def __init__(self,...):\n",
        "    \"\"\"\"\n",
        "    Defines the model. You can put the input size as a parameter if needed..\n",
        "    \"\"\"\"\n",
        "    super().__init__() # to init the main class\n",
        "    self.layers = ... # defining the model : could be Conv2d, Linear, RNN, LSTM\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    \"\"\"\n",
        "    The input x is forwarded through the neural net. \n",
        "    \"\"\"\n",
        "    output = self.layers(x)\n",
        "    return output\n",
        "\n",
        "  # Other methods go down\n",
        "```\n",
        "\n",
        "More informations : https://pytorch.org/docs/stable/nn.html\n"
      ],
      "metadata": {
        "id": "UvnEBg0ahMa1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correcting the Mistakes\n",
        "\n",
        "First, we will try a really simple model :\n",
        "* an Input Dense Layer\n",
        "* a Latent Space\n",
        "* an Output Dense Layer\n",
        "\n",
        "\n",
        "We have received some codes from the other members of the Deep Learning Engineering Team. Looks like there are lots of mistakes.. Let's correct them."
      ],
      "metadata": {
        "id": "T730pWdwLRXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Correct the Following Class. \n",
        "# Hint : Look at the input, output size, the activations, how the data is forwarded ...\n",
        "\n",
        "class AutoEncoder_MLP(nn.Module):\n",
        "  def __init__(self, input_size, compressed_space_size):\n",
        "    \"\"\"\n",
        "    The model is an Input Layer, a Hidden Layer and an Output layer \n",
        "    \"\"\"\n",
        "    super().__init__() \n",
        "    # Init the class attributes\n",
        "    self.input_size = input_size\n",
        "    self.output_size = input_size\n",
        "    self.compressed_space_size = compressed_space_size\n",
        "    # Init the model\n",
        "    self.input = nn.Sequential(nn.Linear(self.input_size, self.compressed_space_size),\n",
        "                               nn.ReLU()) \n",
        "    self.output = nn.Sequential(nn.Linear(self.compressed_space_size,self.output_size ),\n",
        "                               nn.Sigmoid())\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    \"\"\"\n",
        "    The input x is forwarded through the neural net. \n",
        "    \"\"\"\n",
        "    compressed_image = self.input(x)\n",
        "    decompressed_image = self.output(compressed_image)\n",
        "    return decompressed_image\n"
      ],
      "metadata": {
        "id": "bxvGXm9rLx2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Create an Instance of the Model by calling the Class with the correct values\n",
        "model = AutoEncoder_MLP(28*28,128)\n",
        "\n",
        "# TODO : Print the model.\n",
        "print(model)"
      ],
      "metadata": {
        "id": "YSb86xStr3gK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2732a9d1-e50f-4c0e-a5c5-8fc4b88e39cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoEncoder_MLP(\n",
            "  (input): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (output): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=784, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N8KQNJy6n1F"
      },
      "source": [
        "# 3 - Training\n",
        "\n",
        "We can train the model. We have a Model and a Dataset. We need few more things..\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3- a - A Loss\n",
        "\n",
        "We need a Loss Function. The Loss function must tell us how far our predictions are from the labels (or not ?). It could be by comparing the distribution of two input datas, or by directly comparing the datas using distances .\n",
        "\n",
        "Let's reason. We are recreating an Image from its compressed version and we want that the recreated image must be as similar as the original image. i.e $\\tilde{x} = x$\n",
        "\n",
        "<img src=\"https://i.imgflip.com/653jbl.jpg\" height=400>\n"
      ],
      "metadata": {
        "id": "5MqMXbQw_1Kr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- How can you calculate the similarity between two vectors ?\n",
        "- What type of loss do you know that calculates the **distance** between two inputs ?\n",
        "\n",
        "More informations : https://pytorch.org/docs/stable/nn.html#loss-functions"
      ],
      "metadata": {
        "id": "cjJwaIhlVrWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Load the needed loss function\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "Am2fuauUBoUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 - b - An Optimizer\n",
        "\n",
        "<img src=\"https://i.imgflip.com/640sfs.jpg\" height= 400>\n",
        "\n",
        "We need something to update the weights of the model. In fact, we need to perform Gradient Descent to recalculate the weights of each layers regarding the model's predictions. The optimizer will search for an Optimum. However, it needs a step to perform this research. This step is called the Learning Rate. The learning rate has a huge effect on the learning. \n",
        "\n",
        "<img src=https://miro.medium.com/max/918/0*uIa_Dz3czXO5iWyI. height =300>\n",
        "\n",
        "In this case, we will use Adam Optimizer as it is a really efficient Optimizer. Don't hesitate to have a look at the other optimizers. \n",
        "\n",
        "More informations : https://pytorch.org/docs/stable/optim.html"
      ],
      "metadata": {
        "id": "vdJa2rgV___i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : define a small learning rate\n",
        "learning_rate = 1e-3\n",
        "\n",
        "# TODO : load the Adam optimizer in the optimizer variable\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate )"
      ],
      "metadata": {
        "id": "7lykHsQ-HrMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 - c - Training\n",
        "\n",
        "Now that we have everything that is needed for training, we have to create the training loop. We need hyperparameters, parameters that controls the learning. We also need to send the model and the data to the gpu for accelerated computation.\n",
        "\n",
        "\n",
        "The loop consists of :\n",
        "* Sending Data through the model to obtain Predictions\n",
        "* Computing the Loss \n",
        "* Backwarding the Loss using Gradients \n",
        "* Logging the losses and accuracies (if exists)\n",
        "\n",
        "\n",
        "The number of epochs is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset.\n",
        "\n",
        "Think of it as you trying to answer an exercise : the first time you won't understand, the second time you'll suceed more, and so on.."
      ],
      "metadata": {
        "id": "9sVerRhLIdpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre Defined and Useful variables\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' # To send to the gpu\n",
        "mini_batches_print = 10 # To print every 10 mini batches\n",
        "# TODO : Send the model to the device using .to\n",
        "net = model.to(device)\n",
        "\n",
        "# TODO : Define your number of epochs\n",
        "num_epochs = 20\n",
        "\n",
        "loss_train , loss_val = [], []\n",
        "for epoch in range(num_epochs) : \n",
        "    running_loss_t,running_loss_v = 0.0, 0.0\n",
        "    # TODO : Create your Training Loop\n",
        "    for i, data in enumerate(train_loader, 0): \n",
        "        # TODO : load the data into two variables\n",
        "        image, label = data\n",
        "        # TODO : reshape the input image so that it fit the input layers neuron numbers. Don't forget the Batch Size, the 1rst dimension must always be the Batch Size\n",
        "        image_reshaped, label = image.view(image.shape[0],-1).to(device), data[1]\n",
        "        optimizer.zero_grad()\n",
        "        # TODO : send the image to the model\n",
        "        outputs = net(image_reshaped)\n",
        "        # TODO/Questions : Do we need to reshape the input image ? If yes, reshape the image\n",
        "        outputs = outputs.view(image.shape)\n",
        "        # TODO : Compute the loss\n",
        "        loss = criterion(outputs, image.to(device))\n",
        "       \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss_t += loss.item()\n",
        "        if i == mini_batches_print :\n",
        "          running_loss_t= running_loss_t/mini_batches_print  \n",
        "          print('training loss is :',running_loss_t)\n",
        "          loss_train.append(running_loss_t)      \n",
        "    # TODO : Create your Validation Loop\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(val_loader, 0):    \n",
        "        # TODO : Do the same as the Train loop but delete everything related to weight update (optimizer, loss backwards ...)\n",
        "        image, label = data[0].view(data[0].shape[0],-1).to(device), data[1]\n",
        "        outputs = net(image)\n",
        "        outputs = outputs.view(data[0].shape)\n",
        "        loss = criterion(outputs, data[0].to(device))\n",
        "        \n",
        "        running_loss_v += loss.item()\n",
        "        if i == mini_batches_print :\n",
        "            running_loss_v= running_loss_v/mini_batches_print \n",
        "            print('validation loss is :',running_loss_v)\n",
        "            loss_val.append(running_loss_v)"
      ],
      "metadata": {
        "id": "v_9nrxJj7Bj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3 - d - Did it learn somethin' ?\n",
        "\n",
        "As you might see we've logged into two lists (train_loss, val_loss) the losses computed while training. Let's plot them (Don't forget to put Titles and Axis)\n",
        "- How can you tell that the training is over ?"
      ],
      "metadata": {
        "id": "KP7wfVDTVNn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : plot the train and val loss on the same graph using matplotlib.pyplot \n",
        "\n",
        "plt.plot(loss_train)\n",
        "plt.plot(loss_val)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "myd0mSIkVc7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 - Testing the Compression\n",
        "\n",
        "Now that we trained our model, let's test it on the test dataset. What does testing mean ? Wait there's an email from the senior Data Scientist :\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        " üîä üîä üîä **Message from the Senior Data Scientist** üîä üîä üîä\n",
        "\n",
        "Sup' heard you've trained your model. \n",
        "Ok so let's test it, shall we ?\n",
        "Take the test dataloader, iterate through it and send the test data to the model. We need to check how well the decompressed image is..\n",
        "Don't forget to delete all gradients calculations, it takes time and space for nothing. \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6rFLeJkes8Ll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4 - a - Testing on the Test Dataset\n"
      ],
      "metadata": {
        "id": "lT6XTkXKtLC6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interesting, the Senior talked about deleting all gradient calculations \n",
        "* Why must we not compute the gradients for the testing step ?"
      ],
      "metadata": {
        "id": "FISqPpOGuGHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(img,name= 'GT'):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.title(name)\n",
        "    plt.show()\n",
        "\n",
        "# TODO : form your testing loop.\n",
        "with torch.no_grad():\n",
        "  losses = 0\n",
        "  for i, data in enumerate(test_loader, 0):    \n",
        "    image, label = data[0].view(data[0].shape[0],-1).to(device), data[1]\n",
        "    outputs = net(image)\n",
        "    outputs = outputs.view(data[0].shape)\n",
        "    loss = criterion(outputs, data[0].to(device))\n",
        "    losses += loss\n",
        "\n",
        "# Plot the last batch\n",
        "imshow(torchvision.utils.make_grid(outputs.detach().cpu()),'Pred')\n",
        "imshow(torchvision.utils.make_grid(data[0]),'GT')\n",
        "\n",
        "# TODO : Print the difference in decompression and write it somewhere\n",
        "print('The difference between the Real Images and the Decompressed Images is: ',losses)"
      ],
      "metadata": {
        "id": "1AB-kxbEtIbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jak6Xd8h6n1F"
      },
      "source": [
        "Ok now to see the effect of the compression, change the latent_size to different values. For example try : 512, 128, 16, 1.\n",
        "\n",
        "\n",
        "<img src=\"https://i.imgflip.com/64elyi.jpg\" height=200>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Change your model, Test for differents size of Compressed Space Size. We advice you to try 1, 128, 512\n",
        "model = AutoEncoder_MLP(28*28,2048)\n",
        "# Train it\n",
        "num_epochs = 20\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "net = model.to(device)\n",
        "criterion = nn.MSELoss()\n",
        "learning_rate = 1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate )\n",
        "for epoch in range(num_epochs) : \n",
        "    running_loss_t,running_loss_v = 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0): \n",
        "        # TODO : load the data into two variables\n",
        "        image, label = data\n",
        "        # TODO : reshape the input image so that it fit the input layers neuron numbers. Don't forget the Batch Size, the 1rst dimension must always be the Batch Size\n",
        "        image, label = data[0].view(data[0].shape[0],-1).to(device), data[1]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(image)\n",
        "        outputs = outputs.view(data[0].shape)\n",
        "        loss = criterion(outputs, data[0].to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss_t += loss.item()\n",
        "        if i == 50:\n",
        "          running_loss_t= running_loss_t/50\n",
        "          print('training loss is :',loss)\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(val_loader, 0):    \n",
        "        image, label = data[0].view(data[0].shape[0],-1).to(device), data[1]\n",
        "        outputs = net(image)\n",
        "        outputs = outputs.view(data[0].shape)\n",
        "        loss = criterion(outputs, data[0].to(device))\n",
        "        running_loss_v += loss.item()\n",
        "        if i == 50:\n",
        "            running_loss_v= running_loss_v/50\n",
        "            print('validation loss is :',loss)\n",
        "\n",
        "# Test it\n",
        "\n",
        "with torch.no_grad():\n",
        "  running_loss = []\n",
        "  for i, data in enumerate(test_loader, 0):    \n",
        "    image, label = data[0].view(data[0].shape[0],-1).to(device), data[1]\n",
        "    outputs = net(image)\n",
        "    outputs = outputs.view(data[0].shape)\n",
        "\n",
        "    loss = criterion(outputs, data[0].to(device))\n",
        "    running_loss.append(loss)\n",
        "\n",
        "# Plot the last batch\n",
        "imshow(torchvision.utils.make_grid(outputs.detach().cpu()),'Pred')\n",
        "imshow(torchvision.utils.make_grid(data[0]),'GT')\n",
        "sum(running_loss)"
      ],
      "metadata": {
        "id": "wRMKAqZdzrVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4 - b - Testing on unseen Data\n",
        "\n",
        "Alright, we can obsviously say that it works pretty fairly on the Test Data. We should be ok nah ?\n",
        "\n",
        "Let's test it on other Data.\n",
        "\n",
        "* Write the code to test the inference on Images taken from the internet."
      ],
      "metadata": {
        "id": "d4dirY6mE_Sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Test some images from the internet to see the compression effect \n",
        "image_filename = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQLwsAJaf0m-QmpP056GQMqvY3jTD6cF6FU7Q&usqp=CAU\"\n",
        "image_numpy = cv2.cvtColor(skimage.io.imread(image_filename ),cv2.COLOR_BGR2GRAY)\n",
        "transform=transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Resize((28,28))])\n",
        "\n",
        "# TODO : Transform the images and add a dimension for the batch size using unsqueeze\n",
        "image = transform(image_numpy).unsqueeze(0)\n",
        "\n",
        "#TODO : Send the model to the model and process the prediction\n",
        "pred = model(image.view(1,-1).to(device))\n",
        "pred = pred.view(image.shape).squeeze(0).squeeze(0)\n",
        "\n",
        "#TODO : Plot dem results'\n",
        "fig,axarr = plt.subplots(1, 2)\n",
        "axarr[0].imshow(pred.detach().cpu().numpy())\n",
        "axarr[1].imshow(image.squeeze(0).squeeze(0))\n"
      ],
      "metadata": {
        "id": "z8GcBFKAFCqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* What can you say ?"
      ],
      "metadata": {
        "id": "0UhnIMewpF5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 - Write your Research\n",
        "\n",
        "Now we need to present our results to the Senior Data Scientist. \n",
        "* Sum up all your research on this subject in 2 pages.\n",
        "\n",
        "You must explain :\n",
        "* The dataset you used \n",
        "* The tests you did\n",
        "* The models you tested\n",
        "* The results you had\n",
        "* The explanation of the results (why it works, why it doesn't)\n",
        "* How can we compute the compression rate of the model ? \n",
        "* Do we need to consider the model's size ?"
      ],
      "metadata": {
        "id": "J8Ma8YUNE3So"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II - Convolutional Layer Style : Seeing a Region\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1838/1*LSYNW5m3TN7xRX61BZhoZA.png\" height = 300>\n",
        "\n",
        "The first sprint is over. The Senior Data Scientist sent a new message üáÆ\n",
        "\n",
        "\n",
        "---\n",
        " üîä üîä üîä **Message from the Senior Data Scientist** üîä üîä üîä\n",
        "\n",
        "\n",
        "Sup'\n",
        "\n",
        "Good work for your first results. However, we need to try another type of model.\n",
        "Test the same using Conv2d layers. I know that it is new for you but here are some explanations:  Convolutional Layers are filters that \"scans\" the input image in order to extract features. \n",
        "\n",
        "I sent you some classes that you must reuse in your code. Tell me if it has better results.\n",
        "\n",
        "Peace\n",
        "\n",
        "Senior Data Scientist\n",
        "\n",
        "P.S here's a funny image for ya \n",
        "\n",
        "<img src=\"https://i.imgflip.com/65b89l.jpg\" height=400>\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "i1kpRMLuU9_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO : Need more exaplanation on conv layers"
      ],
      "metadata": {
        "id": "B5crmvSMbkMN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take 5 minutes and play with the following link :   \n",
        "\n",
        "* https://ezyang.github.io/convolution-visualizer/\n",
        "\n",
        "Questions :    \n",
        "* What is the stride parameter ?\n",
        "* What is the padding parameter ?\n",
        "* What does it change on the output to increase the Kernel Size ?\n"
      ],
      "metadata": {
        "id": "ibihGUzZ-C00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some Definition\n",
        "\n",
        "Receptive Field : The receptive field are the pixels seen by the kernel layer"
      ],
      "metadata": {
        "id": "CC7RbnN1dKiW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Model Definition : The code they sent us\n",
        "\n",
        "Hmmm let's have a look at the model sent by the senior Data Scientist. Looks like there are bunch of submodules   "
      ],
      "metadata": {
        "id": "6v_cYtuufVur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 - a - SubModules : The stem"
      ],
      "metadata": {
        "id": "FiDIW6xzfURZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conv Down\n",
        "\n",
        "ConvDown is used to compress the input image. It applies a convolution between the input image and the kernel. In fact, it is used to extract features. Our ConvDown Model will be composed of two layers :     \n",
        "* Conv2d layer\n",
        "* Non Linearity (ReLU)\n",
        "\n",
        "<img src=\"https://www.jeremyjordan.me/content/images/2017/07/no_padding_no_strides.gif\">"
      ],
      "metadata": {
        "id": "6aR_6-5AfURZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30AE171_fURZ"
      },
      "outputs": [],
      "source": [
        "class ConvDown(nn.Module):\n",
        "\n",
        "    def __init__(self, input_channel, output_channel, kernel_size = 3):\n",
        "        super().__init__()\n",
        "        self.input_channel = input_channel\n",
        "        self.output_channel = output_channel\n",
        "        self.kernel_size = kernel_size\n",
        "        self.model = nn.Sequential(nn.Conv2d(self.input_channel, self. output_channel, kernel_size =self.kernel_size ),\n",
        "                                    nn.ReLU())\n",
        "                                    \n",
        "    def forward(self,x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conv Up\n",
        "\n",
        "ConvUp is used to decompress the input image. In fact, it uses extracted features to propose a reconstructed output feature map.\n",
        "\n",
        "* From what you've seen on the website, is it possible to increase output size map using Conv2d layers ?\n",
        "\n",
        "We introduce ConvTranpose2D layers, that applies Transpose Convolution over an input image. It also means that these layers upsamples the input image. In fact the ConvTranspose layers learns to upsample the images.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1400/1*HnxnJDq-IgsSS0q3Lut4xA.gif\" height=300>"
      ],
      "metadata": {
        "id": "RTj9S6BdfURZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iup_9vP8fURZ"
      },
      "outputs": [],
      "source": [
        "class ConvUp(nn.Module):\n",
        "    \"\"\"\n",
        "    ConvUp stacks a Conv2d layer with an Activation \n",
        "    If output is True : the Activation is Sigmoid\n",
        "    If output is False : the Activation is ReLU\n",
        "    \"\"\"\n",
        "    def __init__(self, input_channel, output_channel, kernel_size = 3 , output = True):\n",
        "        super().__init__()\n",
        "        self.input_channel = input_channel\n",
        "        self.output_channel = output_channel\n",
        "        self.kernel_size = kernel_size\n",
        "        self.output = output\n",
        "        self.model = nn.Sequential(nn.ConvTranspose2d(self.input_channel, self. output_channel, kernel_size =self.kernel_size ),\n",
        "                                    nn.ReLU()) if output is False else nn.Sequential(nn.ConvTranspose2d(self.input_channel, self. output_channel, kernel_size =self.kernel_size ),\n",
        "                                    nn.Sigmoid())\n",
        "        \n",
        "    def forward(self,x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HtHKDLzQXGAZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 - b - Modules : The Wrappers"
      ],
      "metadata": {
        "id": "xKSienu_fURZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoder\n",
        "\n",
        "The encoder stacks multiple ConvDown to compress and extract features.\n",
        "\n",
        "<img src=\"https://i.imgflip.com/65bqe0.jpg\" height=300>"
      ],
      "metadata": {
        "id": "add5ul-BfURZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJg8gNNPfURZ"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self,input_channel, output_channel, kernel_size = 3):\n",
        "        super().__init__()\n",
        "        self.input_channel = input_channel\n",
        "        self.output_channel = output_channel\n",
        "        self.kernel_size = kernel_size\n",
        "        self.model = nn.Sequential( ConvDown(self.input_channel, self.output_channel,self.kernel_size))\n",
        "                    \n",
        "    def forward(self,x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decoder\n",
        "\n",
        "The decoder stacks multiple ConvUp to decompress and upsample the input.\n",
        "\n",
        "<img src=\"https://i.imgflip.com/65br5o.jpg\" height=300>"
      ],
      "metadata": {
        "id": "-Ty_eE8ufURa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOIjpP5JfURa"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self,input_channel, output_channel, kernel_size = 3, output = True):\n",
        "        super().__init__()\n",
        "        self.input_channel = input_channel\n",
        "        self.output_channel = output_channel\n",
        "        self.kernel_size = kernel_size\n",
        "        self.output = output\n",
        "        self.model = nn.Sequential( ConvUp(self.input_channel,self.input_channel,self.kernel_size, output))\n",
        "                    \n",
        "    def forward(self,x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 - c - The Conv AutoEncoder : Final Model \n",
        "\n",
        "Stack the Encoder and Decoder, we just have to stack them in order to form the AutoEncoder. The stacking is different here as we refer to the input and output channels of each layers.\n"
      ],
      "metadata": {
        "id": "IuUrSK7QfURa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGslcjwafURa"
      },
      "outputs": [],
      "source": [
        "class AutoEncoder_Conv(nn.Module):\n",
        "\n",
        "    def __init__(self,input_size,latent_size, output= True):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.latent_size = latent_size\n",
        "        self.output = output\n",
        "        self.model = nn.Sequential(Encoder(self.input_size,self.latent_size),\n",
        "                                   Decoder(self.latent_size, self.input_size, output= True))\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.model(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxIt_IxgfURa"
      },
      "source": [
        "# 2 -Training and Testing \n",
        "\n",
        "We can reuse the previously written code. However, we need to make some changes...\n",
        "\n",
        "* What changes must we do ?\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Change your model \n",
        "model = AutoEncoder_Conv(1,128)\n",
        "# TODO : Reload your HyperParameters\n",
        "num_epochs = 20\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "net = model.to(device)\n",
        "criterion = nn.MSELoss()\n",
        "learning_rate = 1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate )\n",
        "\n",
        "# TODO : Rewrite your Training Loop\n",
        "for epoch in range(num_epochs) : \n",
        "    running_loss_t,running_loss_v = 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0): \n",
        "        # TODO : load the data into two variables\n",
        "        image, label = data\n",
        "        # TODO : reshape the input image so that it fit the input layers neuron numbers. Don't forget the Batch Size, the 1rst dimension must always be the Batch Size\n",
        "        image, label = data[0].to(device), data[1]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(image)\n",
        "        #outputs = outputs.view(data[0].shape)\n",
        "        loss = criterion(outputs, data[0].to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss_t += loss.item()\n",
        "        if i == 50:\n",
        "          running_loss_t= running_loss_t/50\n",
        "          print('training loss is :',loss)\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(val_loader, 0):    \n",
        "        image, label = data[0].to(device), data[1]\n",
        "        outputs = net(image)\n",
        "        #outputs = outputs.view(data[0].shape)\n",
        "        loss = criterion(outputs, data[0].to(device))\n",
        "        running_loss_v += loss.item()\n",
        "        if i == 50:\n",
        "            running_loss_v= running_loss_v/50\n",
        "            print('validation loss is :',loss)\n",
        "\n",
        "# TODO : Rewrite your Testing Loop\n",
        "\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  running_loss = []\n",
        "  for i, data in enumerate(test_loader, 0):    \n",
        "    image, label = data[0].to(device), data[1]\n",
        "    outputs = net(image)\n",
        "    loss = criterion(outputs, data[0].to(device))\n",
        "    print(loss)\n",
        "    running_loss.append(loss)\n",
        "\n",
        "# Plot the last batch\n",
        "imshow(torchvision.utils.make_grid(outputs.detach().cpu()),'Pred')\n",
        "imshow(torchvision.utils.make_grid(data[0]),'GT')\n",
        "sum(running_loss)"
      ],
      "metadata": {
        "id": "wUO71k8zBwCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFdBGGd3fURa"
      },
      "source": [
        "Hmm interesting.\n",
        "Let's compare the results :  For the same compressed space size (512, 128, 16, 1) :\n",
        "* What are the reconstruction values on the test set ? \n",
        "* What are the training time ?\n",
        "* Which model would you advice ? "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Deepening The Models\n",
        "\n",
        "All the models we've created are only composed of 3 layers : \n",
        "\n",
        "      input layer => hidden layer => output layer\n",
        "\n",
        "We can obviously stack more layers :    \n",
        "* Modify the Convolutional Encoder and the Decoder so that the AE becomes :     \n",
        "      input layer => hidden layer => hidden layer => hidden layer => output layer\n",
        "\n",
        "\n",
        "We want the first and last hidden layer to have the same size"
      ],
      "metadata": {
        "id": "QODNCGtvbvGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self,input_channel, output_channel, kernel_size = 3):\n",
        "        super().__init__()\n",
        "        self.input_channel = input_channel\n",
        "        self.output_channel = output_channel\n",
        "        self.kernel_size = kernel_size\n",
        "        self.model = nn.Sequential( ConvDown(self.input_channel, self.input_channel*2,self.kernel_size),\n",
        "                                   ConvDown(self.input_channel*2, self.output_channel,self.kernel_size))\n",
        "                    \n",
        "    def forward(self,x):\n",
        "        return self.model(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self,input_channel, output_channel, kernel_size = 3, output = True):\n",
        "        super().__init__()\n",
        "        self.input_channel = input_channel\n",
        "        self.output_channel = output_channel\n",
        "        self.kernel_size = kernel_size\n",
        "        self.output = output\n",
        "        self.model = nn.Sequential( ConvUp(self.input_channel,self.output_channel*2,self.kernel_size, False),\n",
        "                                   ConvUp(self.output_channel*2,self.output_channel,self.kernel_size, output))\n",
        "                    \n",
        "    def forward(self,x):\n",
        "        return self.model(x)\n",
        "\n",
        "class AutoEncoder_Conv(nn.Module):\n",
        "\n",
        "    def __init__(self,input_size,latent_size, output= True):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.latent_size = latent_size\n",
        "        self.output = output\n",
        "        self.model = nn.Sequential(Encoder(self.input_size,self.latent_size),\n",
        "                                   Decoder(self.latent_size, self.input_size, output= True))\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.model(x)\n",
        "\n",
        "print(AutoEncoder_Conv(1,128))\n"
      ],
      "metadata": {
        "id": "e_qBhpBxcjsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrain your Model for a Compressed Space of 128 and 64. \n",
        "\n",
        "* Compare the results"
      ],
      "metadata": {
        "id": "_fgaTc96eSA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 - Where's that noise ?\n",
        "\n",
        "The second sprint is over, but we received a mail for the third sprint\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        " üîä üîä üîä **Message from the Senior Data Scientist** üîä üîä üîä\n",
        "\n",
        "Sup'\n",
        "I read somewhere that AE can denoise image. That means that if you add some noise to the input image, the AE will be able to reconsctruct the image without noise. Can you verify that ?\n",
        "\n",
        "Senior Data Scientist\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1400/1*z7SUcHkWp7jT1D_SqvTvgA.png\" height=300>\n",
        "\n",
        "Ok let's verify that, we received a function that add Gaussian Noise to an input image."
      ],
      "metadata": {
        "id": "HHkG7AzeIUNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_noise(inputs):\n",
        "     noise = torch.randn_like(inputs)*0.2\n",
        "     return inputs + noise\n",
        "\n",
        "test_image = mnist_test.__getitem__(2)[0]\n",
        "test_image = add_noise(test_image.unsqueeze(0))\n",
        "denoised_image = model(test_image.to(device))\n",
        "fig,axarr = plt.subplots(1, 2)\n",
        "axarr[0].imshow(test_image.squeeze(0).squeeze(0).squeeze(0))\n",
        "axarr[1].imshow(denoised_image.detach().cpu().squeeze(0).squeeze(0).squeeze(0))\n"
      ],
      "metadata": {
        "id": "0FTrNKuaI8s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* What can you tell ?\n",
        "* Does it work with lots of noise ?"
      ],
      "metadata": {
        "id": "wKdCjPuwMhxA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III - Getting Some Colors (Optional)"
      ],
      "metadata": {
        "id": "sbc21j0pezi4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwsvWzvg2kTe"
      },
      "source": [
        "This is the fourth and final sprint. After that we can send the model to production. Let's read Senior Data Scientist email \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        " üîä üîä üîä **Message from the Senior Data Scientist** üîä üîä üîä\n",
        "\n",
        "Sup'\n",
        "\n",
        "I like colors. We like colors. But do your model work on colors ? I'm asking the Data Engineer Team to send you the API for CIFAR10 so that you can test. Just reapply the same methodology and send me the results asap\n",
        "\n",
        "Kiss kiss XOXO\n",
        "\n",
        "Senior Data Scientist\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - CIFAR10 : Colors and Classes\n",
        "\n",
        " üîä üîä üîä **Message from the Data Engineering Team** üîä üîä üîä\n",
        "\n",
        "Wazzaaaaaaaaa, the API is ready.\n",
        "Have a good day :D\n",
        "\n",
        "Data Engineering Team"
      ],
      "metadata": {
        "id": "mbY6LTflOZgg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding the Data : Data Exploration\n",
        "\n",
        "Ok so let's do the same thing as befor Let's use their API.\n",
        "\n",
        "\n",
        "- What is the size of the train dataset ?\n",
        "- What are the elements available in one piece of data ? (image,label)\n",
        "- What is the shape of one piece of data ?\n",
        "- What is the type of one piece of data ?\n",
        "- Plot few elements of the dataset using Matplotlib.\n",
        "\n"
      ],
      "metadata": {
        "id": "S34WeEbJPGK7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2WyoXz9PGK7"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "dataset_train = CIFAR10(root='./data', train=True,download=True, transform=transform)\n",
        "dataset_test =  CIFAR10(root='./data', train=False,download=True, transform=transform)\n",
        "\n",
        "# TODO : Do all the Data Exploration Things. \n",
        "# Questions : How similar are the data ? Coding Wise ? Data Wise ?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Create the DataLoaders\n",
        "train_loader = DataLoader(dataset_train, batch_size=128,drop_last =True)\n",
        "test_loader = DataLoader(dataset_test, batch_size= 32,drop_last = True)"
      ],
      "metadata": {
        "id": "9g7qvT8LQC9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcWK-oqlPGK8"
      },
      "source": [
        "###  2 - Train and Test your MLP Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkplU-q6PGK8"
      },
      "outputs": [],
      "source": [
        "# TODO : Create you\n",
        "model = AutoEncoder_MLP(32*32*3,1024)\n",
        "# TODO : Reload your HyperParameters\n",
        "num_epochs = 20\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "net = model.to(device)\n",
        "criterion = nn.MSELoss()\n",
        "learning_rate = 1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate )\n",
        "\n",
        "# TODO : Rewrite your Training Loop\n",
        "for epoch in range(num_epochs) : \n",
        "    running_loss_t,running_loss_v = 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0): \n",
        "        # TODO : load the data into two variables\n",
        "        image, label = data\n",
        "       # print(image.shape)\n",
        "        # TODO : reshape the input image so that it fit the input layers neuron numbers. Don't forget the Batch Size, the 1rst dimension must always be the Batch Size\n",
        "        image, label = data[0].view(data[0].shape[0],-1).to(device), data[1]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(image)\n",
        "        outputs = outputs.view(data[0].shape)\n",
        "        loss = criterion(outputs, data[0].to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss_t += loss.item()\n",
        "        if i == 50:\n",
        "          running_loss_t= running_loss_t/50\n",
        "          print('training loss is :',loss)\n",
        "# TODO : Rewrite your Testing Loop\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transform\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "with torch.no_grad():\n",
        "  running_loss = []\n",
        "  for i, data in enumerate(test_loader, 0):    \n",
        "        image, label = data[0].view(data[0].shape[0],-1).to(device), data[1]\n",
        "        outputs = net(image)\n",
        "        outputs = outputs.view(data[0].shape)\n",
        "        loss = criterion(outputs, data[0].to(device))\n",
        "  running_loss.append(loss)\n",
        "\n",
        "# Plot the last batch\n",
        "imshow(torchvision.utils.make_grid(outputs.detach().cpu()),'Pred')\n",
        "imshow(torchvision.utils.make_grid(data[0]),'GT')\n",
        "sum(running_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3 - Train and Test your Conv Model"
      ],
      "metadata": {
        "id": "ed9ilPtLSAQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Create you\n",
        "model = AutoEncoder_Conv(3,512)\n",
        "# TODO : Reload your HyperParameters\n",
        "num_epochs = 20\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "net = model.to(device)\n",
        "criterion = nn.MSELoss()\n",
        "learning_rate = 1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate )\n",
        "\n",
        "# TODO : Rewrite your Training Loop\n",
        "for epoch in range(num_epochs) : \n",
        "    running_loss_t,running_loss_v = 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0): \n",
        "        # TODO : load the data into two variables\n",
        "        image, label = data\n",
        "        # TODO : reshape the input image so that it fit the input layers neuron numbers. Don't forget the Batch Size, the 1rst dimension must always be the Batch Size\n",
        "        image, label = data[0].to(device), data[1]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(image)\n",
        "        #outputs = outputs.view(data[0].shape)\n",
        "        loss = criterion(outputs, data[0].to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss_t += loss.item()\n",
        "        if i == 50:\n",
        "          running_loss_t= running_loss_t/50\n",
        "          print('training loss is :',loss)\n",
        "\n",
        "# TODO : Rewrite your Testing Loop\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transform\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "with torch.no_grad():\n",
        "  running_loss = []\n",
        "  for i, data in enumerate(test_loader, 0):    \n",
        "    image, label = data[0].to(device), data[1]\n",
        "    outputs = net(image)\n",
        "    loss = criterion(outputs, data[0].to(device))\n",
        "    print(loss)\n",
        "    running_loss.append(loss)\n",
        "\n",
        "# Plot the last batch\n",
        "imshow(torchvision.utils.make_grid(outputs.detach().cpu()),'Pred')\n",
        "imshow(torchvision.utils.make_grid(data[0]),'GT')\n",
        "sum(running_loss)"
      ],
      "metadata": {
        "id": "P9pCUMS_SA78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 - Results\n",
        "\n",
        "Now analyze your results and write your report.\n",
        "\n"
      ],
      "metadata": {
        "id": "aYj-oU52PGK8"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "AutoEncoder.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}