{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to DL.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM55R0cMy3AyQIRW2amPwCy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thad75/TP_ENSEA_ELEVE/blob/main/2A/Option%20IA/Introduction_to_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CFaa7vpd7PRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc66b7da-4f22-4439-c1d0-9aee57fb9aba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.62.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12PZB5hWpwAyRuSWAgkaFdZdZluGf8_6Z\n",
            "To: /content/test_signs.h5\n",
            "100% 1.48M/1.48M [00:00<00:00, 174MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1g1CEUs8BvSJXSDroHgjUbTa3izGp9WMO\n",
            "To: /content/train_signs.h5\n",
            "100% 13.3M/13.3M [00:00<00:00, 56.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown\n",
        "!gdown --id 12PZB5hWpwAyRuSWAgkaFdZdZluGf8_6Z\n",
        "!gdown --id 1g1CEUs8BvSJXSDroHgjUbTa3izGp9WMO"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Disclaimer \n",
        "\n",
        "Before beginning this lab, please activate a GPU by going into :     \n",
        "- Exécution\n",
        "- Modifier le type d'éxecution\n",
        "- GPU "
      ],
      "metadata": {
        "id": "peN7xMkxh7y6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DNNs with TensorFlow\n",
        "\n",
        "Welcome to the Deep Learning Lab sessions. As you had a slight introduction to Deep Learning through the Course, you will now apply it through this izi pizi labs.\n",
        "This lab will be done using TensorFlow from Google. \n",
        "You will learn to do the following in TensorFlow: \n",
        "\n",
        "- Initialize variables\n",
        "- Start your own session\n",
        "- Train algorithms \n",
        "- Implement a Neural Network\n",
        "\n",
        "This part of the lab is splitted in two parts :\n",
        "- Using Tensorflow\n",
        "- Creating and Performing Classification using TF.\n",
        "\n",
        "<img src=\"https://www.memesmonkey.com/images/memesmonkey/3f/3fd47d627866ac3f67bc4a38b0b2941c.jpeg\">\n"
      ],
      "metadata": {
        "id": "dcOlbCv-7P0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First Time Hun ?\n",
        "\n",
        "So this might be your first time using Deep Learning for a certain task. So in this lab we will perform a certain Task : Classification. We will classify hands. Hun.\n",
        "\n",
        "When training a DL Algorithm you need few things : \n",
        "* A Dataset\n",
        "* A Model\n",
        "* A Learning Algorithm\n",
        "* Something more ?\n",
        "\n",
        "So we will navigate through each of these points to train a Model to perform Hand Signs Classification.\n",
        "\n",
        "<img src = \"https://i.kym-cdn.com/photos/images/original/000/123/620/Oh-boy-here-we-go.jpg\">\n",
        "\n"
      ],
      "metadata": {
        "id": "B6t5QBmc7RIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I - Dataset : SIGNS"
      ],
      "metadata": {
        "id": "RVTDKEE9-Lgh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We wil use SIGNS Dataset. Let's first have some insight look on our Dataset\n",
        "Load the train and test datasets\n"
      ],
      "metadata": {
        "id": "-jEdisCc94vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# TODO : load the h5 files in the correct variables\n",
        "train_dataset = h5py.File('/content/train_signs.h5', \"r\")\n",
        "test_dataset = h5py.File('/content/test_signs.h5', \"r\")\n",
        "\n",
        "# TODO : print the keys of each variables. \n",
        "# Questions: Are the keys different ? \n",
        "print(train_dataset.keys())\n",
        "print(test_dataset.keys())\n",
        "\n",
        "# TODO : create x_train, y_train, x_test, y_test and convert them to array using numpy\n",
        "# Questions : What is the length of each Dataset.\n",
        "# Questions : What are the labels, what are our images ?\n",
        "\n",
        "print(len(train_dataset))\n",
        "x_train = np.array(train_dataset['train_set_x'][:])\n",
        "y_train = np.array(train_dataset['train_set_y'][:]).reshape((-1))\n",
        "\n",
        "x_test = np.array(test_dataset['test_set_x'][:])\n",
        "y_test = np.array(test_dataset['test_set_y'][:]).reshape((-1))\n",
        "\n",
        "# TODO : load the classes in an array. \n",
        "# Questions : How many labels should you have ? (Count your fingers)\n",
        "classes = np.array(test_dataset[\"list_classes\"][:])\n",
        "print(classes)\n",
        "print(x_train.shape, y_train.shape, type(x_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Zv5idtSAyaF",
        "outputId": "66b906cd-2a91-4736-d17b-668834600d6a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<KeysViewHDF5 ['list_classes', 'train_set_x', 'train_set_y']>\n",
            "<KeysViewHDF5 ['list_classes', 'test_set_x', 'test_set_y']>\n",
            "3\n",
            "[0 1 2 3 4 5]\n",
            "(1080, 64, 64, 3) (1080,) <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
      ],
      "metadata": {
        "id": "cdzZlgq8L1av"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "SHUFFLE_BUFFER_SIZE = 100\n",
        "\n",
        "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "HBPUUn4ZL_bb"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Few questions on the Dataset: \n",
        "* How many elements do you have in your Train and Test Datasets ? Explain the shape of the Train Dataset\n",
        "* What is the size of one element of the Dataset ?\n",
        "* Are the images RGB images ?\n",
        "\n",
        "Plot some images from the train Dataset with their labels along using Matplotlib"
      ],
      "metadata": {
        "id": "4sViFgkcAgJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = 1070\n",
        "plt.title(\"Label is\" + str(np.squeeze(y_train[ index])))\n",
        "plt.imshow(x_train[index])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "t8HqOI_TAkCH",
        "outputId": "f8479bba-78e9-4f13-8aaf-10a1b9a93e5f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f81f9264710>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So now you have some understanding of the Dataset. Let's try things"
      ],
      "metadata": {
        "id": "NBXOWo8ZAzE5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "II- The Model : Your Choice\n",
        "\n",
        "We are going to guide you a lil bit for this. In fact, you can create whatever model you want. However, they might not be as effective as some other networks.\n",
        "In this part, we will try Dense Layers.\n",
        "\n",
        "<img src = \"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/ANN-Graph.gif\" height=300 >\n",
        "\n",
        "\n",
        "* What is the other name of a Dense Layer ?\n",
        "\n",
        "\n",
        "To create this FC model, you have to understand few things :\n",
        "* The input Layer will have a Fixed number of Neurons that must correspond to the image's size.\n",
        "* Between the Layers, you must apply some non-linearity so that the model learns complex features.\n",
        "* You have to compromise between the Shallowness or Depth of your Model. You'll understand why in the next lab.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1400/1*E4_pTJctmAofSRpZCZbv-g.jpeg\" height=300>\n",
        "\n",
        "\n",
        "Let's create a simple Sequential Model :    \n",
        "* an Input Layer\n",
        "* a Hidden Layer\n",
        "* an Output Layer\n",
        "\n",
        "(Like the picture above Andrew)"
      ],
      "metadata": {
        "id": "nCynSEY9H7BA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Create a Simple 3 layer model.\n",
        "# Question : What is the input shape ?\n",
        "# Question : What is the output shape ?\n",
        "# Question : What non linearity must we add ?\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(64,64,3)),\n",
        "  tf.keras.layers.Dense(64*64*3, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(5)\n",
        "])"
      ],
      "metadata": {
        "id": "l8f_9xapH42z"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some questions related to Memes on Activation Functions :\n",
        "\n",
        "<img src=\"https://2.bp.blogspot.com/-IdxHoo3lTrU/XHXNi8HM4_I/AAAAAAAAOhY/xTrp-Z8yYjY6NVBs-PXHw2Gho53vU90DgCLcBGAs/s1600/52386901_10157143758983669_1120348777576660992_o.jpg\" height = 400>\n",
        "\n",
        "*  How do you understand the ReLU function as an activation of a layer ?\n",
        "\n",
        "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQGVkqoa4YitmdIj-pCt88odvoscPbgocSPDQ&usqp=CAU\" >\n",
        "\n",
        "* Can we use any activation functions ? Take the example of multiclass classification, can we use the same activation function in the last layer than in the earlier layers ?"
      ],
      "metadata": {
        "id": "QsKmzR598Hzq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "III- The Loss \n",
        "\n",
        "Now we need something to tell our model if it does well or no. Let's say your model predicts something. We need to compute how far the prediction is compared to the real label. \n",
        "\n",
        "\n",
        "We will use the cross entropy. As some of you might see in Information Theory, Cross Entropy measures the difference between two Probabilty Distributions.\n"
      ],
      "metadata": {
        "id": "DfsGRDejIMMc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In fact, Tensorflow already has coded a bunch of Loss for us. You can have a look at all the existing loss here :\n",
        "* https://www.tensorflow.org/api_docs/python/tf/keras/losses/Loss\n"
      ],
      "metadata": {
        "id": "U_W5LW-v0vYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* What loss will we be using here ?\n",
        "\n",
        "If you don't know how to answer the previous question, ask yourself these things :\n",
        "\n",
        "* Do we have labels ?\n",
        "* What task are we performing ? Regression or Classification ?\n",
        "* What must be the output of our model ?\n"
      ],
      "metadata": {
        "id": "pJFhbQaBBtPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "mRGTfxuSJ35g"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss2 = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "64M_u1Op1ZSf"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IV - The Optimizer\n",
        "\n",
        "So at the end of the Model, we can compute a loss. We need to back-propagate the loss to all the layers so that it sees and understands the end result of a prediction and search for a Local-Global Optimum. You have plenty of optimizers available, the simplest is Gradient Descent. We pratically use Stochastic Gradient Descent in order to find a Global Minimum where the model should be performing 'well'.\n",
        "\n",
        "<img src=\"https://www.memecreator.org/static/images/memes/5296549.jpg\" height = 300>\n",
        "\n",
        "\n",
        "Have a look at the existing optimizers in TensorFlow :    \n",
        "* https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
        "\n",
        "We will use ADAM. In fact, we can use SGD or any other Optimizer. However, ADAM\n",
        "for Adaptive Moment Estimation\n",
        "\n",
        "We will use ADAM optimizer here. Why ? ADAM is more robust than SGD. (and it has more things such as per parameter learning rate adaptation that improves performance on sparse gradient and other things (To quote Andrew NG : Don't worry about it if you don't understand it) \n",
        "\n",
        "<img src=\"https://i.pinimg.com/474x/7b/58/bb/7b58bb3b853ff61ed8873aeb711cb3b6.jpg\">"
      ],
      "metadata": {
        "id": "cZ0j9m8bISOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Load Adam optimizer and set a learning rate.\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)"
      ],
      "metadata": {
        "id": "rZt9Lv11J4PZ"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "V - The Compilation\n",
        "\n",
        "Now that we have all we need, we have to compile the model with all the preceding stuff. \n",
        "\n",
        "That's where TensorFlow is cool. It has a compile method that compiles everything for you."
      ],
      "metadata": {
        "id": "q7DxtlUdIUfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss,\n",
        "              metrics=[tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None)])"
      ],
      "metadata": {
        "id": "ajW5ebUEDwuH"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VI- The Training \n",
        "\n",
        "When you train, you become fit. In Deep Learning, we fit a distribution of Data to the model so that it learns a specific task.\n",
        "\n",
        "Again, TensorFlow has a great method that fits data for you."
      ],
      "metadata": {
        "id": "7tjgUzaTIWU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset.batch(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xySoRwmVLP9W",
        "outputId": "704efd7b-1d0f-4823-c2ef-c35e6f9d777b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset shapes: ((None, None, 64, 64, 3), (None, None)), types: (tf.uint8, tf.int64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset,epochs=5)"
      ],
      "metadata": {
        "id": "o6hQFAbXKRzj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "outputId": "d1d6fe67-b385-42fd-d935-d04cc8698955"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-c2b885053732>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 810, in train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1665, in categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 4994, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 5) are incompatible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AW.. It doesn't work ....\n",
        "\n",
        "\n",
        "<img src=\"https://media.npr.org/assets/img/2016/03/29/ap_090911089838_sq-3271237f28995f6530d9634ff27228cae88e3440-s900-c85.webp\" height = 200>\n",
        "\n",
        "In fact, it is normal. Let's have a closer look on our Dataset and our Model. Especially the last layer.\n",
        "\n",
        "let's have a look at the Dataset labels first."
      ],
      "metadata": {
        "id": "mk4qWRGsAROH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzcI2iwZOXrV",
        "outputId": "f5c896e3-3a17-4fb9-90d3-a336a67387a3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5]\n",
            " [0]\n",
            " [2]\n",
            " ...\n",
            " [2]\n",
            " [4]\n",
            " [5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you might see these are numbers between 0,5. The model will have issues to predict these numbers. In fact, we put a SoftMax activation layer at the end. The SoftMax makes the model behaves as follows : \n",
        "\n",
        "Let's say that the Last Layer has 6 Neurons. We want to train the model so that \n",
        "when the model sees an image of 0 the 1rst neuron has the highest value. When it sees an image of 1 the 2nd neurons has the highest value.. and so on.\n",
        "\n",
        "That means that we need to change our label to something that helps us to learn to activate the wanted neuron for an image.\n",
        "\n",
        "Let's do some 1-Hot Encoding.\n",
        "\n",
        "<img src= \"https://image.slidesharecdn.com/cnn-tsopnang-180418232518/95/demo3-convolutional-neural-network-22-638.jpg?cb=1524094111\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5IdPwIY4O7CI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Create a function that 1-Hot encodes a number into a given size vector. Or have a look at this : https://www.tensorflow.org/api_docs/python/tf/one_hot\n",
        "\n",
        "y_train_oh = tf.one_hot(y_train, 5)\n",
        "y_test_oh = tf.one_hot(y_test, 5)\n",
        "print(y_train_oh)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train_oh))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test_oh))\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "SHUFFLE_BUFFER_SIZE = 100\n",
        "\n",
        "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srSx1hy9SjlK",
        "outputId": "ae2bcaa3-8a27-4b59-af13-1b7f7e931ff2"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0.]], shape=(1080, 5), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset)"
      ],
      "metadata": {
        "id": "u0AuKpc1e26M",
        "outputId": "321b0f9b-969d-454d-af88-b13134f8f7df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset shapes: ((None, 64, 64, 3), (None, 1, 5)), types: (tf.uint8, tf.float32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok let's try again"
      ],
      "metadata": {
        "id": "pkhXKvVofHfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset,epochs=15)"
      ],
      "metadata": {
        "id": "dSWXqkl7fHvB",
        "outputId": "50bb7874-bba7-40df-9a23-d30958bf5a1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "34/34 [==============================] - 1s 34ms/step - loss: 3124170.7500 - categorical_accuracy: 0.1926\n",
            "Epoch 2/15\n",
            "34/34 [==============================] - 1s 35ms/step - loss: 12409.0010 - categorical_accuracy: 0.2093\n",
            "Epoch 3/15\n",
            "34/34 [==============================] - 1s 34ms/step - loss: 8246.6846 - categorical_accuracy: 0.2000\n",
            "Epoch 4/15\n",
            "34/34 [==============================] - 1s 33ms/step - loss: 1.3502 - categorical_accuracy: 0.1676\n",
            "Epoch 5/15\n",
            "34/34 [==============================] - 1s 33ms/step - loss: 1019.1524 - categorical_accuracy: 0.1685\n",
            "Epoch 6/15\n",
            "34/34 [==============================] - 1s 33ms/step - loss: 1.3409 - categorical_accuracy: 0.1926\n",
            "Epoch 7/15\n",
            "34/34 [==============================] - 1s 32ms/step - loss: 1.3413 - categorical_accuracy: 0.1944\n",
            "Epoch 8/15\n",
            "34/34 [==============================] - 1s 33ms/step - loss: 1.3434 - categorical_accuracy: 0.1491\n",
            "Epoch 9/15\n",
            "34/34 [==============================] - 1s 33ms/step - loss: 1.3442 - categorical_accuracy: 0.1833\n",
            "Epoch 10/15\n",
            "34/34 [==============================] - 1s 33ms/step - loss: 1.3431 - categorical_accuracy: 0.2148\n",
            "Epoch 11/15\n",
            "34/34 [==============================] - 1s 32ms/step - loss: 1.3425 - categorical_accuracy: 0.1954\n",
            "Epoch 12/15\n",
            "34/34 [==============================] - 1s 33ms/step - loss: 1.3410 - categorical_accuracy: 0.1537\n",
            "Epoch 13/15\n",
            "34/34 [==============================] - 1s 33ms/step - loss: 1.3427 - categorical_accuracy: 0.1926\n",
            "Epoch 14/15\n",
            "34/34 [==============================] - 1s 33ms/step - loss: 1.3422 - categorical_accuracy: 0.2028\n",
            "Epoch 15/15\n",
            "34/34 [==============================] - 1s 33ms/step - loss: 1.3427 - categorical_accuracy: 0.1546\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f81f9093350>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "id": "_C8HhaECt3Dh",
        "outputId": "0df6433c-cd63-44f4-b396-ca1a274399f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VII- The Evalutation"
      ],
      "metadata": {
        "id": "fYvRK1IOIdkU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nonw that we trained the model, let's evaluate it on the test dataset. Again, TensforFlow has this great .evaluate() method that evaluates your model to the test dataset.\n",
        "\n",
        "* Evaluate your trained model to the Test Dataset."
      ],
      "metadata": {
        "id": "i2i4gJOFxIUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "3c2J-281u96p",
        "outputId": "2d8461b1-f1de-4aea-95fe-d721be4acb7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 8ms/step - loss: 1.3412 - categorical_accuracy: 0.1833\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.341188907623291, 0.18333333730697632]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    }
  ]
}