{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to Pytorch Lightning",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyONSTZJckKRDExbblud8i+1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thad75/TP_ENSEA_ELEVE/blob/main/SIA/TP2/Introduction_to_Pytorch_Lightning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaGntICmaak1"
      },
      "source": [
        "!pip install pytorch-lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu-IgiEnanUm"
      },
      "source": [
        "# Pytorch-Lightning : Training made Easier\n",
        "\n",
        "Time : 30 min \n",
        "\n",
        "In the last lab, we used Pytorch and Tensorflow to perform classification.\n",
        "As you have seen, writing the training and testing loop can be quickly indigest. One can get easily lost.\n",
        "\n",
        "Let us introduce you Pytorch Lightning\n",
        "\n",
        "<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a88de56e65d2ea6bc203ce178a1cecbe9b50a0ac/68747470733a2f2f6769746875622e636f6d2f5079546f7263684c696768746e696e672f7079746f7263682d6c696768746e696e672f7261772f312e342e392f646f63732f736f757263652f5f7374617469632f696d616765732f6c6f676f2e706e67\">\n",
        "\n",
        "\n",
        "Pytorch lightning will handle a lot of things for you. It creates a Trainer which is a Code Management trick used by many companies (FB, Google..) in order to get much more digest code.\n",
        "\n",
        "\n",
        "More Information on : https://www.pytorchlightning.ai/\n",
        "\n",
        "Goal of this lab :\n",
        "\n",
        "* Use Pytorch Lightning for Training\n",
        "* Learn to use Trainers and write comprehensible code in Class\n",
        "* Do classification on MNIST\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_cnXBS7boC7"
      },
      "source": [
        "# Classify Numbers using Lightning\n",
        "\n",
        "This introduction should be quick as is it just reapplying what you've learned in the previous lab.\n",
        "\n",
        "What's interesting about Lightning is that you can plug in your Torch modules without any modification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xBCfzUJcJO9"
      },
      "source": [
        "# LightningDataModule : MNIST\n",
        "\n",
        "As you have seen in the previous lab, you need to create your dataset and then load it into a DataLoader. That Dataloader is then used to fetch and give data as input for your Model.\n",
        "\n",
        "You will see that using Lightning makes things clearer. LightningDataModule allows you to write cleaner Code and fit easily your data to your model.\n",
        "\n",
        "First load MNIST Dataset. You won't need to write the Dataset as it's already embedded in Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIlBETqLbmx3"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from pytorch_lightning import loggers as pl_loggers\n",
        "import pytorch_lightning as pl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKjfGbX7lVfR"
      },
      "source": [
        "In fact,you can also write the normal PyTorch Dataloader code. But you'll see that writing thit DataModule helps for the training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBDDrYrKlr8X"
      },
      "source": [
        "# Model : Classifier \n",
        "\n",
        "We are performing Classification on the MNIST Dataset. You know that MNIST is given in torchvision. We will need to download and load it in ou LightningDataModule class.\n",
        "\n",
        "Have a look at : https://pytorch.org/vision/stable/datasets.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsUhr7BihqxX"
      },
      "source": [
        "class MNISTDataModule(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "        self.data_dir = ''\n",
        "        self.batch_size_train, self.batch_size_valid, self.batch_size_test = 32,32,32\n",
        "\n",
        "    def prepare_data(self):\n",
        "        # download MNIST Dataset from torchvision, this method is used to transform or download data to your Google Colab Session \n",
        "        MNIST(self.data_dir, train=True, download=True)\n",
        "        #...\n",
        "\n",
        "    def setup(self, stage):\n",
        "        #We need to setup our module. We have a training set that we will be fitting in our model\n",
        "        #and a testing set used to test our models prediction.\n",
        "        #the stage variable corresponds to those two steps : \n",
        "        #         |fit\n",
        "        # stage = <test\n",
        "        #         |None  \n",
        "\n",
        "        #First stage is 'fit' (or None)\n",
        "        if stage == \"fit\" or stage is None:\n",
        "\n",
        "            mnist_dataset = MNIST(self.data_dir, train=True, transform=self.transform)\n",
        "            # What additional set can we create ? Why\n",
        "            self.mnist_train, _ = \n",
        "\n",
        "        #Second stage is 'test' \n",
        "        if stage == \"test\" or stage is None:\n",
        "\n",
        "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
        "            #What additional set can we create ? Why ?\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        #Now create your Training DataLoader\n",
        "        \n",
        "\n",
        "    def val_dataloader(self):\n",
        "        #Now create your Validation DataLoader\n",
        "        \n",
        "    def test_dataloader(self):\n",
        "        #Now create your Testing DataLoader\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHZluKCyeI15"
      },
      "source": [
        "As you can see, we added a drop_last variable in our DataLoader:\n",
        "* What is its purpose ?\n",
        "* Is it useful ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71GzlDYqj5xY"
      },
      "source": [
        "# LightningModule :  MNIST Classifier \n",
        "\n",
        "Design a model to perform Classification. Again, ask yourself the following questions: \n",
        "* What task is it ?\n",
        "* What data do I have ?\n",
        "* What learning rate should I use ?\n",
        "* What could be my loss ? Why ?\n",
        "* What non-linearity should I use ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUBuWwX3iypq"
      },
      "source": [
        "class MNISTClassifier(pl.LightningModule):\n",
        "    def __init__(self, output_shape):\n",
        "        super(MNISTClassifier,self).__init__()\n",
        "        # what is the output_shape of your model ?\n",
        "        self.output_shape = output_shape\n",
        "        self.save_hyperparameters()\n",
        "        # Define your model here, be careful, your model will be an instance of the class\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        # What would be the forward steps of this classifier ?\n",
        "\n",
        "        return x\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # Choose your optimizer : https://pytorch.org/docs/stable/optim.html\n",
        "        \n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, train_batch, batch_idx):\n",
        "        # Define your Training Step\n",
        "        # This method is pretty much similar to what your did in the first lab to train your model.\n",
        "        x,y = train_batch     \n",
        "        ...\n",
        "        loss = \n",
        "        # Don't remove the next line, you will understand why later\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def validation_step(self, val_batch, batch_idx):\n",
        "        # Define your Validation Step\n",
        "        # What is the difference between the Training and the Validation Step ?\n",
        "        x,y = val_batch\n",
        "        ...\n",
        "        loss = \n",
        "        # Don't remove the next line, you will understand why later\n",
        "\n",
        "        self.log('val_loss', loss)\n",
        "    \n",
        "    def test_step(self, val_batch, batch_idx):\n",
        "        # Define your Test Step\n",
        "        # What is the difference between the Training, Validation and Test Step ?\n",
        "        x,y = val_batch\n",
        "        ...\n",
        "        loss = F.cross_entropy(latent, y)\n",
        "        # Don't remove the next line, you will understand why later\n",
        "        self.log('test_loss', loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TV-SLU6kWV7"
      },
      "source": [
        "# Did you say Train ?\n",
        "\n",
        "Let's train the model. We hav to create a Trainer that will handle a lot of thing for us. Lightning trainer is full of interesting assets that helps you for your training.\n",
        "\n",
        "To get a glance of what Lightning Trainer can give :\n",
        "https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html\n",
        "\n",
        "We also use TensorBoard "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9wyr4pjj5R-"
      },
      "source": [
        "tb_logger = pl_loggers.TensorBoardLogger(\"introduction to Lightning\")\n",
        "\n",
        "dm = MNISTDataModule()\n",
        "model = MNISTClassifier(10)\n",
        "\n",
        "trainer = pl.Trainer(gpus=-1,max_epochs=10,accelerator='dp',logger=tb_logger)\n",
        "trainer.fit(model, dm)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej56Kf9Zkefo"
      },
      "source": [
        "Oh it's training ! Happy ? Easy ? Let's test the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaWmGYVTjRz5"
      },
      "source": [
        "# Did you say Test ?\n",
        "\n",
        "For testing, well it's pretty easy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idVeeYZKVvSS"
      },
      "source": [
        "trainer.test(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NiFml0Kj88-"
      },
      "source": [
        "In this case we were computing the Loss. However testing a model is not based on its lost but other things. We won't ask you to compute them now but in the next part of the lab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO_fuzVPMNX5"
      },
      "source": [
        "# TensorBoard\n",
        "\n",
        "TensorBoard is a really useful tool. Indeed, it let's you register interesting values during training and plot them INTERACTIVELY. You might have seen a self.log line in the Validation and Training steps. \n",
        "The self.log saves the loss value into a TensorBoard readable file. We can also add images or other values using self.log\n",
        "\n",
        "In fact, look at the checkpoint created by the training. You might see 3 files :\n",
        "* Checkpoint\n",
        "* event.out....\n",
        "* hparam.yaml\n",
        "\n",
        "Let's open tensorboard to see how the training was. Tensorboard is loadable using magic_python commands.\n",
        "More info on TensorBoard : https://www.tensorflow.org/tensorboard/get_started\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzLzFpFdkdoM"
      },
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir \"/content/introduction to Lightning/default/version_0\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCx4XtQojqBf"
      },
      "source": [
        "Pytorch Lightning can be used along PyTorch. We encourage you to use PyTorch Lightning during your Lab Sessions and Career as it simplifies a lot of things for you (MultiGPU, Learning Rate Decay...)\n",
        "Have a good time with it\n",
        "\n",
        "<img src='https://c.tenor.com/VyApQ-jWyV0AAAAC/happy-borat.gif'>\n",
        "\n"
      ]
    }
  ]
}