{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "AC-pm-nLCkms",
        "0XwQAkGZaVwM"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNUXf+0bjo8rj8LYRRroVJ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thad75/TP_ENSEA_ELEVE/blob/main/3A/SIA/TDm/TD_Machine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Deep Learning : Tutorial\n",
        "\n",
        "Welcome to this Tutorial.\n",
        "This might be your first time in Deep Learning. Don't worry, we will guide you.\n",
        "\n",
        "This tutorial will introduce you to various models:\n",
        "\n",
        "<img src=\"https://i.imgflip.com/6u9pe5.jpg\" title=\"Oui Oui \" height=480>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pY1zWsxO6UnD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this tutorial : \n",
        "\n",
        "*   Direct application of DL Course\n",
        "*   Understand the differences between differents networks\n",
        "*   Use Pytorch to create and train a Neural Network\n",
        "*   Learn the Basic Workflow of a Deep Learning engineer.\n",
        "*   Introducing you to some of the useful DL Frameworks\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Questions are in bold characters**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "The tutorial is composed of two main parts :  \n",
        "* a Warmup on PyTorch\n",
        "* a Real Task\n",
        "\n",
        "The same task of classification will be used for all the tutorial. Only the dataset will change between the warmup and the real task"
      ],
      "metadata": {
        "id": "O7VkXorwTgq6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Don't forget to activate your GPU by going to : \n",
        "Exécution -> Modifier le type d'éxecution -> GPU"
      ],
      "metadata": {
        "id": "lLqCCALt1ONt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR-xX5bcHd8M",
        "outputId": "3cbf1861-b80b-4932-bf07-4f39c445126d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.10.0-py3-none-any.whl (529 kB)\n",
            "\u001b[K     |████████████████████████████████| 529 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.12.1+cu113)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import cv2\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "import random\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from torchmetrics import Accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "torch.manual_seed(42)\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "O-L2tscp1ObV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A Simple Neuron\n",
        "\n",
        "Let's introduce a Simple Task. \n",
        "Given a boolean value (0 or 1), we want the model to invert the input value. \n",
        "Example : if the model's input is 0, we want it to output 1.\n",
        "\n",
        "In order to perform this task, we will need few elements:\n",
        "* a Dataset\n",
        "* a Model\n",
        "* a Training/Testing Loop\n",
        "* Some hyperparameters"
      ],
      "metadata": {
        "id": "KJdIaGITzHRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a - The Simple Dataset and Dataloader\n",
        "\n",
        "As you know, to train a model you will need data. In practice before choosing/creating a model, we usually have a look on the Dataset. These datas come in the form of labeled or unlabeled data. \n",
        "\n",
        "In Pytorch, datasets inherits from the Dataset class. It is a simple class composed of minimum 3 methods :\n",
        "* __init__ : to initialize the class\n",
        "* __getitem__ : to retrieve a sample according to a index number\n",
        "* __len__ : to return the len of the entire Dataset\n",
        "\n",
        "In our case, we will generate a list of 0 and 1. The __getitem__ method should return the opposite value of the element picked at the given index."
      ],
      "metadata": {
        "id": "2nh8xJZ0EWhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleDataset(Dataset):\n",
        "\n",
        "  def __init__(self, len_data):\n",
        "\n",
        "    self.len_data = len_data\n",
        "    self.data = [random.randint(0,1) for i in range(len_data)] # This list of length len_data is filled with 0 and 1 \n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    # We select as data the value at index idx of the self.data list\n",
        "    data = self.data[idx]\n",
        "    label = ... if self.data[idx]== 0 else ...\n",
        "    # TODO : Return a dictionnary {'data': .., 'label':}\n",
        "    return {\"data\":torch.as_tensor(), \n",
        "            \"label\": torch.as_tensor()}\n",
        "\n",
        "  def __len__(self):\n",
        "    # Explanation : We know that the total length of the dataset is the length of the self.data attribute\n",
        "    return len(self.data)\n",
        "\n",
        "# TODO : Create dataset_train and dataset_test by initializing the Classes. You can choose a big value for the size of the list\n",
        "len_dataset_train = len_dataset_test= ...\n",
        "dataset_train = SimpleDataset(len_dataset_train)\n",
        "dataset_test = SimpleDataset(len_dataset_test)"
      ],
      "metadata": {
        "id": "QgwLl3CvzxGh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Dataloader is used to fetch batches of data to send them at the same time to the GPU. A DataLoader needs a batch size. Other attributes of the DataLoader class exists but we won't use them."
      ],
      "metadata": {
        "id": "TLToTyilGSu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = DataLoader(dataset_train, batch_size= 2048)\n",
        "dataset_test = DataLoader(dataset_test, batch_size= 2048)"
      ],
      "metadata": {
        "id": "7bx2poGf2Dw2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b - The Simple Model\n",
        "\n",
        "First time coding a neural net ? Let's think a little bit.\n",
        "Questions : \n",
        "* **What kind of task is it ?**\n",
        "*  **Is one neuron enough to perform the inversion of a boolean ?**\n",
        "* **Given an input x, a weight b, a bias b and an activation function f, how do we modelize a Single Neuron ?**"
      ],
      "metadata": {
        "id": "hiwHPWo8GdKY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a Model in PyTorch is pretty simple. We initalize a Class that inherits from nn.Module. \n",
        "\n",
        "It is defined as follows:\n",
        "\n",
        "\n",
        "```\n",
        "class Model(nn.Module):\n",
        "  def __init__(self,...):\n",
        "    \"\"\"\"\n",
        "    Defines the model. You can put the input size as a parameter if needed..\n",
        "    \"\"\"\"\n",
        "    super().__init__() #to init the main class\n",
        "    self.layers = ... # defining the model : could be Conv2d, Linear, RNN, LSTM\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    \"\"\"\n",
        "    The input x is forwarded through the neural net. \n",
        "    \"\"\"\n",
        "    output = self.layers(x)\n",
        "    return output\n",
        "```\n",
        "\n",
        "More informations : https://pytorch.org/docs/stable/nn.html\n",
        "\n"
      ],
      "metadata": {
        "id": "44xzhLcRHCru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using a nn.Parameter, create a single Neuron model.**"
      ],
      "metadata": {
        "id": "y5M_a6_VdOp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self,):\n",
        "      super().__init__()\n",
        "      # Note : We initialize randomly the valuees of the weights and the biases as these are learned through the training\n",
        "      self.w = nn.Parameter(torch.tensor(random.random()), requires_grad =True) # Weight\n",
        "      # TODO : by looking at the weight parameter (self.w) initialize the bias\n",
        "      self.b =  # Bias\n",
        "      # TODO : add a Sigmoid Activation layer\n",
        "      self.sigmoid = \n",
        "\n",
        "    def forward(self,x):\n",
        "      # TODO : Using the famous formula of a single neuron, compute the value of x1 : the output of the neuron\n",
        "      x1 = \n",
        "      # TODO : Pass x1 through the activation layer\n",
        "      x1 = \n",
        "      return x1"
      ],
      "metadata": {
        "id": "GdburjUE1Ktu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Create an instance of the SimpleModel and print the layers it has using print()\n",
        "model = \n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtBBFyV-2ebo",
        "outputId": "95bb99c8-6b3b-4a9c-f0ff-818602ff0de0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleModel(\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c- The Simple Training\n",
        "\n",
        "As of now, we are supposed to have the model and the dataset. Hence, we need to create the training loop and initialize some useful object for the training."
      ],
      "metadata": {
        "id": "MU-01GdZIZN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The training loop is defined as follows :\n",
        "\n",
        "\n",
        "```\n",
        "for epoch in num_epoch : \n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):        \n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(data)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i == ??:\n",
        "          running_loss= running_loss/??\n",
        "\n"
      ],
      "metadata": {
        "id": "mw1xLpjqIeDF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, there are some obscure words that we didn't define yet."
      ],
      "metadata": {
        "id": "YSXJ5iD1I7_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### i - Optimizer\n",
        "\n",
        "Optimizers are algorithms or methods used to minimize an error function (loss function) or to maximize the efficiency of production. A learning rate must be defined. The learning rate handles the step of the Gradient Descent update. Here, we will use stochastic gradient descent (SGD)"
      ],
      "metadata": {
        "id": "-bwijU5hJDm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "MGSEliitJap_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ii - Criterion \n",
        "\n",
        "This is basically the loss function. It measures the differences between the output and the input. We want to minimize it. \n",
        "\n",
        "\n",
        "**Which Loss function will we be using in this Binary Classification Task ?**"
      ],
      "metadata": {
        "id": "jLMiRb1cJI-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Initialize a criterion. Choose between BCELoss or MSELoss. More Information in https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "criterion = "
      ],
      "metadata": {
        "id": "mDYAyh-sKDr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### iii - Num Epoch \n",
        "\n",
        "The number of epoch corresponds to the number of time, the model will see the samples from the dataset"
      ],
      "metadata": {
        "id": "64JbigwpJMmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Choose a number of epochs \n",
        "num_epochs = "
      ],
      "metadata": {
        "id": "EUiLjFurKOuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### iv - Device \n",
        "\n",
        "Once the model initialized, we prefer accelerating the training. Hence, we send it to the GPU to profit from the parralelisation property of GPUs (Coucou HSP). To send it you have to define a device as follows:\n",
        "\n",
        "```\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "```\n",
        "To send your model or data to device : \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "model = model.to(device) or data = data.to(device)\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qOy1JTJ_JSMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "-yz0buH5KejY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### v - Gathering everything under a Loop\n",
        "\n",
        "Let's gather everything under a Training loop and a Testing loop.\n",
        "* The training loop will update the weights of the model\n",
        "* The testing loop will only test the model without updating anything.\n",
        "\n",
        "\n",
        "**Fill in the blanks**"
      ],
      "metadata": {
        "id": "XXzsX8KsK8aY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the Training Loop :\n",
        "# Define Device :\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# TODO : Create an Instance of the Model\n",
        "model = ....to(device)\n",
        "\n",
        "# Define your device : \n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# TODO : Define your optimizer. Don't forget your learning rate :\n",
        "lr = ...\n",
        "optimizer = ...\n",
        "\n",
        "# TODO : Define your criterion :\n",
        "criterion = ...\n",
        "\n",
        "# TODO : Define your number of epochs :\n",
        "n_epoch = ...\n",
        "\n",
        "# Initializing some stuff for visualization\n",
        "loss_train, loss_test = [], []\n",
        "\n",
        "\n",
        "for epoch in range(n_epoch):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(dataset_train, 0):\n",
        "        # TODO : Get the inputs. data is a dictionnary with keys : data and label\n",
        "        inputs, labels = ... .to(device), ... .to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # TODO : Send the input through the model\n",
        "        outputs = model(...)\n",
        "\n",
        "        # TODO : Compute the loss between the ouputs and the targets\n",
        "        loss = criterion(..., labels.float())\n",
        "\n",
        "        # update the weights using backward and optimizer\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 19:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss train: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "    loss_train.append(running_loss/i)\n",
        "\n",
        "    # Explanation : We don't need gradients here as we are not updating anything. This we call torch.no_grad()\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(dataset_test, 0):\n",
        "        # TODO : Get the inputs. data is a dictionnary with keys : data and label\n",
        "        inputs, labels =....to(device), ...\n",
        "\n",
        "        # TODO : Send the input through the model\n",
        "        outputs = model(...)\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 19:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss test: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "    loss_test.append(running_loss/i)\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "qoRHPfMLK_QJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### vi - Let's visualize some stuff\n",
        "\n",
        "As you could see we have to lists where we logged loss values each epochs. Let's plot them to see if the model is overfitting/underfitting.\n",
        "* **What can you tell on your model's training ?**\n",
        "* **Can we actually tell if the model is overfitting or not ? Why ?**"
      ],
      "metadata": {
        "id": "XLbnpF_wOc0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.title('Loss')\n",
        "plt.plot(...)\n",
        "plt.plot(...)"
      ],
      "metadata": {
        "id": "UDfHmMkeMkAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Layers\n",
        "\n",
        "One Neuron can perfom a lot of easy task. However, it is quickly limited when it comes to complex tasks.\n",
        "\n",
        "* **Can a Single Neuron perform a XOR calculation ? Can you prove it ? How many neurons do we need at minimum to perform XOR ?**\n",
        "\n"
      ],
      "metadata": {
        "id": "CGuWojkoy-Sl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The simple answer is no. We can obviously recreate a Model with lots of parameters but why bother when Engineer's wrote the Linear Layer to help us.\n",
        "\n",
        "The Linear Layer from Pytorch is a Layer composed of 1 or more neurons. Hence, we can learn more complex representation of the data. The linear layer takes fixed size input. \n",
        "\n",
        "\n",
        "<img src=\"https://docs.nvidia.com/deeplearning/performance/dl-performance-fully-connected/graphics/fc-layer.svg\">\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "O2HX5l7GS-Gp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some Downloads \n",
        "\n",
        "These are some downloads. Don't bother understanding it."
      ],
      "metadata": {
        "id": "wz-x7vCZ83Sg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "!gdown --id 1OGlSEVyhm06uJ-yusufl8A7poAHzuose\n",
        "!gdown --id 1CNVhbhDMCvGIYdyUv_H5kSsTflEzyI-s\n",
        "!unzip /content/test1.zip\n",
        "!unzip /content/train.zip"
      ],
      "metadata": {
        "id": "NWingntnK_yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a - Another Dataset \n",
        "\n",
        "Let's introduce an Intermediate Task. Given images of dogs and cats, we want the model to classify whether the input image is an image of a dog or a cat. We will use this task for the rest of the tutorial."
      ],
      "metadata": {
        "id": "1uZPUcfIwIbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Exploration\n",
        "\n",
        "Let's have a look on the Dataset. \n",
        "* **Using Matplotlib.Pyplot or cv2_imshow plot some images of the folder** \n",
        "* **Are the sizes of the images the same ? If no, what issue could occur for the training regarding the Model ?**"
      ],
      "metadata": {
        "id": "xJQL8Rehw1On"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Loading the files from the folder\n",
        "def return_files(path):\n",
        "  return [path + i for i in os.listdir(path)]\n",
        "\n",
        "path_train = '/content/train/'\n",
        "path_test ='/content/test1/'\n",
        "\n",
        "train_images = return_files(path_train)\n",
        "test_images = return_files(path_test)\n",
        "print(train_images)"
      ],
      "metadata": {
        "id": "NsqCo8M9nI4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "im = cv2.imread(train_images[1])\n",
        "cv2_imshow(im)"
      ],
      "metadata": {
        "id": "0Bbiq-uCx-kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's some Doggos and Cattos. "
      ],
      "metadata": {
        "id": "xde-aQpZetzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformations\n",
        "\n",
        "One issue could appear when training a Model on images of differents sizes : each image of the dataset could have a different size.\n",
        " \n",
        "*   But how would the Linear Layer handle that ?\n",
        "\n",
        "\n",
        "\n",
        "In fact, the linear layer can't handle that. We have to provide a fixed size input for the layer. One way is to resize the Image to a fixed size. It is where torchvision comes as a handy tool. It proposes a Transform Pipeline able to perform some Transformations on the input data, such as Normalization, Resizing, Blurring...\n",
        "\n",
        "Other Tools : Albumentations, Kornia..\n"
      ],
      "metadata": {
        "id": "RjwKDV2hXlYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Resize((128,128)),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "metadata": {
        "id": "zeRYmh9PhK62"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class IntermediateDataset(Dataset):\n",
        "\n",
        "  def __init__(self,list_images, transforms = None):\n",
        "    self.list_images = list_images\n",
        "    self.transforms = transforms\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    # Returns a piece of data that corresponds to element idx.\n",
        "    image = self.list_images[idx]\n",
        "    label = image.split('.')[0].split('/')[-1]\n",
        "    label = 1 if label =='dog' else 0\n",
        "    image = cv2.imread(image)\n",
        "    if self.transforms:\n",
        "      image = self.transforms(image)\n",
        "    # TODO : Return a dictionnary {'data': .., 'label':}\n",
        "    return {'data':image, 'label':torch.as_tensor(label)}\n",
        "    \n",
        "  def __len__(self):\n",
        "    # Returns the len of the entire Dataset\n",
        "    return len(self.list_images)"
      ],
      "metadata": {
        "id": "_qaNycyn9kD_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We obviously have 2 datasets : the training and the testing dataset. In other scenarios we will also have a validation dataset.\n",
        "\n",
        "*   The training dataset is used to train the model\n",
        "*   The testing dataset is used to test the model\n",
        "\n",
        "There's one particularity in the testing dataset. It doesn't have usable label. Hence we will create a validation dataset from the training dataset and use it for testing.\n",
        "\n"
      ],
      "metadata": {
        "id": "LDNYHiAA96vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = IntermediateDataset(train_images, transform)\n",
        "dataset_test = IntermediateDataset(test_images, transform)\n",
        "train_size = int(0.8 * len(dataset_train))\n",
        "test_size = len(dataset_train) - train_size\n",
        "\n",
        "dataset_train, dataset_validation =  torch.utils.data.random_split( dataset_train, [train_size, test_size])\n",
        "\n",
        "dataset_train = DataLoader(dataset_train, batch_size = 100)\n",
        "dataset_test = DataLoader(dataset_test, batch_size = 20)\n",
        "dataset_valid = DataLoader(dataset_validation, batch_size=10)"
      ],
      "metadata": {
        "id": "6LfELC_U-FBj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Verifiy that the labels on the Datasets are correct**"
      ],
      "metadata": {
        "id": "W46ossXFfqD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Just to verify is the validation dataset contains label.\n",
        "for i, data in enumerate(dataset_valid):\n",
        "  # TODO : Print some label and plot their images\n",
        "  ...\n",
        "  if i == 1 : break"
      ],
      "metadata": {
        "id": "xupfz-twMxVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b- The Intermediate Model\n",
        "\n",
        "The intermediate model will consist of one Linear Layer. The size of the input is known. But to reuse the model, we need to parametrize the input value attribute of the Linear Layer to make it usable for future works. \n",
        "\n",
        "Important Thing : Linear layers take a 1-D Tensor as input. So we will need to reshape the input tensors.\n",
        "\n",
        "**Create a IntermediateModel composed of One layer and its activation**"
      ],
      "metadata": {
        "id": "6aVmTNaK9l-a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NdLdWI8r6STv"
      },
      "outputs": [],
      "source": [
        "class IntermediateModel(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size):\n",
        "    super().__init__()\n",
        "    # TODO : Define your model here. It should be 1 layer and a activation function\n",
        "    self.layer = ...\n",
        "    self.sigmoid = ...\n",
        "  def forward(self,x):\n",
        "    # TODO : Define how your data passes the model\n",
        "    output = ...\n",
        "    output = ...\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c - Creating a Training Loop\n",
        "\n",
        "As usual, create the training loop.\n",
        "**What changes from the previous training ?**\n",
        "\n",
        "In order to compute the accuracy of the model on the testing set, we will use torchmetrics.\n",
        "\n",
        "\n",
        "The accuracy is defined as \n",
        "$\\frac{Correct Classification}{All  Classification}$.\n",
        "\n",
        "\n",
        "We will define a threshold defining if a predicted class belongs to a class Dog or Cat. Here, we define the threshold as 0.5"
      ],
      "metadata": {
        "id": "MF38B6Ah-73e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the Training Loop :\n",
        "# Define Device :\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# TODO : Create an Instance of the Model\n",
        "input_size = ...\n",
        "model = ....to(device)\n",
        "\n",
        "# Define your device : \n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Define your optimizer :\n",
        "lr = 1e-3\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# TODO : Define your criterion :\n",
        "criterion = ...\n",
        "\n",
        "# Define your Accuracy\n",
        "accuracy = Accuracy(threshold = 0.5).to(device)\n",
        "\n",
        "#Define your number of epochs :\n",
        "n_epoch = 2\n",
        "\n",
        "# Initializing some stuff for visualization\n",
        "loss_train, loss_test = [], []\n",
        "\n",
        "\n",
        "for epoch in range(n_epoch):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "    for i, data in enumerate(dataset_train, 0):\n",
        "        # Get the inputs. data is a dictionnary with keys : data and label\n",
        "        inputs, labels = data['data'].to(device), data['label'].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # TODO : Manipulate the input Data so that its shape is BS,Input Size. It will hence fit into the Linear Layer.\n",
        "        inputs = inputs.reshape(...) # Shape must be Batch Size, -1\n",
        "\n",
        "        # TODO : Send the input through the model\n",
        "        outputs = ...\n",
        "        # print(outputs.shape)\n",
        "\n",
        "        # Compute the loss between the ouputs and the targets\n",
        "        loss = criterion(outputs.squeeze(-1), labels.float())\n",
        "        acc = accuracy(outputs.flatten(), labels)\n",
        "\n",
        "        # update the weights using backward and optimizer\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        running_acc += acc.item()\n",
        "        if i % 100 == 99:    # print every 100 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss train: {running_loss / 100:.3f} acc train: {running_acc /100:.3f}')\n",
        "            running_loss = 0.0\n",
        "            running_acc = 0.0\n",
        "\n",
        "    loss_train.append(running_loss/i)\n",
        "    # Explanation : We don't need gradients here as we are not updating anything. This we call torch.no_grad()\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(dataset_valid, 0):\n",
        "        # TODO : Get the inputs. data is a dictionnary with keys : data and label\n",
        "        inputs, labels = data['data'].to(device), data['label'].to(device)\n",
        "        inputs = \n",
        "\n",
        "        # TODO : Send the input through the model\n",
        "        outputs = model(inputs)\n",
        "        # TODO : Compute the accuracy\n",
        "        acc = accuracy(...,...)\n",
        "        running_loss += loss.item()\n",
        "        running_acc += acc.item()\n",
        "\n",
        "        if i % 100 == 99:    # print every 100 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss test: {running_loss / 100:.3f} acc test: {running_acc / 100:.3f}')\n",
        "            running_loss = 0.0\n",
        "            running_acc = 0.0\n",
        "\n",
        "    loss_test.append(running_loss/i)\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "2ag70S1_-_PU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the training loss curves.\n",
        "**What can you say ?**"
      ],
      "metadata": {
        "id": "bO5Br1_ixIWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now test the model on few input images. Let's see of the model is actually good or not.\n",
        "\n",
        "**Send some Images of the Testing Dataset to the model, and look at the predictions**"
      ],
      "metadata": {
        "id": "gk9bRHDdNOjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(iter(dataset_test))\n",
        "data = dataiter.next()\n",
        "images, labels = data.values()\n",
        "# TODO : Perform the inference\n",
        "# TODO1 : Send image to device\n",
        "images = ...\n",
        "# TODO2 : Reshape the image\n",
        "images = ...\n",
        "# TODO3 : Forward\n",
        "predicted = ...\n",
        "classes = ( 'cat', 'dog')\n",
        "\n",
        "# Plot Images\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    npimg = np.transpose(npimg, (1, 2, 0))\n",
        "    npimg = cv2.cvtColor(npimg, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(npimg)\n",
        "    plt.show()\n",
        "\n",
        "def binarize(x, thresh):\n",
        "    return 1 if x > thresh else 0\n",
        "\n",
        "# TODO : Binarize the prediction using 0.5 as threshold and print the predicted classes.\n",
        "print('Predicted: ', ' '.join('%5s' % classes[...] for j in range(images.shape[0])))\n",
        "\n",
        "# TODO : Visually compare the prediction to the Images"
      ],
      "metadata": {
        "id": "xhhjfk_hRGh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In fact, to get something to compare to, we will compute the accuracy on the validation dataset.\n",
        "* **Compute the Accuracy on the Validation Dataset**"
      ],
      "metadata": {
        "id": "WTECD_leQ0aZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = Accuracy(threshold = 0.5).to(device)\n",
        "running_acc = 0.0\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(dataset_valid, 0):\n",
        "    # TODO : Get the inputs. data is a dictionnary with keys : data and label\n",
        "    inputs, labels = data['data'].to(device), data['label'].to(device)\n",
        "    inputs = inputs.reshape(inputs.shape[0],-1)\n",
        "    # TODO : Send the input through the model\n",
        "    outputs = model(inputs)\n",
        "    acc = accuracy(outputs.flatten(), labels)\n",
        "    running_acc += acc.item()\n",
        "\n",
        "print('Accuracy in Dataset Valid is ',running_acc/(len(dataset_valid)) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBIdn36POzHe",
        "outputId": "8a75ee6d-d445-43e3-b76e-2d67fc6ef0c6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy in Dataset Valid is  0.596800006210804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## d - Going Further on Linear Layers\n",
        "\n",
        "As you can see, a lot of code is just some copy paste. Depending on the company you work for, a lot of code is already written. Usually, we create a function or a  **Trainer** class to handle the Training. \n",
        "The Trainer usually has :\n",
        "* a Training method\n",
        "* a Testing method\n",
        "\n",
        "A Trainer allows modularity during training as the model, the data are just attributes of the Trainer.\n",
        "We provide you the code for a really simple Trainer. Have a look at it.\n",
        "\n",
        "For the rest of the tutorial, we will use the Trainer class\n"
      ],
      "metadata": {
        "id": "-OMvOm0XWZcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer():\n",
        "\n",
        "  def __init__(self, model, dataset_train, dataset_test, criterion, optimizer, device = 'cuda'):\n",
        "\n",
        "    self.model = model.to(device)\n",
        "    self.dataset_train = dataset_train\n",
        "    self.dataset_test = dataset_test\n",
        "    self.criterion = criterion\n",
        "    self.optimizer = optimizer\n",
        "    self.device = device\n",
        "    self.accuracy = Accuracy(threshold = 0.5).to(device)\n",
        "    self.epoch = 0\n",
        "  def forward(self,x):\n",
        "    x = x.reshape(x.shape[0],-1)\n",
        "    x = self.model(x)\n",
        "    return x \n",
        "\n",
        "  def train(self):\n",
        "    \n",
        "      running_loss = 0.0\n",
        "      running_acc = 0.0\n",
        "      for i, data in enumerate(tqdm(self.dataset_train), 0):\n",
        "          inputs, labels = data['data'].to(self.device), data['label'].to(self.device)\n",
        "          self.optimizer.zero_grad()\n",
        "          outputs = self.forward(inputs)\n",
        "          loss = self.criterion(outputs.squeeze(-1), labels.float())\n",
        "          acc = self.accuracy(outputs.flatten(), labels)\n",
        "\n",
        "          loss.backward()\n",
        "          self.optimizer.step()          \n",
        "          running_loss += loss.item()\n",
        "          running_acc += acc.item()\n",
        "          if i % 100 == 99:    # print every 2000 mini-batches\n",
        "              print(f'[{self.epoch + 1}, {i + 1:5d}] loss train: {running_loss / 100:.3f} acc train: {running_acc /100:.3f}')\n",
        "              running_loss = 0.0\n",
        "              running_acc = 0.0\n",
        "              \n",
        "  @torch.no_grad()\n",
        "  def test(self):\n",
        "      running_acc = 0.0\n",
        "      for i, data in enumerate(tqdm(self.dataset_test), 0):\n",
        "        inputs, labels = data['data'].to(self.device), data['label'].to(self.device)\n",
        "        outputs = self.forward(inputs)\n",
        "        acc = self.accuracy(outputs.flatten(), labels)\n",
        "        running_acc += acc.item()\n",
        "\n",
        "        if i % 100 == 99:    # print every 2000 mini-batches\n",
        "            print(f'[{self.epoch + 1}, {i + 1:5d}]acc test: {running_acc / 100:.3f}')\n",
        "            running_acc = 0.0\n",
        "\n",
        "  def train_test(self, num_epoch):\n",
        "      for epoch in range(num_epoch):\n",
        "        print(\"Train\")\n",
        "        self.epoch = epoch\n",
        "        self.train()\n",
        "        print(\"Test\")\n",
        "        self.test()\n",
        "\n"
      ],
      "metadata": {
        "id": "G6KUmgwUhjDr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using the Trainer:**\n",
        "* **Change the model for a 2 layered Model. \n",
        "(Linear(input_shape, 512)->Linear( 512,1) for example). Don't forget to add some activation layers (ReLU, GeLU,TanH..).** \n",
        "* **What does it change to the accuracy of the model ?** "
      ],
      "metadata": {
        "id": "L-0iwb4WmA2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IntermediateModel(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size):\n",
        "    super().__init__()\n",
        "    # TODO : Define your model here\n",
        "    self.layer = nn.Linear(...,...) # Layer 1\n",
        "    self.layer2 = nn.Linear(...,...) # Layer 2\n",
        "\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self,x):\n",
        "    # TODO : Define how your data passes the model. Don't forget your activation layer\n",
        "    output = ...\n",
        "    return output"
      ],
      "metadata": {
        "id": "Bme12B8YmAT8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Initialize your trainer**\n",
        "* **Do we need to change the loss**\n",
        "* **Train your Model for 2 epochs**"
      ],
      "metadata": {
        "id": "SYWAJYuenJa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = ...\n",
        "model = IntermediateModel(input_size)\n",
        "lr = 1e-1\n",
        "# TODO : Initialize your Trainer\n",
        "trainer = Trainer( model = ...,\n",
        "                  dataset_train = dataset_train, \n",
        "                  dataset_test =dataset_test, \n",
        "                  criterion= ..., \n",
        "                  optimizer = optim.SGD(model.parameters(), lr=lr), \n",
        "                  device = 'cuda')"
      ],
      "metadata": {
        "id": "IlVEADxmveSr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Train the model\n",
        "trainer.train_test(num_epoch= 2)"
      ],
      "metadata": {
        "id": "9a22IpbjkhlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same thing, let's compute the accuracy on the validation Dataset."
      ],
      "metadata": {
        "id": "vV1mQZn6RLHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = Accuracy(threshold = 0.5).to(device)\n",
        "running_acc = 0.0\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(dataset_valid, 0):\n",
        "    # TODO : Get the inputs. data is a dictionnary with keys : data and label\n",
        "    inputs, labels = ...,...\n",
        "    inputs = inputs.reshape(inputs.shape[0],-1)\n",
        "    # TODO : Send the input through the model\n",
        "    outputs = ...\n",
        "    acc = accuracy(outputs.flatten(), labels)\n",
        "    running_acc += acc.item()\n",
        "\n",
        "print('Accuracy in Dataset Valid is ',running_acc/(len(dataset_valid)))"
      ],
      "metadata": {
        "id": "YM7XQRt8RIPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## e - Conclusion on the Linear Layers\n",
        "\n",
        "* How did the Linear Model perfom on this dataset ?\n",
        "* Is it useful to deepen (add layers) the model ?\n"
      ],
      "metadata": {
        "id": "cZefFOGSwfTY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks : CNN\n",
        "\n",
        "Convolutional neural networks are a specialized type of artificial neural networks that uses a mathematical operation called convolution in place of general matrix multiplication in at least one of their layers. They are really useful in Vision Task. In a Conv Layer, **the kernel is learned** the region seen by the Kernel is called **Receptive Field**.\n",
        "\n",
        "Before beginning let's understand how convolution work:\n",
        "https://ezyang.github.io/convolution-visualizer/\n",
        "* **What is the impact of the Kernel Size parameter on the output Tensor ?**\n",
        "* **What is the impact of the Stride parameter on the output Tensor ?**\n"
      ],
      "metadata": {
        "id": "MjpFRJ4zWcAz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a - Intermediate Dataset Part 2 \n",
        "\n",
        "We won't change the Dataset that much. We will just resize the images to be a little bit bigger. For those wondering, the seed is fixed, so the Validation Dataset will always be the same as the previous parts."
      ],
      "metadata": {
        "id": "s1Ln5hBcxupS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Resize((256,256)),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "dataset_train = IntermediateDataset(train_images, transform)\n",
        "train_size = int(0.8 * len(dataset_train))\n",
        "test_size = len(dataset_train) - train_size\n",
        "dataset_train, dataset_validation = torch.utils.data.random_split( dataset_train, [train_size, test_size])\n",
        "dataset_test = IntermediateDataset(test_images, transform)\n",
        "\n",
        "dataset_train = DataLoader(dataset_train, batch_size = 100)\n",
        "dataset_test = DataLoader(dataset_test, batch_size = 100)\n",
        "dataset_validation = DataLoader(dataset_validation, batch_size=100)"
      ],
      "metadata": {
        "id": "23nKumQNx1aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b - Intermediate Model Part 2 \n",
        "\n",
        "Now we will use a convolutional layer to process the input image. The CNN model is composed of a Feature Extractor (Backbone) and a Classification Head (Head).\n",
        "As a Feature Extractor, we will use a single Conv2D layer.\n",
        "As a Classification Head, we will use a single Linear Layer.\n",
        "\n",
        "**Create a Model with 2 layers:**\n",
        "* **One Conv2D layer as a backbone**\n",
        "* **One Linear layer as a head**\n",
        "\n",
        "Something must be taken care of. Indeed :\n",
        "* The conv layer takes as input a 3-D shaped Input\n",
        "* The linear layer takes as input a 1-D shaped Input\n",
        "\n",
        "\n",
        "So we need to reshape the output of the conv layer so it can go through the linear layer."
      ],
      "metadata": {
        "id": "Sl4a9Zbhx2AF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IntermediateModel2(nn.Module):\n",
        "  def __init__(self, input_channel, linear_input_size):\n",
        "    super().__init__()\n",
        "    self.backbone = nn.Conv2d(in_channels= input_channel,out_channels=64, kernel_size = 3)\n",
        "    self.relu = nn.ReLU()    \n",
        "    # TODO : Initialize your Binary Head using a Linear Layer\n",
        "    self.head = ...\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        " \n",
        "  def forward(self,x):\n",
        "    # TODO : Send your input throught the layers\n",
        "    # TODO : Send through backbone\n",
        "    x = ...\n",
        "    x = ...\n",
        "    # TODO : Send through Head. Do we need to reshape the input ?\n",
        "    x = ...\n",
        "    output = ...\n",
        "    output = ...\n",
        "    return output"
      ],
      "metadata": {
        "id": "3ssqYShqygKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c - Overwriting the Trainer\n",
        "\n",
        "Here is where coding with Classes comes in handy. Inheriting from a Class brings all its method to the inherited class. It means that we don't need to rewrite all the methods is they are usable as is. Normally, the original Trainer should be enough to train the model. \n"
      ],
      "metadata": {
        "id": "3lRsnVFx8Xif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvTrainer(Trainer):\n",
        "\n",
        "  def __init__(self, model, dataset_train, dataset_test, criterion, optimizer, device = 'cuda'):\n",
        "      super().__init__( model, dataset_train, dataset_test, criterion, optimizer, device )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.model(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "THcRI7U2kzns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Initialize your trainer**\n",
        "* **Train your Model for 2 epochs**"
      ],
      "metadata": {
        "id": "3J1C09cVpcY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_channel = ...\n",
        "linear_input_size = ...\n",
        "model = ...\n",
        "lr = ...\n",
        "trainer = ConvTrainer( model = ...,\n",
        "                  dataset_train = dataset_train, \n",
        "                  dataset_test =dataset_test, \n",
        "                  criterion= ..., \n",
        "                  optimizer = optim.SGD(model.parameters(), lr=...), \n",
        "                  device = 'cuda')"
      ],
      "metadata": {
        "id": "d2hRw1Vt-AKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train_test(2)"
      ],
      "metadata": {
        "id": "-La7GefR-S8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again let's compute the Accuracy on the validation dataset."
      ],
      "metadata": {
        "id": "AzoSeIo-S14V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = Accuracy(threshold = 0.5).to(device)\n",
        "running_acc = 0.0\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(dataset_validation, 0):\n",
        "    # TODO : Get the inputs. data is a dictionnary with keys : data and label\n",
        "    inputs, labels = ...,...\n",
        "    # TODO : Send the input through the model\n",
        "    outputs = ...\n",
        "    acc = accuracy(outputs.flatten(), labels)\n",
        "    running_acc += acc.item()\n",
        "\n",
        "print('Accuracy in Dataset Valid is ',running_acc/(len(dataset_validation)) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLCr5BrYTKS1",
        "outputId": "382ef436-8f64-4db7-f55f-90e3766111a5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy in Dataset Valid is  0.49839999616146086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **What can you say about the models accuracy ?**\n",
        "* **Is it better than a Linear Layer ?**"
      ],
      "metadata": {
        "id": "TrGkiYTwTNtE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## d - Going Further on Conv Layers\n",
        "\n"
      ],
      "metadata": {
        "id": "YN3TCM3HVcz7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a Deeper Model \n",
        "\n",
        "We will now create a Deeper Model.\n",
        "<img src=\"https://miro.medium.com/max/1400/1*uUYc126RU4mnTWwckEbctw@2x.png\">\n",
        "\n",
        "* **Recreate this Model** \n",
        "* **Train the Model**\n",
        "* **What does it change on the Accuracy**"
      ],
      "metadata": {
        "id": "UdrfDP50WMql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IntermediateModel2(nn.Module):\n",
        "  def __init__(self, input_channel, linear_input_size):\n",
        "    super().__init__()\n",
        "    self.backbone = nn.Sequential(\n",
        "        # TODO : Create a Conv2d + MaxPool2d + Activation. Kernel size will be 3, output channel size will be 64. MaxPool2d kernel size is 2\n",
        "\n",
        "        # TODO : Create a Conv2d + MaxPool2d + Activation. Kernel size will be 3, output channel size will be 128. MaxPool2d kernel size is 2\n",
        " \n",
        "        # Don't change next lines      \n",
        "        nn.Conv2d(128,256, 3),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.ReLU()   ,\n",
        "        nn.Conv2d(256,512, 3),\n",
        "        nn.MaxPool2d(2))\n",
        "    \n",
        "    self.relu = nn.ReLU()\n",
        "    self.head = nn.Sequential(nn.Linear(linear_input_size,128),\n",
        "                              nn.ReLU(),\n",
        "                              nn.Linear(128,1))\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        " \n",
        "  def forward(self,x):\n",
        "    # TODO : forward your input through the backbone and the head. DOn't forget yuor activations and reshapes\n",
        "    x = ...\n",
        "    x = ...\n",
        "    x = ...\n",
        "    output = ...\n",
        "    output = ...\n",
        "    return output"
      ],
      "metadata": {
        "id": "RFoN2MgoBGI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the Deeper Model"
      ],
      "metadata": {
        "id": "MVw1u2kaqUg1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Initialize your trainer**\n",
        "* **Train your Model for 2**"
      ],
      "metadata": {
        "id": "yVRwyZa5pmGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_channel = ...\n",
        "linear_input_size = ...\n",
        "model = IntermediateModel2(input_channel =input_channel, linear_input_size=linear_input_size)\n",
        "lr = ...\n",
        "trainer = ConvTrainer(model = ...,\n",
        "                      dataset_train = dataset_train, \n",
        "                      dataset_test = dataset_test, \n",
        "                      criterion = ..., \n",
        "                      optimizer = optim.SGD(model.parameters(), lr=...), \n",
        "                      device = 'cuda')"
      ],
      "metadata": {
        "id": "40EQCIptBQwm"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train_test(2)"
      ],
      "metadata": {
        "id": "oe10ZJ4QBS45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again let's compute the Accuracy on the validation dataset."
      ],
      "metadata": {
        "id": "guwpUDWSqCgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = Accuracy(threshold = 0.5).to(device)\n",
        "running_acc = 0.0\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(dataset_validation, 0):\n",
        "    # Get the inputs. data is a dictionnary with keys : data and label\n",
        "    inputs, labels = data['data'].to(device), data['label'].to(device)\n",
        "    # TODO : Send the input through the model\n",
        "    outputs = ...\n",
        "    acc = accuracy(outputs.flatten(), labels)\n",
        "    running_acc += acc.item()\n",
        "\n",
        "print('Accuracy in Dataset Valid is ',running_acc/(len(dataset_validation)) )"
      ],
      "metadata": {
        "id": "gSdWe7lgWE0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##e - Visualizing the Kernels"
      ],
      "metadata": {
        "id": "Auev6Yl7p_ID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing the learned Kernels\n",
        "\n",
        "Let's visualize the learned kernels."
      ],
      "metadata": {
        "id": "gOgJ50q2WI7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import utils\n",
        "\n",
        "def visTensor(tensor, ch=0, allkernels=False, nrow=8, padding=1): \n",
        "    n,c,w,h = tensor.shape\n",
        "    if allkernels: tensor = tensor.view(n*c, -1, w, h)\n",
        "    elif c != 3: tensor = tensor[:,ch,:,:].unsqueeze(dim=1)\n",
        "    rows = np.min((tensor.shape[0] // nrow + 1, 64))    \n",
        "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
        "    plt.figure( figsize=(nrow,rows) )\n",
        "    plt.imshow(grid.cpu().numpy().transpose((1, 2, 0)))\n",
        "\n",
        "\n",
        "# TODO : Change the Backbone layer number to check the Kernels of the earlier and leter layers. The number corresponds to the index of the layer in the model\n",
        "filter = model.backbone[...].weight.data.clone()\n",
        "visTensor(filter, ch=0, allkernels=False)\n",
        "plt.axis('off')\n",
        "plt.ioff()\n",
        "plt.show()  "
      ],
      "metadata": {
        "id": "XLOy7wbHCELI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ehm, can you actually tell something about the learned kernels ?**"
      ],
      "metadata": {
        "id": "XrpZGHQVp3WJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning a Model\n",
        "\n",
        "Generally, we often take as a backbone a pretrained network (ResNet, VGG, ConvNext...). These pretrained network are pretrained on Huge Datasets such as ImageNet; To these backbones, we add an head that will perform the classification task."
      ],
      "metadata": {
        "id": "AC-pm-nLCkms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a - The FineTunable Model\n",
        "\n",
        "We will use convext backbone. Why ? It has 7x7 kernel layers, and is said to be as efficient as a Transformer Model. \n",
        "\n",
        "\n",
        "<img src='https://miro.medium.com/max/778/0*LCoMNVdQjy1pzHXi'>\n",
        "\n",
        "We will import the model and the weights from torchvision. \n",
        "* **Print the model** \n",
        "* **What layers does the model have ?**\n",
        "* **Can we use the classifier Layer as is ? Why ?**\n"
      ],
      "metadata": {
        "id": "8_lgMsv8e6EY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backbone = torchvision.models.convnext_small(weights='DEFAULT')\n",
        "print(backbone)"
      ],
      "metadata": {
        "id": "62wZXMGtgb7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we will need to change the classifier layer to a Linear Layer that allows binary classification."
      ],
      "metadata": {
        "id": "3y1EHKHGhYAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import ConvNext model\n",
        "class FineTunedModel(nn.Module):\n",
        "\n",
        "  def __init__(self,linear_input_size=100):\n",
        "    super().__init__()\n",
        "    # TODO : overwrite the classifier head by a binary classification head.\n",
        "    self.backbone = torchvision.models.convnext_small(weights='DEFAULT').eval() # Do we eval the backbone ? That's just some try and retry to achieve the best perf. In this case, freezing the backbone gives better acc\n",
        "    self.backbone.classifier[-1] = ... \n",
        "    self.relu = nn.ReLU()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self,x ):\n",
        "    # TODO : Forward your input x. We won't need any reshape as it is already included in the Backbone (Thank You Torchvision :') )\n",
        "    feature = ...\n",
        "    output = ...\n",
        "    return output"
      ],
      "metadata": {
        "id": "z7VLKVYMFg9w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's check if the model's classifier layer has been changed to the wanted Layer"
      ],
      "metadata": {
        "id": "8TWwEoNPiT70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_input_size = ...\n",
        "model = FineTunedModel( linear_input_size=linear_input_size)\n",
        "\n",
        "# TODO : Verify that your last layer allows binary classification\n",
        "print(model.backbone. ...)"
      ],
      "metadata": {
        "id": "2L-x2bYkbzA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b - The FineTunable Training\n",
        "Now let's train the model. However, we need to ackowledge something about the learning rate.\n",
        "When FineTuning a model, we don't want the previously learned knowledge to be forgotten. We want to continue the learning using the dataset. To prevent from **catastrophic forgetting** we use a really low learning rate."
      ],
      "metadata": {
        "id": "eA3_9j9nieHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Initialize your Trainer Class\n",
        "lr = ...\n",
        "trainer = ConvTrainer(model = ...,\n",
        "                      dataset_train = dataset_train, \n",
        "                      dataset_test = dataset_test, \n",
        "                      criterion = ..., \n",
        "                      optimizer = optim.SGD(model.parameters(), lr=...), \n",
        "                      device = 'cuda')"
      ],
      "metadata": {
        "id": "6NMtfKkDYqxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c - The FineTunable Training\n",
        "\n",
        "The training will be a little bit long (~15 min/epochs). So if you have questions don't hesitate asking them.\n",
        "\n",
        "Disclaimer : if you have CUDA out of memory error, reinitalize your environment and run the cell in the Hidden Cell section"
      ],
      "metadata": {
        "id": "q2RbFgntaA8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Train your model for one epoch\n",
        "trainer.train_test(num_epoch = ...)"
      ],
      "metadata": {
        "id": "Usmx96IhY9Rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.imgflip.com/6w27wz.jpg\" title=\"made at imgflip.com\"/>"
      ],
      "metadata": {
        "id": "X_ECoXMOs7zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = Accuracy(threshold = 0.5).to(device)\n",
        "running_acc = 0.0\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(dataset_validation, 0):\n",
        "    # TODO : Get the inputs. data is a dictionnary with keys : data and label\n",
        "    inputs, labels = ...,...\n",
        "    # TODO : Send the input through the model\n",
        "    outputs = ...\n",
        "    acc = accuracy(outputs.flatten(), labels)\n",
        "    running_acc += acc.item()\n",
        "\n",
        "print('Accuracy in Dataset Valid is ',running_acc/(len(dataset_validation)) )"
      ],
      "metadata": {
        "id": "KpXHil2tgzQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Is the accuracy better ?**"
      ],
      "metadata": {
        "id": "8Z3g5VCCtW-R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## d - Going Further on the FineTunable model \n"
      ],
      "metadata": {
        "id": "4fbtD6fxkF7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing the kernels\n",
        "\n",
        "We will pick few layers. Each layers should have learned different things. We are going to visualize the kernels and the output feature maps of certain layer to understand what type of information the model sees."
      ],
      "metadata": {
        "id": "YNM95e5-pgGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import utils\n",
        "\n",
        "def visTensor(tensor, ch=0, allkernels=False, nrow=8, padding=1): \n",
        "    n,c,h,w = tensor.shape\n",
        "    if allkernels: tensor = tensor.view(n*c, -1, w, h)\n",
        "    elif c != 3: tensor = tensor[:,ch,:,:].unsqueeze(dim=1)\n",
        "    rows = np.min((tensor.shape[0] // nrow + 1, 64))    \n",
        "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
        "    plt.figure( figsize=(nrow,rows) )\n",
        "    plt.imshow(grid.cpu().numpy().transpose((1, 2, 0)))\n",
        "\n",
        "# Visualize feature maps\n",
        "activation = {}\n",
        "def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        activation[name] = output.detach()\n",
        "    return hook"
      ],
      "metadata": {
        "id": "MbeQDkHBtYvV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We propose you these layers. But you can navigate through other layers in you want.\n",
        "layers = [model.backbone.features[1][2].block[0],\n",
        "          model.backbone.features[3][1].block[0],\n",
        "          model.backbone.features[5][26].block[0],\n",
        "          model.backbone.features[7][2].block[0],]\n",
        "\n",
        "# TODO : Select a layer from the layers list and visualize the kernel filters\n",
        "layer = ...\n",
        "filter = layer.weight.data.clone()\n",
        "visTensor(filter, ch=0, allkernels=False)\n",
        "plt.axis('off')\n",
        "plt.ioff()\n",
        "plt.show()  "
      ],
      "metadata": {
        "id": "nyXjIdlpkbAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **What can you see on the kernels ?**\n",
        "* **How are the kernels in the first layers ?**\n",
        "* **How are the kernels in the later layers ?**"
      ],
      "metadata": {
        "id": "WATg5XXStoff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing the Feature Maps\n",
        "Now let's forward an Image to see what the feature maps are. We put some Hooks inside the model. These Hooks will capture the feature maps at the given layers. If you were in the AI Option in 2a, this is what we did for Style Transfer"
      ],
      "metadata": {
        "id": "pUjlFnvoplES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Plot the Input Image**"
      ],
      "metadata": {
        "id": "9t85n9kxt1yN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = iter(iter(dataset_validation)).next()\n",
        "data = data['data'][0,...].float()\n",
        "# TODO : plot the image\n",
        "plt.imshow(... .permute(1,2,0))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "es49zxMOt2Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hook1 = layers[0].register_forward_hook(get_activation('conv1'))\n",
        "hook2 = layers[1].register_forward_hook(get_activation('conv2'))\n",
        "hook3 = layers[2].register_forward_hook(get_activation('conv3'))\n",
        "hook4 = layers[3].register_forward_hook(get_activation('conv4'))\n",
        "\n",
        "data.unsqueeze_(0)\n",
        "output = model(data.to(device))\n",
        "\n",
        "act1 = activation['conv1'].squeeze().cpu()\n",
        "act2 = activation['conv2'].squeeze().cpu()\n",
        "act3 = activation['conv3'].squeeze().cpu()\n",
        "act4 = activation['conv4'].squeeze().cpu()\n",
        "\n",
        "\n",
        "def plot(act,nf = 50):\n",
        "  fig, axarr = plt.subplots(1,nf)\n",
        "  fig.set_figheight(300)\n",
        "  fig.set_figwidth(300)\n",
        "  for idx in range(nf):\n",
        "    axarr[idx].imshow(act[idx])\n",
        "  plt.show() \n",
        "\n",
        "# TODO : Plot every activations. What can you tell on the feature maps.\n",
        "plot(...)\n",
        "plot(...)\n",
        "plot(...)\n",
        "plot(...)\n",
        "\n",
        "hook1.remove()\n",
        "hook2.remove()\n",
        "hook3.remove()\n",
        "hook4.remove()"
      ],
      "metadata": {
        "id": "SSuHNDlHoEYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(hook1, hook2, hook3, hook4)\n",
        "del hook1, hook2, hook3, hook4\n"
      ],
      "metadata": {
        "id": "UkKYjhgtwihA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **How are the feature maps in the earlier layers?**\n",
        "* **How are the features maps in the later layers?**"
      ],
      "metadata": {
        "id": "o2Md1s4AkWYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Changing the Backbone\n",
        "\n",
        "You can change the models.backbone for another one. Change the Backbone for a ResNext, VGG .. and retrain the model. And visualize the kernels and feature map "
      ],
      "metadata": {
        "id": "pPVbQwQh1rCB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GiHzpWIF17yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hidden Cell"
      ],
      "metadata": {
        "id": "0XwQAkGZaVwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1WLR1bsp73aFNhCjX8ibxi0DAUrUfTVru\n",
        "from google.colab.patches import cv2_imshow\n",
        "from secours import *\n",
        "from torchmetrics import Accuracy\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "path_train = '/content/train/'\n",
        "path_test ='/content/test1/'\n",
        "train_images = return_files(path_train)\n",
        "test_images = return_files(path_test)\n",
        "device = 'cuda'\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Resize((232,232)),\n",
        "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "dataset_train = IntermediateDataset(train_images, transform)\n",
        "\n",
        "train_size = int(0.8 * len(dataset_train))\n",
        "test_size = len(dataset_train) - train_size\n",
        "\n",
        "dataset_train, dataset_validation = torch.utils.data.random_split( dataset_train, [train_size, test_size])\n",
        "dataset_test = IntermediateDataset(test_images, transform)\n",
        "\n",
        "bs = 20\n",
        "dataset_train = DataLoader(dataset_train, batch_size = bs)\n",
        "dataset_test = DataLoader(dataset_test, batch_size = bs)\n",
        "dataset_validation = DataLoader(dataset_validation, batch_size=bs)"
      ],
      "metadata": {
        "id": "UYAFo5htaPOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# See you in TP"
      ],
      "metadata": {
        "id": "kysBq5U3GJho"
      }
    }
  ]
}