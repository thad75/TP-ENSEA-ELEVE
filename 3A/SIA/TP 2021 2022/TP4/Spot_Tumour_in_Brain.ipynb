{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/thad75/TP_ENSEA_ELEVE/blob/main/SIA/TP4/Spot_Tumour_in_Brain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5H0sZHGS09R"
   },
   "outputs": [],
   "source": [
    "!pip install gdown\n",
    "!gdown --id 1A2IU8Sgea1h3fYLpYtFb2v7NYdMjvEhU\n",
    "!tar -xf /content/Task01_BrainTumour.tar\n",
    "!pip install pybids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M25QtNgWcmFi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "def get_decathlon_filelist(data_path, seed=816, split=0.85):\n",
    "    \"\"\"\n",
    "    Get the paths for the original decathlon files\n",
    "    \"\"\"\n",
    "    json_filename = os.path.join(data_path, \"dataset.json\")\n",
    "\n",
    "    try:\n",
    "        with open(json_filename, \"r\") as fp:\n",
    "            experiment_data = json.load(fp)\n",
    "    except IOError as e:\n",
    "        raise Exception(\"File {} doesn't exist. It should be part of the \"\n",
    "              \"Decathlon directory\".format(json_filename))\n",
    "\n",
    "    # Print information about the Decathlon experiment data\n",
    "    print(\"*\" * 30)\n",
    "    print(\"=\" * 30)\n",
    "    print(\"Dataset name:        \", experiment_data[\"name\"])\n",
    "    print(\"Dataset description: \", experiment_data[\"description\"])\n",
    "    print(\"Tensor image size:   \", experiment_data[\"tensorImageSize\"])\n",
    "    print(\"Dataset release:     \", experiment_data[\"release\"])\n",
    "    print(\"Dataset reference:   \", experiment_data[\"reference\"])\n",
    "    print(\"Dataset license:     \", experiment_data[\"licence\"])  # sic\n",
    "    print(\"=\" * 30)\n",
    "    print(\"*\" * 30)\n",
    "\n",
    "    \"\"\"\n",
    "\tRandomize the file list. Then separate into training and\n",
    "\tvalidation lists. We won't use the testing set since we\n",
    "\tdon't have ground truth masks for this; instead we'll\n",
    "\tsplit the validation set into separate test and validation\n",
    "\tsets.\n",
    "\t\"\"\"\n",
    "    # Set the random seed so that always get same random mix\n",
    "    np.random.seed(seed)\n",
    "    numFiles = experiment_data[\"numTraining\"]\n",
    "    idxList = np.arange(numFiles)  # List of file indices\n",
    "    np.random.shuffle(idxList) # Shuffle the indices to randomize train/test/split\n",
    "    \n",
    "    trainIdx = int(np.floor(numFiles*split)) # index for the end of the training files\n",
    "    trainList = idxList[:trainIdx]\n",
    "\n",
    "    otherList = idxList[trainIdx:]\n",
    "    numOther = len(otherList)\n",
    "    otherIdx = numOther//2  # index for the end of the testing files\n",
    "    validateList = otherList[:otherIdx]\n",
    "    testList = otherList[otherIdx:]\n",
    "\n",
    "    trainFiles = []\n",
    "    for idx in trainList:\n",
    "        trainFiles.append(os.path.join(data_path, experiment_data[\"training\"][idx][\"label\"]))\n",
    "\n",
    "    validateFiles = []\n",
    "    for idx in validateList:\n",
    "        validateFiles.append(os.path.join(data_path, experiment_data[\"training\"][idx][\"label\"]))\n",
    "\n",
    "    testFiles = []\n",
    "    for idx in testList:\n",
    "        testFiles.append(os.path.join(data_path, experiment_data[\"training\"][idx][\"label\"]))\n",
    "\n",
    "    print(\"Number of training files   = {}\".format(len(trainList)))\n",
    "    print(\"Number of validation files = {}\".format(len(validateList)))\n",
    "    print(\"Number of testing files    = {}\".format(len(testList)))\n",
    "\n",
    "    return trainFiles, validateFiles, testFiles\n",
    "\n",
    "trainFiles, validateFiles, testFiles = get_decathlon_filelist(\"/content/Task01_BrainTumour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKD4P4Ap_agO"
   },
   "source": [
    "# Goal of this Lab\n",
    "\n",
    "* Work like a Deep Learning Engineer\n",
    "* Apply all things you've learned through all the labs\n",
    "* Understand your Datasets\n",
    "* Try models from your knowledge\n",
    "\n",
    "Don't hesitate to discuss with your lab coworkers in order to gather ideas. Feel free to use whatever framework you need. Understand as much possible the dataset before beginning to work on the model. Do your research ...\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**You are free of all your decisions. Any unjustified move will not be taken into consideration into your notation. An analysis of your results/model/move is awaited.**\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Timing approx :\n",
    "\n",
    "* 2 hours : Data Understanding/Dataset writing\n",
    "* 30min -1h : Model/ Training pipeline writing & training\n",
    "* 1h-1h30 : Results understanding and showcase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLUljJvy_jXk"
   },
   "source": [
    "# Main Question\n",
    "\n",
    "** Build a Model that spots and show Tumour in Brain MRI scanners. **\n",
    "\n",
    "As a helper, we give you some indications :\n",
    "* get_decathlon_filelist gives you an iterable over the nii.gz files of the label datasets. In order to get the training images replace labelsTr by imagesTr (as shown in the next cell). \n",
    "* nii.gz files are NIFTI files. They are used for medical imaging. In order to read nii.gz files, look at the next cell.\n",
    "* The tumour is any value > 0 in a slice in the label NIFTI file. Every slice is not as important as others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vDzpcbyyB9t_"
   },
   "outputs": [],
   "source": [
    "trainFiles_label = trainFiles\n",
    "trainFiles_images = [i.replace('labelsTr', 'imagesTr') for i in trainFiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "Qi5-7X5yS9uj",
    "outputId": "8b07e122-d1ff-4607-9663-7d2ac1a5fc2f"
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = np.array(nib.load(trainFiles_images[127]).dataobj) # To get the array of the NIFTI file in trainFiles image\n",
    "img_label = np.array(nib.load(trainFiles_label[127]).dataobj) # To get the array of the NIFTI file in trainFiles label\n",
    "\n",
    "img = (img - img.min()) / (img.max() - img.min()) # Some type of normalization, Choose wisely\n",
    "label = (img_label - img_label.min()) / (img_label.max() - img_label.min()) # Some type of normalization, Choose wisely\n",
    "label[label>0] = 1 # Highlighting the tumour\n",
    "\n",
    "\n",
    "# Showcase \n",
    "slice_value = 76 # Try different values to understand what this is\n",
    "plt.imshow(label[:,:,slice_value])\n",
    "plt.title('Tumour in slice %s' % slice_value)\n",
    "plt.show()\n",
    "plt.imshow(img[:,:,slice_value])\n",
    "plt.title('MRI scan of slice %s' % slice_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iLS6CYD3VHr8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN0xNtsscoFaAVPEizVUBSs",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Tumour in Brain.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
