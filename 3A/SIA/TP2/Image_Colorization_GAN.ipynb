{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Image_Colorization_GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thad75/TP_ENSEA_ELEVE/blob/main/SIA/TP2/Image_Colorization_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyqhdSa_M3OR"
      },
      "source": [
        "# TP GAN : Image Colorization\n",
        "\n",
        "Approximate Time : 2h (if lucky)\n",
        "\n",
        "The goal of this lab is to make you understand a certain type of GAN : conditional GANs. You will train a model to predict the colors of an Black and White image.\n",
        "\n",
        "Goal of this lab :               \n",
        "* Understand GANs and cGANs\n",
        "* Apply your knowledge on Adversarial Generative Learning\n",
        "* Use Pytorch Lightning with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_TyxsJ0evBE"
      },
      "source": [
        "!pip install pytorch-lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3De7ApQHRXRW"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "import cv2 as cv\n",
        "from google.colab.patches import cv2_imshow\n",
        "import pytorch_lightning as pl\n",
        "imageimagefrom pytorch_lightning import LightningDataModule, LightningModule, Trainer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlWAnIdTNkEs"
      },
      "source": [
        "# Colorization\n",
        "\n",
        "The task of colorization is :             \n",
        "Given a Black and White input image, find colors of regions of the image.\n",
        "More technically speaking, we will move the image from the RGB space to the La*b* space and regress two specific channels.\n",
        "\n",
        "* What is the Lab space ? define each terms of the Lab space\n",
        "* Which channel(s) do you think the model should create ?\n",
        "\n",
        "For this lab, we will use the CIFAR10 Dataset (Again :D). \n",
        "* What modification should we make on the existing CIFAR10 dataset from torchvision ? Using skimage library, make those changes.\n",
        "* Is normalization needed ?\n",
        "\n",
        "\n",
        "Please take in notice that the CIFAR10_Colorization Dataset inherits from CIFAR10 dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfgvvP1QsZs8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "class CIFAR10_Colorization(CIFAR10):\n",
        "  def __init__(self, directory, train= True, download = True):\n",
        "    self.directory = directory\n",
        "    self.train = train\n",
        "    self.download_data = download\n",
        "    super(CIFAR10_Colorization, self).__init__(root = self.directory, train = self.train, download = self.download_data)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img = \n",
        "\n",
        "    return {'L': L, 'ab':ab ,'image': img} # L, ab\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgkG9hKlSu88"
      },
      "source": [
        "Define your train, val, test Datasets and Dataloaders. Feel free to use a LightningDataModule"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlFMjl1XdWgp"
      },
      "source": [
        "class CIFARDataModule(LightningDataModule):\n",
        "    def __init__(self, directory, batch_size, download=True):\n",
        "        self.directory = directory\n",
        "        self.batch_size = batch_size\n",
        "        self.download = download \n",
        "\n",
        "    def setup(self, stage=None):\n",
        "      if stage == \"fit\" or stage is None:\n",
        "        dataset_train = \n",
        "        self.dataset_train, _ = \n",
        "\n",
        "      if stage == \"test\" or stage is None:\n",
        "        self.dataset_test = \n",
        "    \n",
        "    def train_dataloader(self):\n",
        "       return \n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return \n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3VD3LbdsnYP"
      },
      "source": [
        "# Generative Adversarial Network\n",
        "\n",
        "* Before beginning anything, tell me a story to help me understand how GANs should work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lFS3W1oUHCX"
      },
      "source": [
        "In this lab, we will use a specific GAN : conditional GAN (cGAN).\n",
        "\n",
        "<img src='https://www.researchgate.net/profile/Gerasimos-Spanakis/publication/330474693/figure/fig1/AS:956606955139072@1605084279074/GAN-conditional-GAN-CGAN-and-auxiliary-classifier-GAN-ACGAN-architectures-where-x_Q320.jpg'>\n",
        "\n",
        " On the contrary of a normal GAN, cGAN has a condition that will help us CONTROL how the GAN should generate images. The generator will take some \"inspiration\" from the Condition. For example, if you want to generate digits from the MNIST Dataset, you can add a condition to force the GAN to create a specific Digit. In this case, the condition would be the class label.\n",
        "\n",
        "An interesting paper for you to read : https://arxiv.org/pdf/1411.1784.pdf\n",
        "\n",
        "We are going to color images "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA3_M7kcYl1w"
      },
      "source": [
        "# A closer look into the world of GANs\n",
        "\n",
        "*  What are the component of a GAN ?\n",
        "* What is the purpose of each of them ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBIaPLQLspdN"
      },
      "source": [
        "# Generator\n",
        "\n",
        "In general, the Generator is here to generate Data from input Noise. For example if we train a GAN on MNIST dataset, the generator will create digits using the noise we give it as input. \n",
        "\n",
        "* What type of model can recreate images ?\n",
        "\n",
        "In this lab, we are dealing with cGANs, so we need a Condition to condition our GAN. \n",
        "* What could be the condition ? To answer that :\n",
        "  * What are we trying to do ?\n",
        "  * What should the Generator do ? Should it recreate some things specific ?\n",
        "\n",
        "Using that specific model, create a Generator that takes as your condition. (Are you puzzled ?)\n",
        "\n",
        "Hint : There are 3 parts in this lab. One of the lab recreates images. Feel free to reimport it and modify it :)\n",
        "\n",
        "\n",
        "We give you some skeleton of models if needed. But if your previous model work, import it.\n",
        "\n",
        "HINT : The following Conv2D channels work well (3 => 64 => 128 => Latent_Size)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47Fe_XzAbMUj"
      },
      "source": [
        "class ConvDown(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "      super(ConvDown, self).__init__()\n",
        "  def forward(self,x):\n",
        "      return self.model(x)\n",
        "\n",
        "class ConvUp(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "      super(ConvUp, self).__init__()\n",
        "  def forward(self,x):\n",
        "      return self.model(x)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, in_channels, latent_size):\n",
        "    super(Encoder, self).__init__()\n",
        "  def forward(self, x):\n",
        "    return self.encoder(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, latent_size, out_channels):\n",
        "    super(Decoder, self).__init__()\n",
        "  def forward(self, x):\n",
        "    return self.decoder(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, in_channels, latent_size, out_channels):\n",
        "    super(Generator, self).__init__()\n",
        "    self.encoder = \n",
        "    self.decoder = \n",
        "\n",
        "  def forward(self, x):\n",
        "    _ = self.encoder(x)\n",
        "    generated_image = self.decoder(_)\n",
        "    return generated_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na-6h-v_di38"
      },
      "source": [
        "# Discriminator\n",
        "\n",
        "Now that the generator is able to create Data, we need someone to put down the Generator's knowledge : the Discriminator.\n",
        "\n",
        "The Discriminator is here to force the Generator to create better and better images. While the Generator brings bad quality representation, the Discriminator will not be happy.\n",
        "\n",
        "<img src=\"https://i.pinimg.com/474x/88/9d/1b/889d1b3f74b7c20c845f2a2f7db2ca8a.jpg\">\n",
        "\n",
        "* What task is the Discriminator performing ? \n",
        "* Create a Discriminator. \n",
        "* What must be the output of the model ?\n",
        "\n",
        "* HINT :  The following Conv2D channels work well (in_channels => 3 => 32 => 64 => 128 => out_channels).\n",
        "* HINT 2 : Add LeakyRelu with slope 0.2 to avoir Vanishing Gradient. Add batchNormalization\n",
        "\n",
        "* What is Vanishing Gradient ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxCHEJ8Sgmxb"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.main = nn.Sequential(\n",
        "        # 3x32x32\n",
        "        nn.Conv2d(in_channels = in_channels,\n",
        "                  out_channels = 32,\n",
        "                  kernel_size = 3,\n",
        "                  stride = 2,\n",
        "                  padding = 1),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # 32x16x16\n",
        "        nn.Conv2d(in_channels = 32,\n",
        "                  out_channels = 64,\n",
        "                  kernel_size = 4,\n",
        "                  stride = 2,\n",
        "                  padding = 1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        nn.Conv2d(in_channels = 64,\n",
        "                  out_channels = 128,\n",
        "                  kernel_size = 4,\n",
        "                  stride = 2,\n",
        "                  padding = 1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # 128x4x4\n",
        "        nn.Conv2d(in_channels = 128,\n",
        "                  out_channels = out_channels,\n",
        "                  kernel_size = 3,\n",
        "                  bias=False),\n",
        "\n",
        "    )\n",
        "\n",
        "  def forward(self, input):\n",
        "    input = input \n",
        "    return self.main(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PAq9ySPd8tr"
      },
      "source": [
        "# Loss : Let's battle\n",
        "\n",
        "Now that we have our separate models created, we need to put them together. But before that let's read some boring formulas.\n",
        "\n",
        "<img src=\"https://miro.medium.com/proxy/1*QB05s3iiTDYlJ8ck-qoI_Q.png\">\n",
        "\n",
        "Beautiful formula's no ? Let's understand them like humans.\n",
        "* What is x, y, z in our Case ? \n",
        "* What loss is it ?\n",
        "* Which term is the Discriminator loss ? Generator loss ?\n",
        "* From the small story on how GAN should work (asked at the beginning), how should the Discriminator and Generator behave ? What does it mean on the loss ?\n",
        "\n",
        "We also add an L1 loss for better correpondance between colors.\n",
        "<img src=\"https://www.oreilly.com/library/view/machine-learning-with/9781787121515/assets/a98f39f2-ef47-4747-ace5-12eed888d600.png\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHw4kzwMf5ry"
      },
      "source": [
        "Let's define a class defining the GAN Loss. \n",
        "* What are the labels if the input are Real ? Fake ?\n",
        "* What should be the size of the Label regarding the Output of the Discriminator ?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKykwI74f4eX"
      },
      "source": [
        "class GANLoss(nn.Module):\n",
        "      def __init__(self, real_label=1, fake_label=0, device = None):\n",
        "        super().__init__()\n",
        "        self.loss = nn.BCEWithLogitsLoss()\n",
        "        self.real_label = real_label\n",
        "        self.fake_label = fake_label\n",
        "        self.device = device\n",
        "\n",
        "      def get_labels(self, predictions, real_or_not):\n",
        "          if real_or_not :\n",
        "              labels = \n",
        "          else : \n",
        "              labels = \n",
        "          return torch.tensor(_).expand_as(_).to(self.device)\n",
        "      \n",
        "      def forward(self, predictions, real_or_not ):\n",
        "          return "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8NW0p0lsrKY"
      },
      "source": [
        "# GAN\n",
        "\n",
        "Let's form our GAN. Let's use the Lightning Framework. If you want you can obviously not use the Lightning framework and use Vanilla PyTorch.\n",
        "\n",
        "\n",
        "The training of a GAN occurs in mulitple steps. The training is done one after the other. For example, we train the Generator and then the Discriminator. We want to get to the Nash Equilibrium.\n",
        "\n",
        "Let's define all the terms of our GAN LightningModule. \n",
        "* Let's configure our model first. Define your generator and your discriminator.\n",
        "* Let's configure our optimizer(s?) :\n",
        "  * What optimizer would you use ? How many of them ? \n",
        "  Coding wise, you have to return a list of optimizers if you use many.\n",
        "* Let's get to the training loop.\n",
        "  * You have to train once the generator then the discriminator. The training_step method has an optimizer_idx input which allows you to choose which model you will train.\n",
        "\n",
        "Now Let's get to the cGAN. How would you train it ?  Let's discuss :)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " <img src=\"data:image/png;base64,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\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_v_32dwg6Ny"
      },
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "class GAN(pl.LightningModule):\n",
        "  def __init__(self ):\n",
        "    super().__init__()\n",
        "    self.generator = \n",
        "    self.discriminator = \n",
        "\n",
        "  def forward(self,x):\n",
        "    L = _\n",
        "    ab_fake = _\n",
        "    img_fake = torch.cat([_,_], dim=1).permute(0,2,3,1)\n",
        "    return img_fake\n",
        "\n",
        "\n",
        "\n",
        "  def training_step(self, train_batch, batch_idx, optimizer_idx):\n",
        "    #TODO:  send your L image through the Generator \n",
        "    self.L, self.condition = train_batch['L'].float().clone(), train_batch['ab'].float()\n",
        "    #TODO : define your loss\n",
        "    criterion = GANLoss(device = self.device).to(self.device)\n",
        "    criterionL1 = nn.L1Loss()\n",
        "    if optimizer_idx == 1:\n",
        "    #TODO: Train discriminator \n",
        "\n",
        "        #Question: When does this step occurs ?\n",
        "        #TODO : Recreate the images and calculate the mean of Loss(es)\n",
        "        recolored_image =\n",
        "        fake_prediction = \n",
        "\n",
        "        real_image = \n",
        "        real_prediction =  \n",
        "        #TODO : Calculate Loss(es)\n",
        "        loss_fake = criterion(fake_prediction,real_or_not = False)\n",
        "        loss_real = criterion(real_prediction, real_or_not = True)\n",
        "\n",
        "        loss =(loss_real + loss_fake)/2\n",
        "        return loss\n",
        "\n",
        "    if optimizer_idx == 0 :\n",
        "    #TODO : Train generator \n",
        "        #TODO : Generate Fake Color and create image\n",
        "        self.fake_color = \n",
        "        recolored_image = \n",
        "        #TODO : Send to Discriminator for review\n",
        "        fake_prediction = \n",
        "        #TODO : Calculate Loss(es)\n",
        "        loss_true =                         #GAN LOSS : let's fight\n",
        "        loss_l1 =                           #L1 LOSS : Distance between created and real\n",
        "        return loss_true + loss_l1*100\n",
        "\n",
        "  def validation_step(self, val_batch, batch_idx):\n",
        "      #TODO : write validation step\n",
        "\n",
        "\n",
        "  def test_step(self, val_batch, batch_idx):\n",
        "      #TODO : write test step\n",
        "\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "      #Questions : How many optimizers will you define ? Why ? Use Adam\n",
        "      lr = 2e-4\n",
        "      beta1=0.005 #What is it \n",
        "      beta2=0.999 #What is it ?\n",
        "      optimizer_generator = _\n",
        "      optimizer_discriminator = _\n",
        "      return [optimizer_generator, optimizer_discriminator], []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI_q8Pk21DoA"
      },
      "source": [
        "# Let's Train\n",
        "\n",
        "If you continue in Deep Learning and work with GANs, you will see that it is a pain in the ass to train. \n",
        "* What could be the optimal training scenario ? How would the losses behave ?\n",
        "* What could be the other cases ? How would the losses behave ?\n",
        "\n",
        "Draw a small image showing the different cases. ADD IT ON YOUR SLIDES.\n",
        "\n",
        "Now let's try to train your model. The training will be quite long (At least 15 epochs to see some results). So you can either grab a Coffee (or Do your slides?)\n",
        "\n",
        "\n",
        "FEEL FREE TO LOAD A TENSORBOARD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JffeDds1dMbD"
      },
      "source": [
        "dm = CIFARDataModule(directory ='./path', batch_size =512)\n",
        "model = GAN()\n",
        "trainer = Trainer(gpus=-1, max_epochs=20)\n",
        "trainer.fit(model, dm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K29wObJpEwhh"
      },
      "source": [
        "trainer.test(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pDjAlDN-Wms"
      },
      "source": [
        "# Let's test the model \n",
        "\n",
        "Now that your model learned something. Let's test it on the test dataset. \n",
        "Did it work ? How would you evaluate your work ?\n",
        "* If yes, show us some examples ? \n",
        "* If no, tell us explain **why your training was not good and what happened during your training**. Give us some axis of amelioration of your model. And if you have some time, try it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNHbo8CPhzFO"
      },
      "source": [
        "import skimage\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#TODO: Load your checkpoint into your model.\n",
        "model = GAN().load_from_checkpoint(_)\n",
        "\n",
        "\n",
        "\n",
        "for i, data in enumerate(test_loader):\n",
        "\n",
        "  L, ab, img   = data['L'], data['ab'], data['image']\n",
        "  predictions = model(L) #Send image to model, Depending on your forward you might need to concatenate things.\n",
        "  prediction_rgb = lab2rgb()  #Convert to rgb\n",
        "  # Plot some images/\n",
        "  plt.imshow(prediction_rgb)\n",
        "  plt.show()\n",
        "  plt.imshow(img.squeeze(0).detach().cpu().numpy())\n",
        "  print()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7DksCvPgDsB"
      },
      "source": [
        "# Is the GAN really useful ?\n",
        "\n",
        "Open question :               \n",
        "\n",
        "* Do we really need a GAN to recolorize images ? \n",
        "* Can we do it with self supervised technics ? What could be the issues ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOIHpzi5-tXI"
      },
      "source": [
        "# Wanna Do it on pokemons ?\n",
        "\n",
        "* If you have a GPU and some videos of pokemons, you can try to recolore some episodes. "
      ]
    }
  ]
}