{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/thad75/TP_ENSEA_ELEVE/blob/main/3A/SIA/TP4/Attention_in_Finance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-iNSH47r3uu"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch-lightning\n",
    "!pip install wandb\n",
    "\n",
    "USE_COLAB = True\n",
    "CONTENT_DIR = \"/content\" if USE_COLAB else \".\"\n",
    "\n",
    "import wandb\n",
    "if not wandb.login():\n",
    "    raise ValueError(\"WandDB authentification failed.\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(42)\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import MNIST\n",
    "import cv2 as cv\n",
    "from google.colab.patches import cv2_imshow\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
    "from typing import Optional, List\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "def _get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAV2huZur75y"
   },
   "source": [
    "# Transformer : A Model Used Everywhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGZZ0bSCsCp8"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Goal of this lab :     \n",
    "\n",
    "\n",
    "*   Understand and code basic Transformer \n",
    "*   Introduction to Finance\n",
    "*  Understand your knowledge of deep learning.\n",
    "* Become Rich ?\n",
    "\n",
    "**Disclaimer : ANY NON ILLUSTRATED ANALYSIS WILL LEAD TO A 0 TO THE GIVEN PART**\n",
    "\n",
    "<img src =\"https://i.imgflip.com/6g1fwb.jpg?a463272\" height = 200>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RqzZHrcNQx5"
   },
   "source": [
    "We have seen through multiple labs industrial applications of Deep Learning models in Computer Vision. Now let's look at another task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7VWYvDMNpNt"
   },
   "source": [
    "# Transformer : Definitions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2nagjfnOO9p"
   },
   "source": [
    "## Model\n",
    "\n",
    "\n",
    "The transformer is a  network architecture based on attention mechanisms. It consists of an encoder-decoder architecture: \n",
    "* the encoder maps an input sequence of symbol representations $(x_1,…,x_n)$ to a sequence $z=(z_1,…,z_n)$ \n",
    "* the decoder, given $z$ , generates an output sequence $(y_1,…,y_m)$. \n",
    "\n",
    "At each time step, the model consumes the previously generated symbols as additional input when generating the next (it is auto-regressive) \n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*BHzGVskWGS_3jEcYYi6miQ.png\" width= 400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HJarJb4OuV-"
   },
   "source": [
    "## Positional Encoding\n",
    "\n",
    "Transformers work on a sequence of Data. Order does matter. \n",
    "Example :  \n",
    "\n",
    "\n",
    "> **Vivre pour manger =! Manger pour vivre.**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For recurrent networks (RNN, LSTM, GRU), the word positions are implicitly embedded inside the model since they are processed sequentially. The Transformer doesn't process sequentially the input. How can we specify the position of a Token ?\n",
    "The solution of the authors was to add a vector representing the position of the words to the embedding vectors: \n",
    "\n",
    "\n",
    "> **THE POSITIONAL ENCODING**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQKt23MiP10x"
   },
   "source": [
    "## Attention : The reason of this model\n",
    "\n",
    "Attention , self-attention and multi-head attention are the main component of this model. They let the model know that specific regions or tokens are interesting. They let the model take care of specific parts of the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyBltd6vNIiG"
   },
   "source": [
    "# Finance : Is attention all you need ?\n",
    "\n",
    "In this lab, we will try to create a model able to predict trends in Stock Values. This might be a foundation for a trading bot. We will use a Transformer Encoder to perform this task.\n",
    "\n",
    "Feel free to download any stock you want.\n",
    "Some examples of stock : \n",
    "* S&P500 : https://finance.yahoo.com/quote/%5EGSPC/history?p=%5EGSPC , https://www.investing.com/indices/us-spx-500-historical-data, https://www.nasdaq.com/market-activity/index/spx/historical\n",
    "* Bitcoin : https://finance.yahoo.com/quote/BTC-USD/history?p=BTC-USD\n",
    "* Gold : https://finance.yahoo.com/quote/GC%3DF/history?p=GC%3DF\n",
    "* ...\n",
    "\n",
    "To download your csv file, go on the Historical Data tab, choose a Time Period and Download your file.\n",
    "\n",
    "**Important : Make sure that you have a historical data of a long period of time.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMvRTGC20mSu"
   },
   "source": [
    "### I - Time Series : A Different Dataset\n",
    "\n",
    "Time Series are a series of data points indexed by time. We often treat them by sequence of equally spaced points in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7QlOkOU1RY9"
   },
   "source": [
    "#### a - EDA : What Trends in your stock ?\n",
    "\n",
    "Let's read your stock file. As a Data Scientist, you will be asked to explore data before doing anything. Data Exploration is needed for data understanding and preprocessing.\n",
    "* Using Pandas perform a full Exploratory Dataset Analysis.\n",
    "\n",
    "Feel free to read the documentation of each library. It will be needed to perform anything\n",
    "\n",
    "Is expected : \n",
    "* A description of the stock\n",
    "* A summary of the features \n",
    "* What could be the trend for next week ?\n",
    "* Plots of the useful features.\n",
    "* Correlation between features.\n",
    "\n",
    "Some useful libraries :    \n",
    "* To read a csv file : use **pandas** library and read_csv method\n",
    "* **seaborn** is a useful library that processes a pandas dataframe \n",
    "* **matplotlib** is your old friend\n",
    "\n",
    "Some useful methods :    \n",
    "* In pandas : \n",
    "  * head() \n",
    "  * describe()\n",
    "* In seaborn:\n",
    " * displot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsNFiWHp1NgU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df= pd.read_csv(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d1HVkhWSbMSK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ya7-5jyUqv-c"
   },
   "source": [
    "#### b - Creating a Stock Dataset\n",
    "\n",
    "As you might have seen, multiple features are available in the dataset. We will use the attention mecanism to process 5 of the given features. We will use the following features :    \n",
    "* Open\n",
    "* High\n",
    "* Low\n",
    "* Close\n",
    "* Volume\n",
    "\n",
    "We are going to create a Dataset that is conform to Pytorch Dataset class.\n",
    "The Dataset should take as input :\n",
    "*    Dataframe(s?)\n",
    "*    $N_{window}$ : length of the sequence \n",
    "\n",
    "\n",
    "We're feeding the model Time Series which are sequential datas. Each data $p_{i}$ is part of a sequence of length $N_{window}$. We want to predict what could happen after that data. We are sending the data thanks to a sliding non overlapping window of size $N_{window}$. \n",
    "\n",
    "In fact, we will be sending $N_{window}$ sequences to the model to learn how to approximate  $f( W_t) \\approx W_{t+1}$ \\\n",
    "where :\n",
    "\n",
    "\n",
    "$W_t = (p_{t_{w}}, p_{t_{w+1}}, \\dots, p_{(t+1)_{w-1}})$\n",
    "\n",
    "We want the dataset to return the following:\n",
    "for \n",
    "\n",
    "*    $N_{window}$ = 3\n",
    "\n",
    "\n",
    "$\\text{Input}_1 = [p_0, p_1, p_2], \\text{Label}_1 = [p_3, p_4, p_5]$ \\\n",
    "\n",
    "\n",
    "$\\text{Input}_3 = [p_6, p_7, p_8], \\text{Label}_3 = [p_9, p_{10}, p_{11}]$\n",
    "\n",
    "__getitem__ method should return a dictionnary where : \n",
    "*   dict['input'] : is a list of $N_{window}$ input values\n",
    "* dict['label'] : is a list of $N_{window}$ target values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRJG6afmrdPD"
   },
   "outputs": [],
   "source": [
    "class StockDataset(Dataset):\n",
    "\n",
    "  def __init__(self, df,N_window,normalized = True,num_steps =1):\n",
    "      self.df = df\n",
    "      self.df.dropna(how='any', axis=0,inplace= True)\n",
    "      self.N_window = N_window\n",
    "      self.num_steps =num_steps\n",
    "      self.normalized = normalized\n",
    "      self.X, self.y = self.process_df()\n",
    "\n",
    "  def process_df(self):\n",
    "      \"\"\"\n",
    "      process method should return X,y: \n",
    "      * X is an array of num_steps*N_windows input values\n",
    "      * y is an array of corresponding target values\n",
    "      \"\"\"\n",
    "      scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "      data_raw= self.df.to_numpy()\n",
    "      close = self.df['Close'].to_numpy()\n",
    "      open = self.df['Open'].to_numpy()\n",
    "      high = self.df['High'].to_numpy()\n",
    "      low = \tself.df['Low'].to_numpy()\n",
    "      volume = self.df['Volume'].to_numpy()\n",
    "\n",
    "      if self.normalized : \n",
    "        close = scaler.fit_transform(close.reshape(-1, 1))\n",
    "        open = scaler.fit_transform(open.reshape(-1, 1))\n",
    "        high = scaler.fit_transform(high.reshape(-1, 1))\n",
    "        low = \tscaler.fit_transform(low.reshape(-1, 1))\n",
    "        volume = scaler.fit_transform(volume.reshape(-1, 1))\n",
    "\n",
    "      data_raw= np.stack([close,open,high,low,volume])\n",
    "      assert len(close)==len(open)==len(high)==len(low)==len(volume)\n",
    "\n",
    "      # TODO : Create a list of sequences of N_window elements\n",
    "      seq = ...\n",
    "      # TODO : Return an array of sequences where X is the input values and y the target values               \n",
    "      X = ...\n",
    "      y = ...\n",
    "      return X,y\n",
    "\n",
    "  def __len__(self):\n",
    "      '''\n",
    "      Be careful on your len because of the overlapping issues\n",
    "      '''\n",
    "      # TODO : What is the len of the dataset ?\n",
    "      return ...\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "      \"\"\"\n",
    "      __getitem__ method should return a dictionnary where : \n",
    "      * dict['input'] : is a list of num_{steps} lists of N_{window} elements\n",
    "      * dict['label'] : is a list of N_{window} target value\n",
    "      \"\"\"\n",
    "      # TODO : Return one element\n",
    "      x = ...\n",
    "      y = ...\n",
    "      return {'input': x.squeeze(-1), \n",
    "              'label':y.squeeze(-1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQh8P6nauOUM"
   },
   "outputs": [],
   "source": [
    "# TODO : Verify that your Dataset is correct.\n",
    "\n",
    "df = ...\n",
    "N_window = ...\n",
    "normalized = ...\n",
    "dataset = StockDataset(df = ...,\n",
    "                       N_window = ...,\n",
    "                       normalized = ...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoD75GvwtfT_"
   },
   "source": [
    "At this moment, each samples will be a dictionnary with a sequence. However, one important feature is hidden in our stock price but we need a proper way to use it. \n",
    "* What feature are we talking about ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3zY-G3SrKxc"
   },
   "source": [
    "#### c- Creating the Lightning DataModule\n",
    "\n",
    "As usual create a Lightning Datamodule that encompasses everything. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53MZMTbbrYRT"
   },
   "outputs": [],
   "source": [
    "class StockDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,df,N_window, normalized, batch_size):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.N_window = N_window\n",
    "        self.normalized = normalized\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def setup(self, stage):\n",
    "        # First stage is 'fit' (or None)       \n",
    "\n",
    "        # TODO : Do we shuffle the datasets ? Why ?\n",
    "        X_train, X_test = train_test_split(self.df, shuffle=...)\n",
    "        X_train, X_valid = train_test_split(X_train, shuffle=...)\n",
    "\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            # We create a validation split to watch the training.\n",
    "            # TODO : As usual\n",
    "            self.stock_train =  StockDataset(...)\n",
    "            self.stock_valid =  StockDataset(...)\n",
    "\n",
    "        # Second stage is 'test' \n",
    "        if stage == \"test\" or stage is None:\n",
    "            # TODO : As usual\n",
    "            self.stock_test =  StockDataset(...)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.stock_train, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.stock_valid, self.batch_size, shuffle=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.stock_test,self.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tpRHAcYNda6M"
   },
   "outputs": [],
   "source": [
    "# TODO : Initialize your datamodule\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ilwKU725epE"
   },
   "source": [
    "### II - Positional Encoding : Incorporating Time to the features with Time2Vector\n",
    "\n",
    "Transformers use a posiional encoding to provide a sense of word order in a sequence. However, these positional encodings doesn't provide any sens of time. In that way, Time2Vector is a model-agnostic vector representation for time. The main idea of this vector is that : \n",
    "* a meaningful representation of time has to include both periodic and non-periodic patterns.\n",
    "* a time representation should have an invariance to time rescaling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Nt2LXf58vHu"
   },
   "source": [
    "\n",
    "Specifically, a Time2Vec Layer is defined as :    \n",
    "<img src =\"data:image/png;base64,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\" width = 400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmokwVTV8lUL"
   },
   "source": [
    "* $\\mathcal{F}$ is a periodic function for e.g. sin or cos\n",
    "* $w_i$, $\\varphi_{i}$   are learnable parameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPonGx6A0UWm"
   },
   "source": [
    "Let's create a Time2Vec Layer. We need non-periodic feature and a periodic feature.\n",
    "* To your opinion is there a useless feature to exclude of this time embedding ?\n",
    "* Why ?\n",
    "\n",
    "\n",
    "\n",
    "**Important Disclaimer : Usually we add our positional encoding to our input tensor. However, in our case we will concatenate it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iW3jL4sE9bDm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class Time2Vector(nn.Module):\n",
    "\n",
    "  def __init__(self,in_features):\n",
    "      super().__init__()\n",
    "      self.in_features = in_features \n",
    "      self.w0 = nn.parameter.Parameter(torch.randn(1,1), requires_grad =True)\n",
    "      self.b0 = nn.parameter.Parameter(torch.randn(in_features, 1), requires_grad =True)\n",
    "      self.w = nn.parameter.Parameter(torch.randn(1,1), requires_grad =True)\n",
    "      self.b = nn.parameter.Parameter(torch.randn(in_features, 1), requires_grad =True)\n",
    "      self.f = torch.sin\n",
    "\n",
    "\n",
    "  def forward(self,x):\n",
    "      bs,seq_len,n_feat = x.shape\n",
    "      # TODO : Exclude the unwanted feature and compute the mean along the last axis\n",
    "      x = ...\n",
    "\n",
    "      linear = x.unsqueeze(-1) \n",
    "      periodic = x.unsqueeze(-1)\n",
    "      linear = torch.matmul(linear,self.w0) + self.b0 \n",
    "      W = self.w.repeat(bs,1,1)\n",
    "      b = self.b.repeat(bs,1,1)\n",
    "      periodic = self.f(torch.bmm(periodic,W) + b) \n",
    "      return torch.cat([linear, periodic], -1).permute(0,2,1)\n",
    "\n",
    "# TODO : Verify the output of Time2Vector shape. It should be of shape (Batch Size, Sequence Length, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V0DesvfbB6wD"
   },
   "source": [
    "### III - Transformer : A Big Model around Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZIMEQz6LZ4u"
   },
   "source": [
    "We are going to build each modules of our Transformer model. The heart of the model resides in the Attention Mecanism. The goal of the Attention mecanism is to force the model to look at specific part of the input. We will build each component of the transformer part by part.\n",
    "\n",
    "\n",
    "Create the different components of the Transformer Encoder : \n",
    "* Attention Module\n",
    "* Multi-Head Attention Module\n",
    "* Transformer Encoder Layer\n",
    "* Transformer Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1bU8e0LCUiu"
   },
   "source": [
    "#### a - Attention layer\n",
    "\n",
    "Let's compute the attention layer. We will create a layer that computes Bandhanau's attention also called Dot Scale Product attention. The attention mecanism takes an input $X$ and project it using a set of queries, keys and values. Think of it as a Database which you query (with the queries) using a set of keys, which returns a set values.\n",
    "\n",
    "Mathematicaly speaking, we are computing the scaled dot product between $Q$, $K$, $V$\n",
    "\n",
    "\n",
    "The  attention is : \n",
    "$Attention(Q,K,V)$ =  $Softmax(\\frac{Q*K}{\\sqrt{dim}})$$*V$\n",
    "\n",
    "<img src=\"https://production-media.paperswithcode.com/methods/SCALDE.png\" height = 400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yoB68E2LDPBP"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "\n",
    "  def __init__(self, dim_query):\n",
    "    super().__init__()\n",
    "    self.dim_query = dim_query \n",
    "\n",
    "  \n",
    "  def forward(self,q,k,v):\n",
    "    # TODO : Compute the attention mecanism between q,k,v\n",
    "    attn = torch.bmm(...,...)/math.sqrt(self.dim_query)\n",
    "    attn = F.softmax(attn,-1)\n",
    "    context = torch.bmm(...,...)\n",
    "    return context, attn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q24Z5fwECRji"
   },
   "source": [
    "#### b - Multi head Attention \n",
    "\n",
    "Usually, we like creating a Multi-Head Attention layer. Multi-Head only means that we are computing the attention over multiple heads. In fact, instead of having only one function computed by the attention mecanism, we leave each head free to learn a different function. Hence, we will have different outputs each computing a different value.\n",
    "\n",
    "Mathematically speaking : \n",
    "\n",
    "$MultiHead(Q,K,V)=Concat(head_1,…,head_h)W^O$\n",
    "\n",
    "with $head_i=Attention(QW_i^Q,KW_i^K,VW_i^V).$\n",
    "\n",
    "\n",
    "<img src='https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTv6Bgq7bdnXdT-JDWEnnzK2EM1xY0NUEOyBg&usqp=CAU'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Asj6n9anTZ0j"
   },
   "source": [
    " Question :    \n",
    " * What is $W^O$ ? Is it a learned parameter ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cNzQxfhnFK4F"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "  def __init__(self, embed_dim, dim_query, dim_value,num_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        # Embed dim is the shape of the feature space\n",
    "        self.embed_dim = embed_dim\n",
    "        # Num Heads is the number of heads\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        self.w_query = nn.Linear(embed_dim, num_heads*dim_query)\n",
    "        self.w_key = nn.Linear(embed_dim, num_heads*dim_query)\n",
    "        self.w_value = nn.Linear(embed_dim, num_heads*dim_value)\n",
    "        self.linear = nn.Linear(num_heads*dim_value, embed_dim)\n",
    "        # Dim Query, Dim Value are the projected dimensions of each tensors\n",
    "        self.attention = Attention(dim_query)\n",
    "\n",
    "\n",
    "  def forward(self, query, key, value):\n",
    "\n",
    "      # TODO : Project your query, key, value into their respective heads\n",
    "      q = self.w_query(...)\n",
    "      k = self.w_key(...)\n",
    "      v = self.w_value(...)\n",
    "      # TODO : Compute the attention \n",
    "      attn, context  = self.attention(...,...,...) \n",
    "      attn = self.linear(attn)\n",
    "      return attn, context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9L27Af1C98Y"
   },
   "source": [
    "#### c - Transforming the Transformer\n",
    "\n",
    "So let's create our Transformer model. We will just create the Encoder, as we don't need the Decoder in our case. We are just trying to Encode the input and find interesting patterns.\n",
    "Usually we code the Transformer Model into a specific format :\n",
    "* Layer Class\n",
    "* Model Class\n",
    "\n",
    "<img src=\"https://www.researchgate.net/publication/334288604/figure/fig1/AS:778232232148992@1562556431066/The-Transformer-encoder-structure.ppm\" height=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zSo7KRdQPkhS"
   },
   "outputs": [],
   "source": [
    "# TODO : Create one Transformer Encoder Layer\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "\n",
    "  def __init__(self,embed_dim, dim_query, dim_value, num_heads, dim_feedforward= 256,dropout = 0.1):\n",
    "      super().__init__()\n",
    "      self.attention = MultiHeadAttention(embed_dim, \n",
    "                                          dim_query,\n",
    "                                          dim_value, \n",
    "                                          num_heads)\n",
    "\n",
    "      self.linear= nn.Sequential(nn.Linear(embed_dim, dim_feedforward),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(dropout), \n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(dim_feedforward, embed_dim))\n",
    "\n",
    "      self.norm1 = nn.LayerNorm(embed_dim)\n",
    "      self.norm2 = nn.LayerNorm(embed_dim)\n",
    "      self.dropout1 = nn.Dropout(dropout)\n",
    "      self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "\n",
    "  def forward(self, sequence):\n",
    "      q=k=v= sequence.double()\n",
    "      # TODO : Compute the attention \n",
    "      attn, context = ... \n",
    "      sequence = sequence + self.dropout1(attn)  \n",
    "      sequence = self.norm1(sequence)\n",
    "      sequence = self.linear(sequence)\n",
    "      sequence = sequence +  self.dropout2(sequence)\n",
    "      sequence = self.norm2(sequence)\n",
    "      return sequence\n",
    "\n",
    "# TODO : Create a Transformer Encoder. \n",
    "class TransformerEncoder(nn.Module):\n",
    "  def __init__(self, encoder_layer, num_layers):\n",
    "          super().__init__()\n",
    "          self.layers = _get_clones(encoder_layer, num_layers)\n",
    "          self.num_layers = num_layers\n",
    "\n",
    "  def forward(self, sequence):\n",
    "        output = sequence.permute(2,0,1)\n",
    "        for layer in self.layers:\n",
    "            # TODO : Send your Input to your transformer\n",
    "            output = layer(...)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OsWa6gmqVPoM"
   },
   "source": [
    "#### Building the entire model \n",
    "\n",
    "Finally let's build the entire model. Let's use Pytorch-Lightning to encompass everything. \n",
    "Normally your model must be composed of three components : \n",
    "* The Transformer\n",
    "* The Time2Vector \n",
    "* A Regression Head \n",
    "\n",
    "As usual ask yourself what task you are performing, how your data should travle trhough the model, what the data is, blablablablalablba\n",
    "\n",
    "Don't forget to use your favorite logger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1M5xOk8FVXtN"
   },
   "outputs": [],
   "source": [
    "class StockModel(pl.LightningModule):\n",
    "    def __init__(self,embed_dim,dim_query,dim_value, num_layers, num_heads):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        # TODO : Define your model here, be careful, your model will be an instance of the class. Watch  out for the input data.\n",
    "        # TOOD : Define your Encoder Layer\n",
    "        encoder_layer = TransformerEncoderLayer(embed_dim = ..., # TODO : What should be the hidden dim ?\n",
    "                                                dim_query = dim_query, \n",
    "                                                dim_value = dim_value,\n",
    "                                                num_heads = num_heads, \n",
    "                                                dim_feedforward= 256,\n",
    "                                                dropout = 0.1)\n",
    "        \n",
    "        # TODO : Initialize your Transformer\n",
    "        self.transformer = TransformerEncoder(encoder_layer = ...,\n",
    "                                              num_layers = ...)\n",
    "        # TODO : Initialize your regression head\n",
    "        self.head = nn.Linear(...,...) # What is your input hidden dim, output hidden dim ? Don't forget your time embedding\n",
    "        # TODO : Initialize your Time2Vector Embeddings\n",
    "        self.timeencoder = Time2Vector(...) # What is the in_features dimension ? Is it the same as the input ?\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        bs,h,len = x.shape\n",
    "        pos = x.permute(0,2,1)\n",
    "        time_vec = self.timeencoder(pos)\n",
    "        # TODO : Concatenate your time embedding to the input sequence\n",
    "        x = torch.cat(...) # TODO : Verify that the tensor was correctly concatenated within the feature dim\n",
    "        # TODO : Send your input through your transformer\n",
    "        x = self.transformer(x)\n",
    "        x = x.view(bs*len, -1)\n",
    "        # TODO : Send your input through the regression head\n",
    "        x = self.head(x)\n",
    "        x = x.view(bs,-1,len)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # TODO : Define your Training Step\n",
    "        X,y = ...\n",
    "        out = ...\n",
    "        loss = ...\n",
    "        # Don't remove the next line, you will understand why later\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # TODO : Define your Validation Step\n",
    "        X,y = ...\n",
    "        out = ...\n",
    "        loss = ...\n",
    "        # Don't remove the next line, you will understand why later\n",
    "        self.log('val_loss', loss)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # TODO : Define your Test Step\n",
    "        X,y = ...\n",
    "        out = ...\n",
    "        loss = ...\n",
    "        self.log('test_loss', loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNs5inW6Xt_a"
   },
   "source": [
    "## IV - Training the Model\n",
    "\n",
    "* Initialize a model with 3 stacks of Encoder with 8 heads.\n",
    "* What is the Embed Dimension ?\n",
    "* What is the Dimension of a Query, Key and Value ? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8HXr5PLUXupy"
   },
   "outputs": [],
   "source": [
    "# TODO : Initalize Model, Datamodule and Trainer\n",
    "embed_dim = ...\n",
    "num_heads = ...\n",
    "dim_query = ...\n",
    "dim_value = ...\n",
    "num_layers = ...\n",
    "\n",
    "model = StockModel(embed_dim=...,\n",
    "                      dim_query=...,\n",
    "                      dim_value=..., \n",
    "                      num_layers=..., \n",
    "                      num_heads= ...).double()\n",
    "\n",
    "\n",
    "dm = ...\n",
    "\n",
    "trainer = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DPXG6HUEe2Qv"
   },
   "outputs": [],
   "source": [
    "# TODO : Fit the Data to the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_21I4eFCTqtH"
   },
   "source": [
    "## V - Testing the model : Inference \n",
    "\n",
    "Now that the model is trained, testing it is a key to become rich."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h70XsCUhZWdr"
   },
   "source": [
    "#### a - Testings \n",
    "\n",
    "Test the model on the test dataset.\n",
    "\n",
    "* What happens ?\n",
    "* What can we do to enhance the results ?\n",
    "* Will you deploy the model ?\n",
    "* What are your predictions for next week ? Can we invest or not ?\n",
    "\n",
    "**Illustrate your arguments using charts or any kind of visual materials supporting your analysis. Any non illustrated analysis won't be taken into account**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2LemCOfzERLZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtli_XCEZJL_"
   },
   "source": [
    "#### b - Further Testings \n",
    "\n",
    "Test the model on a different dataset.\n",
    "* What can you say ?\n",
    "* What are your predictions for next week ? Can we invest or not ?\n",
    "\n",
    "**Illustrate your arguments using charts or any kind of visual materials supporting your analysis. Any non illustrated analysis won't be taken into account**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iZtp7Aq7ZS2m"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMh6VThIhQsKrZtnI293vDJ",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
