{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pokemon Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kNLuJz0mezw6"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thad75/TP_ENSEA_ELEVE/blob/main/SIA/TP1/Pokemon_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--1y1YEKqpHE"
      },
      "source": [
        "# TP1 \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "This lab is an introduction to TensorFlow. \n",
        "In this lab, you will create a model that classifies two pokemons. \n",
        "\n",
        "<img src=\"https://i.ytimg.com/vi/6KYA-7HtSVA/hqdefault.jpg\">\n",
        "\n",
        "You will follow the classical Deep Learning Strategy:\n",
        "\n",
        "* Gather Data\n",
        "* Create Model\n",
        "* Train Model\n",
        "\n",
        "The goal of this lab :\n",
        "* Learn to use TensorFlow\n",
        "* Create a Binary Classification Model\n",
        "* Do some Data Augmentation\n",
        "* Learn to plot things with matplotlib\n",
        "* Learn to read a documentation\n",
        "* Test your model \n",
        "\n",
        "Your bestfriend for this whole lab will be : https://www.tensorflow.org/api_docs/python/tf/keras/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfdSUs9Vj7gh"
      },
      "source": [
        "Load the dataset into your current workspace and unzip it. A drag and drop will be sufficent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HScyERfwJ81"
      },
      "source": [
        "!unzip '/content/TP.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjK4TA4crlU5"
      },
      "source": [
        "# W TF.Keras ?\n",
        "\n",
        "<img src=\"https://blog.zenika.com/wp-content/uploads/2017/11/markblogtensorflow-1.png\">\n",
        "\n",
        "Tensorflow is a Deep Learning framework created by Google. This will be the only lab in TensorFlow as the Deep Learning Community evolves quickly with Pytorch. But feel free to rewrite the other code in TF in you want.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdGbCU-vsSke"
      },
      "source": [
        "# Gather Data \n",
        "\n",
        "\n",
        "Your goal will be to create a classifier that classifies Pikachu and Jigglypuff (or any other Pokemon you like, ask me the dataset, so I can give you the image. Only the Gen1 is available)\n",
        "\n",
        "For the joke :  https://www.youtube.com/watch?v=WSGV_n6H1n0\n",
        "\n",
        "<img src='data:image/jpeg;base64,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'>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy9vp5satBU0"
      },
      "source": [
        "Your goal is now to gather data for training. \n",
        "* What data should you gather ?\n",
        "* How are you going to gather the data ?\n",
        "* What will be the issues you'll be facing ?\n",
        "\n",
        "Give some strategies and its advantages and inconvenients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur8MzVgDtMij"
      },
      "source": [
        "# Scrap the Data\n",
        "\n",
        "As futur engineers, you will see that Data management and preparation is a huge (boring) work. However it is mandatory to have quality labelled data. We scrapped the data for you. However we need to do some preprocessing to easen the data loading.\n",
        "\n",
        "In this case, as we are doing binary classification, it is easier to have two separate folders for each images. \n",
        "\n",
        "* What are the labels ? Are there Outliers ?\n",
        "* How would you handle outliers ?\n",
        "* How are the labels constructed ?\n",
        "* Describe your dataset\n",
        "\n",
        "Create subfolders separating the data and move the corresponding data in its folder\n",
        "\n",
        "Write a function that takes into account the image folder, and creates as much subfolders as needed where each subfolder is a Class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42Jm2dG7LN0u"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def move_image_to_folder(folder, folder_to_move_to):\n",
        "  \"\"\"\n",
        "  Function must move a file to its corresponding Subfolder. You might have to create the folder before.\n",
        "  \"\"\"\n",
        "  files = [folder + '/' + i for i in os.listdir(folder)]\n",
        "\n",
        "\n",
        "\n",
        "folder = \"/content/TP\"\n",
        "folder_to_move_to = _\n",
        "move_image_to_folder(folder,folder_to_move_to))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpBzU9vvNiRk"
      },
      "source": [
        "Now run the next code, we are just moving some Data for what will happen next in the lab. Please verify that your folder is constructed as follows :\n",
        "* Dataset\n",
        "  * Class 1\n",
        "  * Class 2\n",
        "  * ...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmJJeU-FNaqu"
      },
      "source": [
        "from distutils.dir_util import copy_tree\n",
        "import os \n",
        "import shutil\n",
        "def Move_and_Create(folder):\n",
        "    folders = [folder + '/' + i for i in os.listdir(folder)]\n",
        "    if len(folders)>3:\n",
        "      os.system('rmdir /content/TP/.ipynb_checkpoints')\n",
        "    os.mkdir(\"/content/TP/Part1/\")\n",
        "    os.mkdir(\"/content/TP/Part2/\")\n",
        "    shutil.move(\"/content/TP/Pikachu\",\"/content/TP/Part1/\")\n",
        "    copy_tree(\"/content/TP/Part1/Pikachu\", \"/content/TP/Part2/Pikachu\")\n",
        "    shutil.move(\"/content/TP/Jigglypuff\",\"/content/TP/Part1/\")\n",
        "    shutil.move(\"/content/TP/Raichu\",\"/content/TP/Part2/\")\n",
        "    \n",
        "Move_and_Create(\"/content/TP\")    "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tidj1UIxPCh9"
      },
      "source": [
        "# Part 1 : Pikachu vs Jigglypuff\n",
        "\n",
        "The goal of this first part will be to classify images of Jigglypuff and Pikachu. Before beginning anything :  \n",
        "* Is it going to be an easy task ? If yes why ? Think as a human :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad_vC__Ztnug"
      },
      "source": [
        "# Preprocessing and Dataset Creation\n",
        "\n",
        "Tensorflow has this wonderful method : Image_dataset_from_directory. This method creates a dataset from images found in a folder. The folder should be constructed as follows : \n",
        "* Dataset\n",
        "  * Class 1\n",
        "  * Class 2\n",
        "  * ....\n",
        "\n",
        "where each Class x subfolder is filled with images of class X.\n",
        "\n",
        "* What are we going to do ? Do some EDA (Exploratory Data Analysis)\n",
        "More information on : https://www.tensorflow.org/tutorials/load_data/images\n",
        "* Define all the terms you'll be using in the image_dataset_from_directory folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl9EoSEIUHh2"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\"/content/TP/Part1/\",\n",
        "                                                        validation_split=_,\n",
        "                                                        subset=_,\n",
        "                                                        batch_size=_)\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\"/content/TP/Part1/\",\n",
        "                                                      validation_split=_,\n",
        "                                                      subset=_,\n",
        "                                                      seed=123,\n",
        "                                                      batch_size=_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS-L_CWDaJGp"
      },
      "source": [
        "Now that the Datasets are created let's get an in depth understanding of what was created.\n",
        "* Print the class names. Are they coherent with the data ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "195ZQnMiWsb7"
      },
      "source": [
        "class_names = _"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSwfn4UUFq1p"
      },
      "source": [
        "Now let's print few elements of a batch in the training dataset.\n",
        "For exemple print the shape of one batch and the labels of the batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEadsV8dWxgz"
      },
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3txSCGVL8rGJ"
      },
      "source": [
        "* What do you think of the quantity of data you have ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehhL1NJouMcc"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhmsTma6uP6D"
      },
      "source": [
        "Now you will create the model you are going to train. \n",
        "* What type of layers would be the most suitable ? \n",
        "* Why ?\n",
        "* What should be the output of the model ?\n",
        "* What loss will you be using ?\n",
        "\n",
        "Create a simple model that performs classification. We have imported the most used Layers for you.\n",
        "* Define all terms in your model\n",
        "* Explain how you create your model. \n",
        "\n",
        "If you tried multiple model, show us the different models you used.\n",
        "And explain why your model did or did not work. It's ok for your first model not to work. However, try to understand why and how you can enhance it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDHMZ8OSrkpG"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model, Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc68WE7sE2L6"
      },
      "source": [
        "PokemonClassifier = Sequential([\n",
        "\n",
        "])\n",
        "\n",
        "# Create an instance of the model\n",
        "model = PokemonClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxP02elDPrFc"
      },
      "source": [
        "# Loss \n",
        "\n",
        "* What loss will you be using ?\n",
        "* Why ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kmSr4gkPx2J"
      },
      "source": [
        "loss = tf.keras.losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFQ0ri9DP0ax"
      },
      "source": [
        "# Optimizer\n",
        "\n",
        "* What optimizer will you be using ?\n",
        "* Why ?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpcRdwbrP6hQ"
      },
      "source": [
        "optimizer = tf.keras.optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwzruwVMP88U"
      },
      "source": [
        "# Metrics\n",
        "\n",
        "* What metric could you calculate ?\n",
        "* How ? Why ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlxEy63eQVTA"
      },
      "source": [
        "accuracy= tf.keras.metrics\n",
        "precision = \n",
        "recall = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN_aXV0KPZy5"
      },
      "source": [
        "Let's compile the model and print its summary. \n",
        "* Explain how the output shape of each layer is calculated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZAs4HUwKOR7"
      },
      "source": [
        "model.compile()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyig0gjcRfuO"
      },
      "source": [
        "# Let's Train\n",
        "\n",
        "* Choose a number of epoch.\n",
        "* Fit the data to the model.\n",
        "\n",
        "The history variable will keep a log of the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YteQoTTRLes"
      },
      "source": [
        "epochs =_\n",
        "history = model.fit(\n",
        "  _,\n",
        "  validation_data=_,\n",
        "  epochs=_\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0B33FShRtv-"
      },
      "source": [
        "# Plot\n",
        "\n",
        "Let exploit the history. \n",
        "* What are the keys of the history.history variable ? \n",
        "* What should we plot ? How ?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0UJFY5ZK0Hy"
      },
      "source": [
        "history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F14jd-_pDD7Q"
      },
      "source": [
        "Using matplotlib plot the values of the keys and explain how the model training was :\n",
        "* Overfitting, Underfitting ?\n",
        "* Effect of LR ?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL68tOK_KeEB"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = _\n",
        "val_acc = _\n",
        "\n",
        "loss = _\n",
        "val_loss = _\n",
        "\n",
        "prec = _\n",
        "val_prec = _ \n",
        "\n",
        "recall = _\n",
        "val_recall = _ \n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(24, 8))\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.plot(epochs_range, _, label=)\n",
        "plt.plot(epochs_range, _, label=)\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mc5JFHvLFCWP"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U275OOPhSJII"
      },
      "source": [
        "# Test the model \n",
        "\n",
        "Pick some images on the internet of Pikachu and Jigglypuff, and send them to the model. We provide you the needed libraries to stream an array from a link.\n",
        "* Explain why we expand_dim ?\n",
        "* Explain why we resize ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlzFtM5dSJIZ"
      },
      "source": [
        "import skimage\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "image_filename = _ #URL of iamge\n",
        "image_numpy = cv2.cvtColor(skimage.io.imread( image_filename ),cv2.COLOR_BGR2RGB)\n",
        "cv2_imshow(image_numpy)\n",
        "img_array = tf.keras.utils.img_to_array(image_numpy)\n",
        "\n",
        "# WHY DO WE ADD THIS LINE ?\n",
        "img_array.resize((256, 256,3))\n",
        "\n",
        "# WHY DO WE ADD THIS LINE ?\n",
        "img_array = tf.expand_dims(img_array, 0)\n",
        "predictions = _\n",
        "score = _\n",
        "\n",
        "\n",
        "print(\n",
        "    \"This image is %.2f percent Jygglipuff and %.2f percent Pikachu.\"\n",
        "    % (100 * (1 - score), 100 * score)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJZ7FJMLt5F2"
      },
      "source": [
        "Depending of your training, you might have good or bad results. If you model can not generalize, show us why it can't and find a solution against that. If your model generalizes well, WELL DONE !\n",
        "\n",
        "<img src='https://external-preview.redd.it/NgWFa6bp1oViwWwdfVYU1Wwy8_w8O0bsinJjyLZGD7M.jpg?width=640&crop=smart&auto=webp&s=156ff536f86d80bdc024f69c0ac7ccb8088eb5b4'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6bNZKH3FRMH"
      },
      "source": [
        "# Another Try with Data Augmentation\n",
        "\n",
        "\n",
        " Let's now try on pokemon similar to Pikachu : Raichu\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_WC_OAETTm9"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  \"/content/TP/Part2/\",\n",
        "  validation_split=_,\n",
        "  subset=_,   \n",
        "  seed=123,\n",
        "  batch_size=_)\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  \"/content/TP/Part2/\",\n",
        "  validation_split=_,\n",
        "  subset=_,\n",
        "  seed=123,\n",
        "  batch_size=_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh1WE7Xxf6i-"
      },
      "source": [
        "class_names = _\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX630Z0CewlN"
      },
      "source": [
        "# Data Augmentation and Processing using TF\n",
        "\n",
        "\n",
        "In the previous part, we could have done few things to enhance the results. The preprocessing part is important. Many type of preprocessing exists. For example, one could resize the image shape before sending in to the image.\n",
        "\n",
        "* What's the range of the value of your images ?\n",
        "* Normalize the images between [0,1]. Why would we normalize the image ?\n",
        "Have a look at :  https://www.tensorflow.org/api_docs/python/tf/keras/utils\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glqM3wCB8qE4"
      },
      "source": [
        "normalize = tf.keras.layers"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKkook-NfuHx"
      },
      "source": [
        "# Data Augmentation\n",
        "\n",
        "* What's the purpose of doing Data Augmentation ?\n",
        "* Apply Random Rotation to your Data\n",
        "have a look at : https://www.tensorflow.org/guide/keras/preprocessing_layers\n",
        "\n",
        "To add a Preprocessing Layer to your model, simply add the layers into your model.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7DagjH5qBCC"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model, Sequential"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J5ZNtyJIBOZ"
      },
      "source": [
        "data_augmentation = Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "  ]\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGgDtkHfW_q8"
      },
      "source": [
        "CAREFUL. To see the effect of Data Augmentation, first train your model without the Preprocessing and Data Augemntation layers. Save the results somewhere, then try again with teh same model and add the preprocessing layers.\n",
        "You can create multiple model if needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai2hbIF3qBCH"
      },
      "source": [
        "PokemonClassifier = Sequential([\n",
        "  # add your preprocessing layers\n",
        "\n",
        "  \n",
        "  # your model goes here.\n",
        "\n",
        "])\n",
        "\n",
        "# Create an instance of the model\n",
        "model = PokemonClassifier"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY38wxdVqBCI"
      },
      "source": [
        "# Loss \n",
        "\n",
        "* What loss will you be using ?\n",
        "* Why ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6zXZp75qBCI"
      },
      "source": [
        "loss ="
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFdG9EtDqBCI"
      },
      "source": [
        "# Optimizer\n",
        "\n",
        "* What optimizer will you be using ?\n",
        "* Why ?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pA1JcvbqBCI"
      },
      "source": [
        "optimizer = "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75O4_fFuqBCI"
      },
      "source": [
        "# Metrics\n",
        "\n",
        "* What metric could you calculate ?\n",
        "* How ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRo1rTaCqBCI"
      },
      "source": [
        "accuracy= \n",
        "precision = \n",
        "recall = "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj2iy26OqBCI"
      },
      "source": [
        "Let's compile the model and print its summary. \n",
        "* Explain how the output shape of each layer is calculated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql9dizQ7qBCI"
      },
      "source": [
        "model.compile()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJuW41yZqBCI"
      },
      "source": [
        "# Let's Train\n",
        "\n",
        "* Choose a number of epoch.\n",
        "* Fit the data to the model.\n",
        "\n",
        "The history variable will keep a log of the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LwUEibNqBCI"
      },
      "source": [
        "epochs = 30\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=_,\n",
        "  epochs=_\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68XLbASv2pIn"
      },
      "source": [
        "Plot and Explain your Training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZXEc2ylwwKS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnja_D683Hn8"
      },
      "source": [
        "Test your model on few images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzAnXpwEwMcd"
      },
      "source": [
        "import skimage\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "image_filename =  #URL OF IMAGE\n",
        "image_numpy = cv2.cvtColor(skimage.io.imread(image_filename ),cv2.COLOR_BGR2RGB)\n",
        "cv2_imshow(image_numpy)\n",
        "img_array = tf.keras.utils.img_to_array(image_numpy)\n",
        "\n",
        "img_array.resize(\n",
        "     (256, 256,3))\n",
        "img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = predictions[0]\n",
        "\n",
        "\n",
        "print(\n",
        "    \"This image is %.2f percent Raichu and %.2f percent Pikachu.\"\n",
        "    % (100 * (1 - score), 100 * score)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkoptXdpe-Ay"
      },
      "source": [
        "* DId the Data augmentation change something to the training ?\n",
        "* What could we do to get better results ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKdiJUDx0rA8"
      },
      "source": [
        "# Visualization\n",
        "\n",
        "Hmm, let's do something more. Let's visualize how the feature are scattered in the feature world.\n",
        "We provide you few functions that will help you. Normally the plotting must be done on a separate Test set. However, let's do it on the Validation Set. But before that :    \n",
        "* Why is it ok to do it on the Validation Set ?\n",
        "\n",
        "Use the TSNE method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrMsw3MyJx3j"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def dimension_reduction_2D(X, method='tsne'):\n",
        "    ''' unsupervised linear dimensionality reduction and scale to [0, 1] '''\n",
        "\n",
        "    fitter = {\n",
        "        'tsne': TSNE(n_components=2).fit_transform,\n",
        "        'pca': PCA(n_components=2).fit_transform\n",
        "    }.get(method, None)\n",
        "    if fitter is None:\n",
        "       raise Exception('unkown dimensionality reduction technique')\n",
        "    \n",
        "    Xs = fitter(X)\n",
        "    Xmin, Xmax = np.amin(Xs), np.amax(Xs)\n",
        "    Xs = (Xs - Xmin) / (Xmax - Xmin)\n",
        "    return Xs\n",
        "\n",
        "def plot_tsne(X_2D, label, n_classes, figsize=(8, 8)):\n",
        "    x, y = X_2D.T\n",
        "\n",
        "    cmap_tsne = cm.get_cmap('hsv', n_classes+1) \n",
        "\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    \n",
        "    ax.scatter(x, y, c=sorted(['#1f77b4', '#ff7f0e']*(len(label)//2)), cmap=cmap_tsne, s=50, edgecolors='c')\n",
        "\n",
        "    (x_left, x_right), (y_bot, y_top) = ax.get_xlim(), ax.get_ylim()\n",
        "    ratio = abs((x_right-x_left) / (y_bot-y_top))\n",
        "    ax.set_aspect(ratio)\n",
        "\n",
        "    ax.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "def sample_latent(model, dataloader, n_classes:int, k:int=10, thresh=0.5,device=None, enable_tqdm=True):\n",
        "    ''' return k randomply sampled embedding from each class\n",
        "    using the reservoir sampling algorithm along with there labels\n",
        "    '''\n",
        "    # reservoir sampling\n",
        "    thresh = tf.constant(thresh)\n",
        "    counters = [0] * n_classes\n",
        "   # print(counters)\n",
        "    sampling = [[] for _ in range(n_classes)]\n",
        "    iterator = tqdm(dataloader) if enable_tqdm else dataloader\n",
        "    for images, labels in iterator: \n",
        "        h = model(images)\n",
        "        # reservoir sampling selection\n",
        "        for i, label in enumerate(labels):\n",
        "            if counters[label] < k:                \n",
        "                sampling[label].append(tf.expand_dims(h[i], axis= 0))\n",
        "            else: \n",
        "                j = np.random.randint(counters[label])\n",
        "                if j < k:\n",
        "                    sampling[label][j] =tf.expand_dims(h[i], axis= 0)\n",
        "            counters[label] += 1\n",
        "\n",
        "    # flatten list to a single tensor\n",
        "    embeddings = []\n",
        "    for i in range(n_classes):\n",
        "        embedding_class_i = tf.concat(sampling[i],axis = 0)\n",
        "        embeddings.append(embedding_class_i)\n",
        "\n",
        "    embeddings = tf.concat(embeddings, axis = 0).cpu().numpy()\n",
        "    labels = np.repeat(np.arange(n_classes), k)\n",
        "\n",
        "    return embeddings, labels\n",
        "\n",
        "\n",
        "n_classes = _\n",
        "k =39//2\n",
        "\n",
        "embeddings, labels = sample_latent(model, val_ds, n_classes, k=k, device='gpu')\n",
        "embeddings_2D = dimension_reduction_2D(embeddings, method='tsne')\n",
        "plot_tsne(embeddings_2D, labels, n_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooJNZCstykVc"
      },
      "source": [
        "* How is the feature space ? How are the data gathered ? Is it normal ?\n",
        "* Are the data linearly separable ? If yes draw a line showing the separation.\n"
      ]
    }
  ]
}