# 🎨 Generating Images with Deep Learning  

Image generation is a rapidly evolving field, with diffusion models leading recent breakthroughs. However, before their rise, other architectures played a key role in generating images. This lab explores generative models, their applications, and how they are used across industries—ranging from NFT creation and virtual try-ons to deepfake generation.  

---

## 🌟 Learning Objectives  

By the end of this lab, you will:  
- **Work hands-on with generative models** to create images.  
- **Reinforce your Deep Learning knowledge** through practical experimentation.  
- **Train an Autoencoder on MNIST** to understand latent space representation.  
- **Implement a Generative Adversarial Network (GAN)** to generate realistic samples.  
- **Explore the Pix2Pix GAN for image-to-image translation**, specifically for transforming Google Maps overlays into satellite images.  
- **Use existing codebases** to understand and extend pre-trained models.  
- **Leverage PyTorch Lightning** for efficient model training and structuring.  
- **Explore real-world AI applications** in industries utilizing image generation.  

---

## 🛠️ How to Use  

- Train an **Autoencoder on MNIST** to learn compressed image representations.  
- Implement a **GAN to generate synthetic images** from random noise.  
- Experiment with **Pix2Pix GAN for translating map overlays to satellite imagery**.  
- Modify and reuse existing PyTorch Lightning implementations for efficient model training.  

---

## 🚀 Why This Lab?  

- **Practical Approach** – Gain hands-on experience instead of just theoretical knowledge.  
- **Industry-Relevant Skills** – Understand how AI-powered image generation is applied in real-world scenarios.  
- **Efficient Model Training** – Learn best practices for using PyTorch Lightning in generative modeling.  

---

Get ready to explore the power of AI in image generation! 🚀  